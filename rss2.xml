<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Michael&#39;s Study Blog</title>
    <link>https://kimh060612.github.io/</link>
    
    <atom:link href="https://kimh060612.github.io/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>Backend Engineering, Deep learning, Algorithm &amp; DS, CS 전공 지식 공부 저장소</description>
    <pubDate>Wed, 15 Jun 2022 11:49:20 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>SLAM Study Part 1.</title>
      <link>https://kimh060612.github.io/2022/06/02/SLAM-Survey/</link>
      <guid>https://kimh060612.github.io/2022/06/02/SLAM-Survey/</guid>
      <pubDate>Thu, 02 Jun 2022 11:07:12 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;SLAM-Study-Introduction&quot;&gt;&lt;a href=&quot;#SLAM-Study-Introduction&quot; class=&quot;headerlink&quot; title=&quot;SLAM Study - Introduction&quot;&gt;&lt;/a&gt;SLAM Study - In</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="SLAM-Study-Introduction"><a href="#SLAM-Study-Introduction" class="headerlink" title="SLAM Study - Introduction"></a>SLAM Study - Introduction</h2><p>이번 포스트에서는 SLAM에 관해서 논의해 볼 것이다. 이 포스트는 <a href="http://www1.cs.columbia.edu/~allen/F19/NOTES/slam_paper.pdf">다음 글</a>을 바탕으로 제작되었다.</p><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li>SLAM: Problem Definition  <ol><li>Mathematical Basis</li><li>Example: SLAM in Landmark Worlds</li><li>Taxonomy of the SLAM Problem</li></ol></li><li>Three Main SLAM Paragigms  <ol><li>Extended Kalman Filters</li><li>Particle Methods</li><li>Graph-Based Optimization</li><li>Relation of Paradigms</li></ol></li><li>Visual RGB-D SLAM  </li></ol><h3 id="SLAM-Problem-Definition"><a href="#SLAM-Problem-Definition" class="headerlink" title="SLAM: Problem Definition"></a>SLAM: Problem Definition</h3><p>SLAM이란, 이동하는 로봇이 미지의 환경과 noise가 낀 Sensor를 가지고 주변 환경의 Map을 만들면서 자기 자신의 상대적인 위치를 특정하는 알고리즘을 일컫는다. 이러한 알고리즘을 배우기 위해서 이 파트에서는 어떠한 수학적 지식이 필요한지와, 어떤 문제들을 해결해 나가야 하는지를 배우게 된다.</p><h4 id="Mathematical-Basis"><a href="#Mathematical-Basis" class="headerlink" title="Mathematical Basis"></a>Mathematical Basis</h4><p>SLAM에서 mobile robot의 궤적은 다음과 같이 정의된다.</p><blockquote><p>2차원 평면에서의 좌표 $(x, y)$와 로봇이 향하고 있는 방향 $\theta$의 3차원 벡터의 Sequence</p></blockquote><p>예를 들어서 $x_t = (x,y,\theta)$ 라고 하자. 그렇다면 이러한 궤적(path)는 다음과 같이 정의된다.</p><script type="math/tex; mode=display">X_T = \{x_0, x_1, x_2, \dots , x_T\}\tag{Definition 1}</script><p>이러한 궤적에서 $T$는 $\infin$가 될 수도 있다.<br>여기서 Odometry라는 개념이 나온다. 이는 무엇이냐면, “시간에 따른 위치 변화를 측정하기 위하여 Sensor의 데이터를 사용하는 것”이다. 굉장히 포괄적인 개념인데, SLAM을 할때는 반드시 나오는 개념이니 꼭 이해해 두도록 하자.</p><p>여기서 우리는 간단하게 Odometry로 $t-1$에서 $t$로의 위치 벡터 $x_t$를 추정할 수 있는 데이터 $u_t$가 있다고 가정하자.</p><p>그렇다면 다음의 Sequence $U_T$를 로봇의 상대적인 위치의 motion의 정보라고 할 수 있다.</p><script type="math/tex; mode=display">U_T = \{ u_1, u_2, \dots, u_T \}\tag{Definition 2}</script><p>noise가 없는 motion의 경우, $U_T$와 $x_0$만으로도 충분히 경로를 복원할 수 있을 것이다. 하지만 어림도 없다. $U_T$에는 반드시 noise가 끼워져 있을 수 밖에 없다. </p><p>최종적으로 로봇은 주변 환경을 감지할 것이다. LiDAR든지 Camera를 사용해서 말이다. 우리는 $m$을 주변 환경에 대한 <em>진짜</em> 지도라고 앞으로 표시하겠다.<br>이러한 지도 $m$은 Landmark, object, surface 등등으로 구성되어 있을 것이다. 그리고 $m$은 그들의 location이 될 것이다. 그리고 $m$은 종종 time-invariant하다고 간주된다. </p><p>주변의 환경 정보 $m$과 자신의 위치 정보 $x_t$ 사이에서 로봇의 measurements는 정보를 수립하게 된다. 만약에 로봇이 정확하게 1번의 기준 시점에서 1개의 measurement를 얻는다면 우리는 이러한 measurement의 sequence를 다음과 같이 표시할 수 있다. </p><script type="math/tex; mode=display">Z_T = \{ z_1, z_2, z_3, \dots, z_T \}\tag{Definition 3}</script><p>그렇다면 우리는 SLAM을 위의 definition 1,2,3을 사용해서 재차 간략하게 표현할 수 있다. </p><blockquote><p>SLAM은 $U_T$와 $Z_T$를 가지고 주변 환경 $m$과 자신의 위치의 sequence $X_T$를 복원하는 문제이다.</p></blockquote><p>이러한 SLAM 문제를 조금 더 세부적으로 나눠서 여러 문제들이 또 존재한다.<br>첫번째로, 밑의 확률 분포를 구하는 문제를 <em>full SLAM problem</em>이라고 한다.</p><script type="math/tex; mode=display">p(X_T, m | Z_T, U_T)\tag{Definition 4}</script><p>보이다시피, 이 알고리즘을 데이터를 batch 단위로 처리하게된다. 즉, offline이라는 것이다. </p><p>두번째로, 밑의 확률 분포를 구하는 문제를 <em>online SLAM problem</em>이라고 한다. </p><script type="math/tex; mode=display">p(x_t,m | Z_t, U_t)\tag{Definition 5}</script><p>Online SLAM은 로봇의 전체 경로를 복원하는 것보다는 현재의 위치에 초점을 맞추고 있다. 이러한 online알고리즘들은 통상 <em>filters</em>라고 부른다. </p><p>이러한 SLAM Problem들을 해결하기 위해서는 2가지의 모델이 추가로 필요하다. </p><ol><li>Odometry Model $U_T$에 대한 수학적인 model</li><li>환경 $m$에서 로봇의 위치가 $x_t$일때, measurment $z_t$에 대한 model</li></ol><p>그렇다면 우리는 SLAM에서 다음과 같은 확률 분포를 추측하는 것이 타당하다고 쉽게 알 수 있을 것이다.</p><script type="math/tex; mode=display">p(x_t|x_{t-1}, u_t)\tag{Definition 6}</script><script type="math/tex; mode=display">p(z_t|x_t, m)\tag{Definition 7}</script><p>위 2가지 확률 분포를 여태까지의 내용을 종합해 보았을때 우리가 필요한 2가지의 모델이라고 할 수 있다.</p><h4 id="Example-SLAM-in-Landmark-Worlds"><a href="#Example-SLAM-in-Landmark-Worlds" class="headerlink" title="Example: SLAM in Landmark Worlds"></a>Example: SLAM in Landmark Worlds</h4><p>우리는 종종 표현하기 어려운 수학적인 모델을 표현하기 쉽도록 가정을 통해서 constraints를 두는 것을 많이 진행한다.</p><p>SLAM에서 가장 흔하게 쓰이는 가정이 바로 환경 $m$을 point-landmarks로 표현하는 것이다.<br>이를 간략하게 설명하자면, 2D 평면에 점들을 찍어서 Map을 표현하는 것이다. 이렇게 표현하면 점의 갯수를 $N$이라고 했을때 Map을 $2N$ Dimension의 벡터로 표현할 수 있다. </p><p>이러한 계파에서는 다음과 같이 가정을 하는 것이 일반적이다. </p><blockquote><p>로봇은 다음 3가지를 감지할 수 있다.</p><ol><li>landmarks 주변의 상대적인 거리</li><li>landmarks들의 상대적인 bearing (방위각)</li><li>landmark들의 identity </li></ol></blockquote><p>위에서 1,2번은 noise가 발생할 수 밖에 없다. 하지만 가장 simple한 케이스로 한정을 한다면 3번은 완벽하게 측정할 수 있다. </p><p>만약, 3번을 결정하는 문제로 넘어가면 그건 SLAM의 가장 어려운 문제중 하나로 분류된다.</p><p>위 설정을 가지고 noise가 없는 measurement function을 먼저 정의해 보도록 하겠다.</p><script type="math/tex; mode=display">z^g_t = h(x_t, m)\tag{Definition 8}</script><script type="math/tex; mode=display">x^g_t = g(x_{t-1}, u_t)\tag{Definition 9}</script><p>위의 $z^g_t$, $x^g_t$는 각각 $\mathbb{R}^2$, $\mathbb{R}^3$에 속하는 벡터들로써, noise가 없는 진짜 사물의 landmark point/위치이다.</p><p>하지만 우리가 실제로 받는 값은 여기에 Noise가 끼기 마련이다. 따라서 이를 수학적으로 정의하기 위해서 우리는 하나의 예시로써 다음과 같이 $z_t$, $x_t$를 정의해 보자.</p><p>$\mathcal{N}$을 Gaussian Distribution이라고 하고 $\mathbf{Q}_t \in \mathbb{R}^{2 \times 2}$, $\mathbf{R}_t \in \mathbb{R}^{3 \times 3}$인  Noise Covariance Matrix 2개가 있다고 가정하자.</p><p>그렇다면 $z_t$, $x_t$는 다음과 같이 표현할 수 있다.</p><script type="math/tex; mode=display">p(z_t | x_t, m) = \mathcal{N}(z^g_t, \mathbf{Q}_t)\tag{Definition 10}</script><script type="math/tex; mode=display">p(x_t|x_{t-1}, u_t) = \mathcal{N}(x^g_t, \mathbf{R}_t)\tag{Definition 11}</script><p>물론, 여태까지의 논의는 솔직히 너무 현실과 동떨어져있다. 하지만 명심해야할 점은 어떠한 SLAM 알고리즘이던, 결국에는 $p(z<em>t | x_t, m)$와 $p(x_t|x</em>{t-1}, u_t)$에 대한 논의가 필요하다는 것이다. </p><h4 id="Taxonomy-of-the-SLAM-Problem"><a href="#Taxonomy-of-the-SLAM-Problem" class="headerlink" title="Taxonomy of the SLAM Problem"></a>Taxonomy of the SLAM Problem</h4><p>SLAM이 워낙 포괄적인 문제이다보니, 알고리즘별로 여러 접근 방법이 존재한다. 우리는 그것의 분류법을 여기서 다뤄볼 것이다. </p><ol><li><p>Full Batch vs Online</p><p> 위에서 다룬 논의이니 넘어가도록 하겠다.</p></li><li><p>Volumetric vs Feature-Based</p><p> Volumetric SLAM에서는 Map 정보가 고화질로 sampling되어 주변 환경을 photo-realistic하게 재구축할 수 있는 상황이다. 상당히 많은 데이터를 다루고 그만큼 연산량도 엄청나다.</p><p> 그에 비해서 Feature-Based SLAM은 상대적으로 sparse한 정보를 가지고 SLAM을 진행한다. 이 방법이 조금 더 연산량이 가볍고 효율적이지만, 정확도는 상대적으로 떨어질 수 밖에 없다.</p></li><li><p>Topological vs Metric</p><p> Topological한 Mapping 기법은 location들의 관계를 기초로 하여 정의된다. 그에 반해서 Metric Mapping은 location들의 거리(Metric)에 기반하여 Mapping을 진행한다. 요즘 학계에서는 Topological 기법을 거의 쓰지 않는다.</p></li><li><p>Known vs Unknown Correspondence</p><p> Correspondence 문제는 관측된 것들의 Identity끼리의 관계도를 조사하는 것이다. 몇몇 SLAM 알고리즘들에서 이러한 처리를 추가적으로 진행한다. 이러한 Correspondence를 추정하는 문제는 <em>data association</em> 문제라고도 불리우며 SLAM의 가장 난제중 하나이다.</p></li><li><p>Static vs Dynamic</p><p> Static SLAM은 주변 환경이 시간에 따라 변화하지 않는다는 전제를 가지고 SLAM을 진행한다. Dynamic SLAM은 시간에 따라 환경이 변화할 수 있다는 것을 전제로 SLAM을 진행한다.</p></li><li><p>Small vs Large Uncertainty</p><p> SLAM의 문제는 위치의 uncertainty를 어느 정도로 다룰 수 있는지에 따라서 구분된다. closing loop에 대해서는 이러한 uncertainty가 매우 커지는데, 이 문제를 <em>loop closing problem</em>이라고 한다. 이렇게 loop를 닫는 문제를 푸는 것이 현대 SLAM의 특징이다. 이러한 uncertainty는 GPS같이 자신의 절대 위치를 특정할 수 있으면 조금 감소되어진다.</p></li><li><p>Active vs Passive</p><p> Passive SLAM에서는 다른 개체가 로봇을 조종하게 된다. 그리고 SLAM 알고리즘은 순전히 관측만 한다. 대부분의 SLAM 알고리즘이 이것에 속한다. </p><p> 그에 반해서 Active SLAM에서는 로봇이 자체적으로 환경을 조사하면서 정확한 지도를 얻어내게 된다. </p></li><li><p>Single-Robot vs Multi-Robot</p><p> notation 대로, 단일 로봇이냐 다중 로봇이냐이다. </p></li><li><p>Any-Time and Any-Space</p><p>이 문제는 제한된 시간과 computation power를 가진 로봇에서 SLAM을 푸는데 있어서 과거의 방법애 대한 대안이다. </p></li></ol><h3 id="Three-Main-SLAM-Paragigms"><a href="#Three-Main-SLAM-Paragigms" class="headerlink" title="Three Main SLAM Paragigms"></a>Three Main SLAM Paragigms</h3><p>이 장에서는 다음 3가지의 알고리즘에 대해서 다루게 된다. </p><ul><li>EKF SLAM </li><li>Particle filters</li><li>Graph-Based Optimization</li></ul><p>각각의 특성을 알고리즘별로 알아볼 것이다. </p><h4 id="Extended-Kalman-Filters"><a href="#Extended-Kalman-Filters" class="headerlink" title="Extended Kalman Filters"></a>Extended Kalman Filters</h4><p>역사적으로 Extended Kalman Filters(EKF)는 가장 일찍 나왔다. 아마도 가장 영향력 있는 SLAM 알고리즘이 아닐까 싶다. </p><p>간략하게 설명하자면, 로봇이 주어진 환경에서 움직이면서 measurement를 수집하는데, system의 state vector와 covariance vector가 Kalman filter로 계속 update가 되는 방식이다.<br>즉, 새로운 feature가 발견될때마다 quaderatic하게 covariance의 dimension이 증가하게 된다. </p><p>이러한 Kalman filter의 구현은 매우 중요하고도 어려운 주제이다. 또한 마찬가지로 sensing과 world modeling 또한 이에 필요한 주제이다. 이는 해당 <a href="https://link.springer.com/chapter/10.1007/978-3-319-32552-1_36">링크</a>에서 자세한 내용을 확인할 수 있다. </p><p>EKF 알고리즘은 robot의 estimation을 다음과 같은 multivariate Gaussian으로 표현한다.</p><script type="math/tex; mode=display">p(x_t, m| Z_t, U_t) = \mathcal{N}(\bf{\mu}_t, \bf{\Sigma}_t)\tag{Definition 12}</script><p>여기서 고차원의 벡터 $\bf{\mu}_t$는 현재 위치 $x_t$에 대해서 최적의 estimation을 나타낸다. 그리고 $\bf{\Sigma}_t$는 $\bf{\mu}_t$에 대한 평균적인 error이다. </p><p>지난번에 다루었던 point-landmark 예시에서는 $\bf{\mu}_t$는 $3 + 2N$차원아고 $\bf{\Sigma}_t$는 $(3+2N) \times (3+2N)$차원인 양의 준 정방 행렬이다. </p><p>EKF SLAM의 point-landmark example에서의 유도를 간략히 설명해 보자면 한 시점에서 $g$와 $h$가 Talyor Expansion으로 선형화되고, 그 선형화 된 식에 Kalman Filter를 적용하는 방식이다.<br>EKF SLAM은 기본적으로 online SLAM으로 분류된다. 밑의 그림이 이를 대략적으로 나타내고 있다. </p><p align="center"><img src="https://kimh060612.github.io/img/KalmanFilterExample.png" width="100%"></p><p>위 그림에서 점선이 로봇의 실제 궤적이고 회색 타원이 EKF가 추정한 로봇의 위치이다. 또한 회색 점이 Landmark point의 실제 위치이고 흰색 타원이 EKF가 추정한 point의 위치이다.   </p><p>(a-c)까지는 landmark를 마주할 때마다 로봇의 위치의 uncertainty가 커지게 된다. 그리고 (d)에서 로봇이 처음의 landmark를 다시 감지했을때 모든 landmark와 position의 uncertainty가 감소한다. (d를 잘 보면 현재 위치에 대한 uncertainty가 특히 감소되어 있다.)</p><p>이러한 현상은 Gaussian Posterior의 Covariance Matrix의 Correlation 덕분이다. 로봇의 위치에 대한 오차가 누적되어 가면서 시간에 따라 추정치는 모호해질 수 밖에 없다. 하지만 상대적으로 잘 알려져 있는 첫번째 landmark의 위치를 확실하게 다시 특정하여 로봇의 위치에 대한 정보를 확정한 순간 연관되어 있는 모든 landmark point에 영향을 주어 정보를 전파할 수 있는 것이다. </p><p>EKF SLAM의 가장 기본 전제는 map의 feature들을 로봇이 한 지점에서 완벽하게 관측이 가능하다는 것이다. 물론 아닌 경우에 대한 연구들도 존재한다.<br>EKF SLAM의 가장 난점은 연산이 quadratic하다는 것이다. 시간 복잡도가 폭팔한다. 이를 해결하기 위해서 EKF의 Extention에 해당하는 연구들이 많이 등장하였는데, 여기서는 다루지 않겠다.</p><h4 id="Particle-Methods"><a href="#Particle-Methods" class="headerlink" title="Particle Methods"></a>Particle Methods</h4><p>두번째 방법은 Particle filter를 사용하는 방법이다. 이는 Monte Carlo Method(1947)에 기인하고 있지만, 최근 20년 근처에 꽤 유행하게 되었다.<br>꽤 추상적으로 먼저 말해보자면, 수 많은 particle들을 모아서 posterior distribution을 추정하는 것이 particle filter 방법이다. </p><p>대표적인 알고리즘으로는 Fast SLAM이 있는데, 이를 간략하게 point-landmark example에 대입해서 생각해 보도록 할 것이다. </p><p>여기서부터는 Fast SLAM의 설명입니다.</p><hr><p>모든 시간대에서 FastSLAM은 $K$개의 다음과 같은 type의 Particle을 가진다.</p><script type="math/tex; mode=display">X_t^{[k]}, \bf{\mu}_{t, 1}^{[k]}, \dots, \bf{\mu}_{t, N}^{[k]}, \bf{\Sigma}_{t, 1}^{[k]}, \dots, \bf{\Sigma}_{t, N}^{[k]}\tag{Definition 13}</script><p>위 정의 13에서 $[k]$는 Sample의 index이다. 위 식에 대한 설명을 하자면 다음과 같다. </p><ul><li>Sample Path $X_t^{[k]}$</li><li>$N$ (Landmark의 point의 개수)개의 2-D Gaussian Distribution의 mean $\bf{\mu}<em>{t, n}^{[k]}$과 Covariance Matrix $\bf{\Sigma}</em>{t, n}^{[k]}$</li></ul><p>위에서 $n$은 landmark point의 index($1 \leq n \leq N$)이다.</p><p>즉, FastSLAM은 $K$개의 Path와 $KN$개의 Gaussian Distribution을 가지고 있는 것이다.<br>이 파라미터들을 초기화 하는 것은 간단하다. 모든 particle의 로봇의 위치를 원점으로 두고 계산하는 것이다.<br>그 다음에 parameter의 update는 다음과 같이 수행한다. </p><ol><li><p>Odometry의 측정값이 도착하면, 새로운 위치 변수가 각 particle들에 대해서 stochastic하게 생성된다. 이때 location particle들을 생성하는 분포는 definition 14와 같다. 여기서 $x^{[k]}_{t-1}$는 이전 location이며 이러한 확률적 sampling 과정은 kinematics가 계산될 수 있는 어떠한 로봇이든 쉽게 수행될 수 있다.</p><script type="math/tex; mode=display"> x^{[k]}_t \approx p(x_t | x^{[k]}_{t-1}, u_t) \tag{Definition 14}</script></li><li><p>measurement $z_t$를 받으면 2가지 일이 일어난다.<br>첫번째로 각 particle들에 대해서 $z_t$의 확률을 계산한다. definition 15 처럼 말이다.<br>이러한 $w_t^{[k]}$를 importance weight라고 한다. (현재 measurement에 대해서 이 particle이 얼마나 중요한지를 나타내는 factor)  </p><script type="math/tex; mode=display">w_t^{[k]} = \mathcal{N}(z_t | x^{[k]}_t, \bf{\mu}_{t, 1}^{[k]}, \bf{\Sigma}_{t, N}^{[k]})\tag{Definition 15}</script></li><li><p>그 다음으로 Fast SLAM은 위에서 만든 importance weight를 가지고 새로운 particle을 뽑는다. 이 과정을 resampling이라고 한다. </p></li><li>그 다음에 새로 뽑은 particle set을 가지고 EKF Filter의 rule에 따라서 parameter를 update 한다. </li></ol><hr><p>꽤 복잡하게 들리지만, 막상 적용하기는 쉽다. </p><ol><li>motion sampling은 이미 역학적인 계산으로 쉽게 얻을 수 있고</li><li>Gaussian measurement를 사용한다면 importance를 계산하는 것도 쉽고,</li><li>parameter를 update 하는 것도 결국 low-dimension에서 이루어지니 쉽다.</li></ol><p>이러한 FastSLAM의 유도 과정에서는 3가지 테크닉을 활용하는데, 간략하게 이름만 적어 보도록 하겠다.</p><ol><li>Rao–Blackwellization</li><li>conditional independence</li><li>resampling</li></ol><p>이 3가지 과정을 중점적으로 공부하면서 차후에 FastSLAM은 더 자세히 포스트로 정리해서 올려둘 것이다. </p><p>이러한 FastSLAM은 2가지 문제점이 있다.</p><ol><li>map을 구성하기 위한 sample의 수가 <em>적당히</em>(educated guess) 지정되어야 한다</li><li>이전에 mapping된 지역에 재방문 하는 일이 많은 nested loop의 경우에는 particle depletion이 발생할 수 있다.</li></ol><p>이를 해결하기 위해서 또 많은 연구들이 등장했는데, 여기서는 다루지 않도록 하겠다.</p><h4 id="Graph-Based-Optimization"><a href="#Graph-Based-Optimization" class="headerlink" title="Graph-Based Optimization"></a>Graph-Based Optimization</h4><p>이번에 다룰 내용은 SLAM 문제를 풀 수 있는 3번째 방법인 Graph Based Optimization이다. 이 방법은 non-linear sparse optimization으로 SLAM을 해결한다. 이 방법을 직관적으로 설명하자면 다음과 같다.</p><ol><li>Landmark와 robot의 location은 graph의 node라고 생각할 수 있다.</li><li>각각의 연속된 location pair $x_{t-1}, x_t$는 edge로써 연결되어 있다.</li><li>해당 edge는 odometry $u_t$로 부터 나오는 정보를 표현한다.</li><li>이때, 해당 edge는 시간 $t$에서의 location $x_t$에서 landmark $m_i$를 감지했을때 발생한다.</li></ol><p>이러한 Graph의 Edge는 Soft constraints이다. 이러한 Constraints를 만족시키는 것으로 map과 robot의 full path를 추정할 수 있다. 이 과정은 밑의 그림으로 자세히 설명할 수 있다. </p><p align="center"><img src="https://kimh060612.github.io/img/SLAMGraphRep.png" width="100%"></p><p>그림을 보면 robot이 이동하면서 위치 $x_t$애서 landmark $m_i$를 감지할때마다 edge가 생기게 되고, 그것을 adjacent matrix로 표현해 나갈 수 있다. 이러한 과정에서 위 matrix는 sparse한 상태로 남게 된다. 최악의 경우에는 node에 비해 constraints의 갯수가 시간과 node의 개수에 대해서 linear해질 수도 있다. </p><p>정보 이론적으로 생각해서, 우리가 이러한 SLAM문제를 푸는 것은 이 그래프의 엔트로피를 최소화 하는 것으로 생각해 볼 수 있다. 그 관점에서 우리는 graph를 다루기 이전에 지난번에 정의한 posterior probability에 log를 씌워보자.</p><script type="math/tex; mode=display">\ln p(X_T,m |Z_T,U_t)\tag{Definition 16}</script><p>우리는 각 location과 mapping의 sensing 사건이 독립적이라고 가정했을때 다음과 같이 수식을 전개할 수 있다.</p><script type="math/tex; mode=display">\ln p(X_T,m |Z_T,U_t) = \text{const} +  \sum_t \log p(x_t | x_{t - 1}, u_t) + \sum_t  \log p(z_t | x_t, m)\tag{equation 1}</script><p>엔트로피를 최소화 한다는 것은 definition 16을 최대화 하는 것과 같다.</p><script type="math/tex; mode=display">X_T^*, m^* = \argmax_{X_t, m} \ln p(X_T,m |Z_T,U_t)\tag{equation 2}</script><p>equation 1을 point-landmark example에서 Gaussian 추정을 적용하여 다음과 같은 quadratic form으로 표현할 수 있다. </p><script type="math/tex; mode=display">\ln p(X_T,m |Z_T,U_t) = \text{const} + \\\sum_t [x_t - g(x_{t - 1}, u_t)]^TR_t^{-1}[x_t - g(x_{t - 1}, u_t)] + \\ \sum_t  [z_t - h(x_t, m)]^TQ_t^{-1}[z_t - h(x_t, m)]\tag{equation 3}</script><p>위 equation 3를 최적화 하는 것이 SLAM문제를 푸는 것으로 연결된다. 흔한 선택지로는 sparse Cholesky &amp; QR decomposition이고, Gradient Descent나 conjugate gradient 방법도 좋은 선택지이다.</p><p>Graphical SLAM은 EKF보다 훨씬 더 넓은 map으로 scale을 넓힐 수 있다는 것이 장점이다. 몇몇 추정을 더해야하기는 하지만, EKF에 비하면 Graph method의 update에 필요한 time-complexity와 space-complexity는 각각 constant/linear하다.</p><h4 id="Relation-of-Paradigms"><a href="#Relation-of-Paradigms" class="headerlink" title="Relation of Paradigms"></a>Relation of Paradigms</h4><ul><li>EKF SLAM: quadratic한 Time/Space Complexity로 인한 map의 scaling에 한계가 있다 + linearization 과정에서 mapping이 잘못될 수 있다.</li><li>Particle filter: EKF SLAM에 있던 계산 복잡도의 한계를 해결했으나, map이 복잡해질 수록 필요한 particle의 수가 기하 급수적으로 늘어난다.</li><li>Graph-based Optimization: 시간복잡도와 공간 복잡도를 혁명적으로 해결함으로써 가장 큰 mapping을 그릴 수 있는 알고리즘이 되었다. </li></ul><h3 id="Visual-RGB-D-SLAM"><a href="#Visual-RGB-D-SLAM" class="headerlink" title="Visual RGB-D SLAM"></a>Visual RGB-D SLAM</h3><p>최근에 SLAM의 중요한 연구 화제는 단영 Visual SLAM이다. Visual SLAM은 RGB-D Sensor(Kinect)나 Camera를 활용하여 주변 map을 생성하거나 로봇의 6-DOF Pose를 추정하는 알고리즘이다. Visual SLAM은 appearance information을 활용해서 loop-closing같은 어려운 문제를 해결할 수 있는 단초를 제공하기도 한다. 이러한 Visual SLAM은 최근까지도 Video Stream을 처리할 HW 성능이 부족해서 난항을 겪고 있었다.<br>Davison이 이러한 연구에 있어서 선구자적인 역할을 하면서 해당 분야가 각광을 받게 되었다.</p><p>Davison과 다른 연구자들에 의하면 Visual SLAM은 camera로 얻어지는 measurement가 odometry 정보를 제공할 수 있게 만드는 것이라고 한다. 이러한 연구들의 종파들 중에는 Feature detection, Feature matching, outlier rejection, constraint estimation, trajectory optimization 등이 있다.</p><p>그리고 Visual Information은 loop-closing을 위한 정보 또한 엄청나게 많이 제공을 하는데, 대표적인 예시가 바로 visual object detection을 이용한 location recognition이다. </p><p>또한, robust한 visual SLAM의 이정표를 만든 연구는 PTAM이다. 이 연구는 keyframe mapping과 localization을 별도릐 thread로 나눠서 계산을 진행함으로써 online processing에서의 robustness와 성능을 동시에 높일 수 있었다. 여기서의 keyframe은 현재 Visual SLAM에서 복잡도를 줄일 수 있는 방법으로써 주류를 이루고 있다.<br>다른 방법으로는 view-based mapping system이라고 large-scale에서 pose graph optimization을 기반으로 visual mapping을 진행하는 방법도 있다.</p><p>다른 계파로는, RGB-D sensor(Kinect)를 이용해서 mapping과 localization을 동시에 진행하는 연구들도 있다. 그리고 object의 surface를 스캔하는 연구도 있다. 이러한 연구는 sensor의 pose와 surface point의 위치를 최적화 하는 연구이다.</p><p>앞으로는 Dense processing method라고 해서 GPU를 활용하여 조금 더 성능을 fine tuning하는 것도 있다.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/SLAM/">SLAM</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Robotics/">Robotics</category>
      
      <category domain="https://kimh060612.github.io/tags/SLAM/">SLAM</category>
      
      
      <comments>https://kimh060612.github.io/2022/06/02/SLAM-Survey/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>interview</title>
      <link>https://kimh060612.github.io/2022/04/23/interview/</link>
      <guid>https://kimh060612.github.io/2022/04/23/interview/</guid>
      <pubDate>Sat, 23 Apr 2022 08:54:07 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;해당-포스트는-필자가-직무-Interview를-위해-스터디한-내용을-적어두는-곳입니다-틀린-내용이-있을-수-있습니다&quot;&gt;&lt;a href=&quot;#해당-포스트는-필자가-직무-Interview를-위해-스터디한-내용을-적어두는-곳입니다-틀린-내용이-있</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="해당-포스트는-필자가-직무-Interview를-위해-스터디한-내용을-적어두는-곳입니다-틀린-내용이-있을-수-있습니다"><a href="#해당-포스트는-필자가-직무-Interview를-위해-스터디한-내용을-적어두는-곳입니다-틀린-내용이-있을-수-있습니다" class="headerlink" title="해당 포스트는 필자가 직무 Interview를 위해 스터디한 내용을 적어두는 곳입니다. 틀린 내용이 있을 수 있습니다."></a>해당 포스트는 필자가 직무 Interview를 위해 스터디한 내용을 적어두는 곳입니다. 틀린 내용이 있을 수 있습니다.</h2><h2 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h2><ul><li>DS &amp; Algorithm  <ul><li>Linked List / Array <ul><li>Linked List for Array</li><li>Linked List for Tree</li></ul></li><li>Stack  </li><li>Queue    </li><li>Sort  <ul><li>Stable / Unstable Sort </li><li>Bubble Sort</li><li>Insert Sort</li><li>Selection Sort</li><li>Quick Sort</li><li>Merge Sort</li><li>Count Sort</li><li>Radix Sort</li></ul></li><li>Tree<ul><li>Binary Tree (Vanila, Full, Complete)</li><li>Binary Search Tree  </li><li>Red Black Tree  </li><li>B Tree  </li><li>B+ Tree</li></ul></li><li>Heap  </li><li>Hash Table  </li><li>Graph  <ul><li>Graph Travarsal  </li><li>Minimum Spanning Tree  <ul><li>Kruskal algorithm  </li><li>Prim algorithm  </li></ul></li></ul></li></ul></li><li>Operating System  <ul><li>Process    </li><li>Thread  </li><li>Multi-processing / Multi-Threading  </li><li>Scheduling  </li><li>System Call  </li><li>Synchronization  </li><li>Memory<ul><li>Memory Management Strategy</li><li>Locality of Cache</li></ul></li></ul></li><li>Database  <ul><li>SQL vs NoSQL    </li><li>Index  </li><li>Transaction  </li><li>Lock    </li><li>deadlock  </li><li>Redis  </li><li>High Avaliablity Strategy  </li><li>ORM  </li></ul></li><li>Web  <ul><li>TCP / UDP</li><li>TCP 3way/4way hand shake  </li><li>TLS/SSL  </li><li>HTTP 1.1/2.0  </li><li>HTTP Cache  </li><li>RESTful API    </li><li>Sync / Async / Blocking / Non-Blocking    </li><li>Blocking IO / Non-Blocking IO    </li></ul></li><li>Javascript/Nodejs    <ul><li>Javascript      </li><li>NodeJS </li></ul></li><li>Object Oriented Programming Basic<ul><li>Properties of OOP</li><li>5 Principle  </li></ul></li></ul><h2 id="DS-amp-Algorithm"><a href="#DS-amp-Algorithm" class="headerlink" title="DS &amp; Algorithm"></a>DS &amp; Algorithm</h2><h3 id="Linked-List-Array"><a href="#Linked-List-Array" class="headerlink" title="Linked List / Array"></a>Linked List / Array</h3><p>먼저 Array에 대해서 설명을 해보자면 Array는 논리적 저장 순서와 물리적 저장 순서가 일치한다. 따라서 index를 통해서 해당 element에 접근이 가능하다. 그렇기에 찾고자 하는 원소의 index를 알고 있으면 $O(1)$의 시간 복잡도로 해당 element에 접근할 수 있다. 즉 random access가 가능하다는  장점이 있다. </p><p>하지만 insert와 delete 연산의 경우에는 이야기가 다르다. 어떠한 index의 element를 삽입/삭제 하는 경우에는 그 뒤의 원소들을 한칸씩 뒤/앞으로 shift해줘야 한다. 이 경우에 시간 복잡도가 O(n)이 된다.</p><p>Linked List는 이와는 다르다. 각각의 원소들은 자기 자신 다음에 어떤 원소인지만을 기억하고 있다. 따라서 이 부분만 다른 값으로 바꿔주면 삭제와 삽입을 O(1) 만에 해결할 수 있는 것이다.</p><p>하지만 Linked List 역시 한 가지 문제가 있다. 원하는 위치에 삽입을 하고자 하면 원하는 위치를 Search 과정에 있어서 첫번째 원소부터 다 확인해봐야 한다는 것이다. Array 와는 달리 논리적 저장 순서와 물리적 저장 순서가 일치하지 않기 때문이다. 이것은 일단 삽입하고 정렬하는 것과 마찬가지이다. 이 과정 때문에, 어떠한 원소를 삭제 또는 추가하고자 했을 때, 그 원소를 찾기 위해서 O(n)의 시간이 추가적으로 발생하게 된다.</p><p>결국 linked list 자료구조는 search 에도 O(n)의 time complexity 를 갖고, 삽입, 삭제에 대해서도 O(n)의 time complexity 를 갖는다. 그렇다고 해서 아주 쓸모없는 자료구조는 아니기에, 우리가 학습하는 것이다. 이 Linked List 는 Tree 구조의 근간이 되는 자료구조이며, Tree 에서 사용되었을 때 그 유용성이 드러난다.</p><h3 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h3><p>선형 자료구조의 일종으로 Last In First Out (LIFO). 즉, 나중에 들어간 원소가 먼저 나온다. 이것은 Stack 의 가장 큰 특징이다. 차곡차곡 쌓이는 구조로 먼저 Stack 에 들어가게 된 원소는 맨 바닥에 깔리게 된다. 그렇기 때문에 늦게 들어간 녀석들은 그 위에 쌓이게 되고 호출 시 가장 위에 있는 녀석이 호출되는 구조이다.</p><h3 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h3><p>선형 자료구조의 일종으로 First In First Out (FIFO). 즉, 먼저 들어간 놈이 먼저 나온다. Stack 과는 반대로 먼저 들어간 놈이 맨 앞에서 대기하고 있다가 먼저 나오게 되는 구조이다. 이를 구현하고 있는 Priority queue등을 사용할 수 있다.</p><h3 id="Sort"><a href="#Sort" class="headerlink" title="Sort"></a>Sort</h3><h4 id="Stable-Unstable-Sort"><a href="#Stable-Unstable-Sort" class="headerlink" title="Stable / Unstable Sort"></a>Stable / Unstable Sort</h4><p>Stable Sort와 Unstable Sort의 차이는 <em>같은 값의 숫자더라도 그 상대적인 위치가 유지 되느냐 아니냐</em>이다.<br>예를 들어서 다음과 같이 “3 <em>3</em> 4 2 1 5 <strong>3</strong>“가 있다고 해보자.<br>만약 sorting된 결과가 다음과 같으면 stable sort이다.<br>“1 2 3 <em>3</em> <strong>3</strong> 4 5”<br>이 이외의 결과는 전부 unstable sort이다. </p><h4 id="Bubble-Sort"><a href="#Bubble-Sort" class="headerlink" title="Bubble Sort"></a>Bubble Sort</h4><p>서로 인접한 두 원소를 검사하여 정렬하는 알고리즘<br>==&gt; 인접한 2개의 레코드를 비교하여 크기가 순서대로 되어 있지 않으면 서로 교환한다.</p><p>기본적으로 $O(n^2)$의 시간 복잡도를 가진다. </p><h4 id="Insert-Sort"><a href="#Insert-Sort" class="headerlink" title="Insert Sort"></a>Insert Sort</h4><p>자료 배열의 모든 요소를 앞에서부터 차례대로 이미 정렬된 배열 부분과 비교 하여, 자신의 위치를 찾아 삽입함으로써 정렬을 완성하는 알고리즘</p><p>기본적으로 $O(n^2)$의 시간 복잡도를 가진다. </p><h4 id="Selection-Sort"><a href="#Selection-Sort" class="headerlink" title="Selection Sort"></a>Selection Sort</h4><p>해당 순서에 원소를 넣을 위치는 이미 정해져 있고, 어떤 원소를 넣을지 선택하는 알고리즘<br>==&gt; 첫 번째 순서에는 첫 번째 위치에 가장 최솟값을 넣는다.<br>==&gt; 두 번째 순서에는 두 번째 위치에 남은 값 중에서의 최솟값을 넣는다.  </p><p>기본적으로 $O(n^2)$의 시간 복잡도를 가진다. </p><h4 id="Quick-Sort"><a href="#Quick-Sort" class="headerlink" title="Quick Sort"></a>Quick Sort</h4><p>분할 정복 알고리즘의 하나로 평균적으로 $O(n\log_2 n)$의 시간 복잡도를 가진다. 이는 불안정 정렬에 속한다.<br>과정은 다음과 같다. </p><ol><li>리스트 안의 한 요소를 선택한다. 이를 pivot이라고 하겠다.</li><li>pivot을 기준으로 그보다 작은 요소를 전부 pivot의 왼쪽으로, 큰 요소는 오른쪽으로 옮긴다. </li><li>pivot을 제외한 왼쪽 리스트와 오른쪽 리스트를 동일한 방법으로 재 정렬한다. </li><li>이를 부분 리스트들이 더 이상 분할 불가능 할때까지 반복한다.</li></ol><p>최악의 경우에는 시간 복잡도가 $O(n^2)$이 되며 이 경우는 대표적으로 리스트가 전부 정렬 되어 있는 경우이다. </p><p>실질적으로는 pivot을 중간값으로 잡아서 알고리즘을 최적화 하는 방법도 있다. 정말 아무 값이나 pivot으로 잡아버리면 리스트가 불균등하게 분할되어 시간이 오래 걸리는 경우가 생긴다. </p><p>이를 방지하기 위해서 C++에서는 quick sort와 heap sort를 합친 intro sort를 사용하고 있다. 이는 기본적으로 quick sort와 동일하게 동작하지만 재귀 호출의 깊이가 일정 수준 이상으로 깊어지면 그 다음부터는 쪼개진 list를 heap sort로 정렬하여 시간 복잡도를 개선하였다. (구체적으로는 재귀함수의 깊이가 $1.5\log_2 N$보다 깊어지면 heap sort를 사용하여 정렬을 진행한다.)</p><h4 id="Merge-Sort"><a href="#Merge-Sort" class="headerlink" title="Merge Sort"></a>Merge Sort</h4><p>분할 정복 알고리즘의 하나로 $O(n\log_2 n)$의 시간 복잡도를 가진다. quick sort와 달리 안정 정렬에 속한다.<br>과정은 다음과 같다.</p><ol><li>리스트의 절반의 길이로 리스트를 2개로 분할한다.</li><li>계속 이렇게 잘라 나가면서 각 부분 리스트들을 재귀적으로 합병 정렬을 이용해서 정렬한다.</li><li>두 부분 리스트들을 하나의 정렬된 리스트들로 병합한다.</li></ol><p>단점으로는 별도의 메모리 공간이 필요하다. 리스트를 병합하는 과정에서 추가적인 메모리 공간에 이를 덧씌우는 작업을 진행하는데, 이 과정에서 컴퓨팅 resource를 잡아 먹으므로 실제로는 quick sort가 최선의 경우에서는 더 좋은 성능을 내고 있다. </p><h4 id="Count-Sort"><a href="#Count-Sort" class="headerlink" title="Count Sort"></a>Count Sort</h4><p>등장하는 숫자의 개수를 counting 하면서 정렬을 하는 알고리즘이다.<br>정렬 자체는 시간복잡도가 $O(N)$이지만, 공간 복잡도가 리스트의 원소에 따라 달라진다. 게다가, 리스트의 원소가 크면 클수록 무의미한 순회를 반복하기 때문에 비효율성이 발생되는 정렬 방법이다. </p><h4 id="Radix-Sort"><a href="#Radix-Sort" class="headerlink" title="Radix Sort"></a>Radix Sort</h4><p>기수 정렬은 낮은 자리수부터 정렬해 가는 정렬이다. 비교 연산을 하지 않으며 시간 복잡도가 $O(dN)$으로 빠른 정렬중에 하나이다. 하지만 데이터의 자리수에 따라서 정렬 시간 복잡도에 영향을 미치며, 추가적인 Queue를 사용하며 메모리 공간을 차지 한다는 점이 단점이다. </p><h3 id="Tree"><a href="#Tree" class="headerlink" title="Tree"></a>Tree</h3><p>Tree는 기본적으로 Stack이나 Queue와는 달리 계층적 구조를 표현하는 비선형 자료구조이다. Tree의 명확한 정의는 “Cycle이 없는 Graph”이다. </p><p>다음은 기본적인 Tree에서의 용어는 Graph에서의 그것과 큰 차이는 없지만 몇가지 추가되는 것이 있다.</p><ol><li>Root Node: 트리 구조에서 최상위 노드에 있는 것을 의미한다.</li><li>Leaf Node: 하위에 다른 노드들이 연결되어 있지 않은 Node를 의미한다.</li><li>Internal Node: 단말 노드를 제외한 모든 노드로 Root Node를 포함한다.</li></ol><h4 id="Binary-Tree-Vanila-Full-Complete"><a href="#Binary-Tree-Vanila-Full-Complete" class="headerlink" title="Binary Tree (Vanila, Full, Complete)"></a>Binary Tree (Vanila, Full, Complete)</h4><p>우선 기본적인 Binary Tree의 정의부터 살펴보도록 하겠다.<br>Root Node를 중심으로 2개의 Sub Tree로 나뉘는 Tree를 뜻한다. 이때 해당 Sub tree 들도 Binary Tree의 조건을 만족해야 한다.<br>이 재귀적인 정의가 성립하려면 공집합도 Binary tree이고 Node가 하나인 것도 Binary Tree이다.   </p><p>이러한 Binary Tree는 그 형태에 따라서 3가지 종류로 나뉜다.</p><ol><li>Perfect Binary Tree: 모든 level이 꽉 찬 Tree   </li><li>Complete Binary Tree: 마지막 level 을 제외한 나머지 level 에 node 들이 가득 차있고, 마지막 level 에서 node 는 가장 왼쪽 부터 채워지는 형태가 Complete Binary Tree 이다.   </li><li>Full Binary Tree: 모든 노드가 0개 혹은 2개의 children 을 가지고 있는 Tree</li></ol><h4 id="Binary-Search-Tree"><a href="#Binary-Search-Tree" class="headerlink" title="Binary Search Tree"></a>Binary Search Tree</h4><p>Binary Search Tree는 다음과 같이 정의된 Tree를 말한다.</p><ol><li>BST의 Node에 저장된 Key는 유일하다</li><li>부모의 Key는 왼쪽 자식 Node의 Key보다 크다.</li><li>부모의 Key는 오른쪽 자식 Node의 Key보다 작다.</li><li>왼쪽과 오른쪽 Sub Tree도 BST이다.</li></ol><p>BST의 특장점은 트리 위에서 특정 Key를 검색하는 속도가 $O(N\log_2 N)$이라는 것이다.<br>하지만 만약 한쪽으로만 계속 데이터가 저장되어 Skewed Tree가 된다면 성능에 영향을 미칠 수 있다. 대표적으로 한쪽으로만 데이터가 계속 저장되면 탐색에 필요한 시간 복잡도는 $O(N)$이 된다.</p><h4 id="Red-Black-Tree"><a href="#Red-Black-Tree" class="headerlink" title="Red Black Tree"></a>Red Black Tree</h4><p>Red Black Tree는 BST에서 Insert/Delete 연산을 수행할때의 시간 복잡도를 줄이기 위해서 나타난 자료구조이다. 동일한 Node의 개수일때, Depth를 최소화하여 시간 복잡도를 줄이는 것이 핵심 Idea이다. </p><p>RBT의 명확한 정의는 다음과 같다.</p><ol><li>BST의 정의를 만족해야 한다.</li><li>각 Node는 red 또는 Black의 색을 가진다.</li><li>Root Node는 무조건 Black이다.</li><li>각 Leaf Node(NULL)는 무조건 Black이다.</li><li>어떤 Node의 색이 Red라면 두 Children의 색은 모두 Black이다.</li><li>각 Node에 대해서 Node로 부터 descendant leaves 까지의 단순 경로는 모두 같은 수의 black nodes 들을 포함하고 있다. </li></ol><p>이러한 RBT는 다음과 같은 특징을 가진다.</p><ol><li>Binary Search Tree 이므로 BST 의 특징을 모두 갖는다.</li><li>Root node 부터 leaf node 까지의 모든 경로 중 최소 경로와 최대 경로의 크기 비율은 2 보다 크지 않다. 이러한 상태를 balanced 상태라고 한다.</li><li>노드의 child 가 없을 경우 child 를 가리키는 포인터는 NIL 값을 저장한다. 이러한 NIL 들을 leaf node 로 간주한다.</li></ol><p>그리고 RBT의 삽입과 삭제 연산은 다음과 같이 수행된다.</p><ul><li><p>삽입</p><p>  BST의 특성을 유지하면서 Node를 삽입한다. 그리고 삽인된 Node의 색은 Red로 지정한다.<br>  삽입 결과가 RBT의 특성에 위반될 경우에는 Node의 색을 조정하고 Black-Height가 같아야 한다는 정의에 위반되면 rotation을 통해서 Height를 조정한다.<br>  이러한 과정을 통해서 RBT는 동일한 Height에 존재하는 internal node들의 Black-hieght가 같아지게 되고 최소 경로와 최대 경로의 크기 비율이 2 미만으로 유지된다. </p></li><li><p>삭제</p><p>  삭제도 삽입과 마찬가지로 BST 의 특성을 유지하면서 해당 노드를 삭제한다.<br>  삭제될 노드의 child 의 개수에 따라 rotation 방법이 달라지게 된다.<br>  그리고 만약 지워진 노드의 색깔이 Black 이라면 Black-Height 가 1 감소한 경로에 black node 가 1 개 추가되도록 rotation 하고 노드의 색깔을 조정한다.<br>  지워진 노드의 색깔이 red 라면 Violation 이 발생하지 않으므로 RBT 가 그대로 유지된다.</p></li></ul><h4 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B Tree"></a>B Tree</h4><p>B Tree는 이진트리에서 발전되어 모든 Leaf Node들이 같은 level을 가질 수 있도록 자동으로 balancing이 되는 Tree이다. 정렬 순서를 보장하고 Multi Level Indexing을 통한 빠른 검색이 가능하다.  </p><p>최대 $M$개의 자식을 가질 수 있는 B Tree의 정의는 다음과 같다.  </p><ol><li>Node에 최대 $M$개부터 $\frac{M}{2}$개 까지의 자식을 가질 수 있다.</li><li>Node에 최대 $M-1$개부터 $[\frac{M}{2}] - 1$개의 Key가 포함될 수 있다.</li><li>Node의 Key가 $x$개라면 자식의 수는 $x+1$개이다.</li><li>최소 차수는 자식수의 하한값을 의미하며 최소 차수가 $t$라면 $M = 2t-1$을 만족한다.</li><li>BST 처럼 각 Key들의 왼쪽 자식들은 항상 부모보다 작은 값을, 오른쪽 자식들은 부모보다 큰 값을 가진다.</li></ol><h4 id="B-Tree-1"><a href="#B-Tree-1" class="headerlink" title="B+ Tree"></a>B+ Tree</h4><p>B+ Tree는 B Tree를 변형한 자료구조이다. 이는 실제 여러 DB에서 Index를 저장할때 사용되고 있다. </p><p>B+ Tree는 B Tree와 다음이 다르다.</p><ol><li>모든 Key, Data가 Leaf Node에 모여 있다. B Tree는 Leaf Node가 아닌 각자 Key 마다 data를 가진다면 B+ Tree는 Leaf Node에 모든 data를 가진다. </li><li>모든 Leaf node가 Linked List의 형태를 띄고 있다. 따라서 B+ Tree에서는 Root Node에서부터 검색을 하는 것이 아닌, Leaf Node에서 선형 검사를 할 수 있어서 시간 복잡도가 굉장히 줄어든다.</li></ol><h3 id="Heap"><a href="#Heap" class="headerlink" title="Heap"></a>Heap</h3><p>Heap은 특정한 규칙을 만족시키는 Complete Binary Tree의 일종이다. Heap에는 Max Heap과 Min Heap 2가지 종류가 있다. </p><p>Max Heap이란 각 Node의 값이 해당 Children의 값보다 크거나 같은 Complete Binary Tree를 말한다.<br>그리고 Min Heap은 그것의 반대이다.   </p><p>Max Heap에서는 Root node 에 있는 값이 제일 크므로, 최대값을 찾는데 소요되는 연산의 time complexity 이 $O(1)$이다. 그리고 complete binary tree이기 때문에 배열을 사용하여 효율적으로 관리할 수 있다. (즉, random access 가 가능하다.) 또한 Min Heap도 최소값이라는 점만 다르고 나머지는 동일하다.</p><h3 id="Hash-Table"><a href="#Hash-Table" class="headerlink" title="Hash Table"></a>Hash Table</h3><p>Hash의 정의는 다음과 같다.</p><blockquote><p>내부적으로 Array를 사용하며 특수한 알고리즘(Hash function)을 사용하여 데이터와 연관된 고유한 숫자를 만들어낸 후에 이를 Index로 사용하는 자료구조.</p></blockquote><p>이러한 특수한 알고리즘 덕분에 collision이 발생하지 않는다면 $O(1)$의 시간 복잡도로 데이터를 찾을 수 있다. </p><p>하지만 어설픈 Hash function을 사용하면 당연히 collision이 자주 발생하게 된다.<br>따라서 좋은 Hash Function을 사용해서 Hash Table을 구성해야 한다. </p><p>Hash function을 무조건 1:1로 만드는 것보다 Collision을 최소화하는 방향으로 설계하고 발생하는 Collision에 대비해서 어떻게 대응할 것인가가 훨씬 더 중요하다. 1:1 대응이 되도록 만드는 것이 거의 불가능하기도 하지만 그런 hash function를 만들어봤자 그건 array 와 다를바 없고 메모리를 너무 차지하게 된다.</p><p>이제는 Conflict를 해결하는 방법을 알아보도록 하겠다.</p><ol><li><p>Open Address 방식</p><p> Hash에서 Collision이 발생하면 다른 Hash Bucket에 해당 자료를 삽입하는 방식이다.<br> 여기서 Hash Bucket은 Hash Table에 데이터를 저장하는 하나의 공간이다.   </p><p> 이렇게 되면 원하는 데이터를 $O(1)$에 못 찾을 수도 있다. 그럴 경우에 원하는 데이터를 찾아내는 여러가지 방법이 있다. 대표적인 예시로 다음과 같은 것들이 있다.</p><ul><li>Linear Probing: 순차적으로 탐색하며 비어있는 버킷을 찾을 때까지 계속 진행된다.</li><li>Quadratic probing: 2 차 함수를 이용해 탐색할 위치를 찾는다.</li><li>Double hashing probing: 하나의 해쉬 함수에서 충돌이 발생하면 2 차 해쉬 함수를 이용해 새로운 주소를 할당한다. 위 두 가지 방법에 비해 많은 연산량을 요구하게 된다.</li></ul></li><li><p>Separate Chaining 방식</p><p> 일반적으로 Open Addressing은 Separate Chaining 방식보다 느리다. Separate Chaining 방식은 Hash Collision이 발생하지 않도록 보조 함수를 통해 조정할 수 있다면 Worst Case에 가까워지는 빈도를 줄일 수 있다.</p><p> 이러한 Separate Chaining 방식은 2가지 구현 방식이 있다. </p><ol><li>Linked List를 활용: 각각의 버킷(bucket)들을 연결리스트(Linked List)로 만들어 Collision 이 발생하면 해당 bucket 의 list 에 추가하는 방식이다. </li><li>Red Black Tree를 이용: 연결 리스트 대신 트리를 사용하는 방식이다. 연결 리스트를 사용할 것인가와 트리를 사용할 것인가에 대한 기준은 하나의 해시 버킷에 할당된 key-value 쌍의 개수이다. 데이터의 개수가 적다면 링크드 리스트를 사용하는 것이 맞다.</li></ol></li></ol><h3 id="Graph"><a href="#Graph" class="headerlink" title="Graph"></a>Graph</h3><p>Graph는 크게 Undirected Graph와 Directed Graph로 나뉜다. 말 그대로 간선 연결 관계에서 방향성이 없는 것을 전자, 방향성을 가진 것을 후자라고 한다.<br>이때, Degree라는 개념이 등장한다. 이는 Undirected Graph 에서 각 정점(Vertex)에 연결된 Edge 의 개수를 Degree 라 한다.<br>그리고 Directed Graph 에서는 간선에 방향성이 존재하기 때문에 Degree 가 두 개로 나뉘게 된다. 각 정점으로부터 나가는 간선의 개수를 Outdegree 라 하고, 들어오는 간선의 개수를 Indegree 라 한다.</p><p>이러한 Graph를 구현하는 방법은 2가지가 있다. </p><ul><li>인접 행렬을 사용하는 방법: 해당하는 위치의 value 값을 통해서 vertex 간의 연결 관계를 $O(1)$ 으로 파악할 수 있다. Edge 개수와는 무관하게 $V^2$ 의 Space Complexity 를 갖는다. Dense graph 를 표현할 때 적절할 방법이다.</li><li>인접 리스트를 사용하는 방법: vertex 의 adjacent list 를 확인해봐야 하므로 vertex 간 연결되어있는지 확인하는데 오래 걸린다. Space Complexity 는 $O(E + V)$이다. Sparse graph 를 표현하는데 적당한 방법이다.</li></ul><h4 id="Graph-Travarsal"><a href="#Graph-Travarsal" class="headerlink" title="Graph Travarsal"></a>Graph Travarsal</h4><p>그래프는 정점의 구성 뿐만 아니라 간선의 연결에도 규칙이 존재하지 않기 때문에 탐색이 복잡하다. 따라서 그래프의 모든 정점을 탐색하기 위한 방법은 다음의 두 가지 알고리즘을 기반으로 한다.</p><ol><li><p>DFS (Depth First Search)</p><p> 그래프 상에서 존재하는 임의의 한 정점으로부터 연결되어 있는 한 정점으로만 나아가는 방법을 우선하여 탐색한다. Stack을 사용하여 구현할 수 있고 시간 복잡도는 $O(V + E)$ 이다.</p></li><li><p>BFS (Breath First Search)</p><p> 그래프 상에 존재하는 임의의 한 정점으로부터 연결되어 있는 모든 정점으로 나아간다. Tree 에서의 Level Order Traversal 형식으로 진행되는 것이다. BFS 에서는 자료구조로 Queue 를 사용한다. 시간 복잡도는 $O(V + E)$이다. 이때 간선이 가중치를 가지고 있지 않으면 (전부 동일한 가중치를 가지고 있다면) BFS로 찾은 경로가 최단 경로이다.</p></li></ol><h4 id="Minimum-Spanning-Tree"><a href="#Minimum-Spanning-Tree" class="headerlink" title="Minimum Spanning Tree"></a>Minimum Spanning Tree</h4><p>그래프 G 의 spanning tree 중 edge weight 의 합이 최소인 spanning tree를 말한다. 여기서 말하는 spanning tree란 그래프 G 의 모든 vertex 가 cycle 이 없이 연결된 형태를 말한다.</p><p>특정 Graph에서 MST를 찾아내려면 다음 2가지 알고리즘을 사용하면 된다.</p><ol><li><p>Kruskal Algorithm</p><p> 초기화 작업으로 edge 없이 vertex 들만으로 그래프를 구성한다. 그리고 weight 가 제일 작은 edge 부터 검토한다. 그러기 위해선 Edge Set 을 non-decreasing 으로 sorting 해야 한다. 그리고 가장 작은 weight 에 해당하는 edge 를 추가하는데 추가할 때 그래프에 cycle 이 생기지 않는 경우에만 추가한다. spanning tree 가 완성되면 모든 vertex 들이 연결된 상태로 종료가 되고 완성될 수 없는 그래프에 대해서는 모든 edge 에 대해 판단이 이루어지면 종료된다.</p><p> 이때 Cycle의 여부는 Union find 알고리즘으로 판단한다. </p><p> 시간 복잡도: $O(E \log E)$</p></li><li><p>Prim Algorithm</p><p> 초기화 과정에서 한 개의 vertex 로 이루어진 초기 그래프 A 를 구성한다. 그리고나서 그래프 A 내부에 있는 vertex 로부터 외부에 있는 vertex 사이의 edge 를 연결하는데 그 중 가장 작은 weight 의 edge 를 통해 연결되는 vertex 를 추가한다. 어떤 vertex 건 간에 상관없이 edge 의 weight 를 기준으로 연결하는 것이다. 이렇게 연결된 vertex 는 그래프 A 에 포함된다. 위 과정을 반복하고 모든 vertex 들이 연결되면 종료한다.</p><p> 시간 복잡도: $O(E \log V)$</p></li></ol><h2 id="Operating-System"><a href="#Operating-System" class="headerlink" title="Operating System"></a>Operating System</h2><h3 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h3><blockquote><p>Process는 실행중인 프로그램으로 디스크로부터 메모리에 적재되어 CPU를 할당받을 수 있는 것을 의미한다. </p></blockquote><p>Process는 OS로 부터 Memory, File, Address Space등을 할당 받으며 이들을 총칭하여 process라고 부른다.<br>OS는 Process를 관리하기 위해 특정 자료구조로 Process의 정보를 저장하고 있는데, 이것이 Process Control Block (PCB)이다. OS는 Process의 생성과 동시에 고유의 PCB를 생성하고 관리한다.  </p><p>(중요도 낮음)<br>PCB에는 다음과 같은 정보들이 저장된다.</p><ul><li>Process ID</li><li>Process 상태</li><li>Program Counter</li><li>CPU Register</li><li>CPU Scheduling 정보</li><li>Memory 관리 정보</li><li>I/O 상태 정보</li><li>Accounting 정보</li></ul><h3 id="Thread"><a href="#Thread" class="headerlink" title="Thread"></a>Thread</h3><blockquote><p>Thread는 Process의 내부에서 각자의 주소 공간이나 자원을 공유하는 하나의 실행 단위이다.</p></blockquote><p>Thread는 Thread ID, Program Counter, Register 집합, 그리고 Stack으로 구성된다. 같은 Process에 속한 Thread들 끼리는 코드, 데이터 섹션, 그리고 열린 파일이나 신호와 같은 OS의 자원을 공유한다.   </p><h3 id="Multi-processing-Multi-Threading"><a href="#Multi-processing-Multi-Threading" class="headerlink" title="Multi-processing / Multi-Threading"></a>Multi-processing / Multi-Threading</h3><ul><li>Multi-Threading의 장점</li></ul><p>Multi-Process를 통해 동시에 처리하던 Task를 Multi-Threading으로 처리할 경우, 메모리 공간과 OS Resource를 절약할 수 있다.<br>만약 병렬로 처리해야하는 Task가 각자의 통신을 요구하는 경우에도 Multi-Processing과는 다르게 별도의 자원을 요구하는 것이 아닌, 전역 변수 공간에 할당된 Heap 영역을 통해 데이터의 공유가 가능하다.<br>심지어 Thread의 Context Switch는 Process의 그것과는 달리 Cache Memory를 비울 필요가 없기 때문에 더 빠르다.<br>이러한 이유로 Multi-Threading이 Multi-Processing보다 자원 소모가 적고 더 빠른 응답 시간을 가진다. </p><ul><li>Multi-Threading의 단점</li></ul><p>Multi-Processing과는 달리, Multi-Threading은 공유 자원인 Heap 영역이 있기 때문에 동일한 자원을 동시에 접근할 수 있어서 이 부분을 신경써서 Programming을 해야한다.<br>이 때문에 Multi-Threading은 동기화 작업이 필요하다.<br>하지만 이를 위해서 과도한 lock을 걸어버리면 오히려 그것 때문에 병목현상이 발생하고 성능이 저하될 수 있다.</p><ul><li>Multi-Threading vs Multi-Processing</li></ul><p>Multi-Threading은 Multi-Processing보다 적은 메모리를 차지하고 빠른 Context Switching이 가능하다는 장점이 있지만, 오류로 인해 하나의 Thread가 죽으면 전체 Thread가 죽을 수도 있다는 단점이 있다.<br>반면 Multi-Processing은 하나의 Process가 죽더라도 다른 Process는 전혀 영향을 받지 않는다.</p><h3 id="Scheduling"><a href="#Scheduling" class="headerlink" title="Scheduling"></a>Scheduling</h3><p>Scheduler란 한정적인 메모리를 여러 프로세스가 효율적으로 사용할 수 있도록 다음 실행 시간에 실행할 수 있는 프로세스 중에 하나를 선택하는 역할을 일컫는다. </p><p>이러한 Scheduling을 위해서 Scheduling Queue라는 것이 존재한다.   </p><ul><li>Job Queue : 현재 시스템 내에 있는 모든 프로세스의 집합</li><li>Ready Queue : 현재 메모리 내에 있으면서 CPU 를 잡아서 실행되기를 기다리는 프로세스의 집합</li><li>Device Queue : Device I/O 작업을 대기하고 있는 프로세스의 집합</li></ul><p>각각의 Queue 에 프로세스들을 넣고 빼주는 스케줄러에도 크게 세 가지 종류가 존재한다.</p><ol><li><p>Long Term Scheduler</p><p> long-term스케줄러는 보조기억장치에 존재하는 프로세스 중 어떤 프로세스를 주 메모리로 load할 지 결정하는 역할을 해준다.<br> 메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 대용량 메모리(일반적으로 디스크)에 임시로 저장된다. 이 pool 에 저장되어 있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 ready queue 로 보낼지 결정하는 역할을 한다.</p></li></ol><ol><li><p>Short Term Scheduler</p><p> CPU 와 메모리 사이의 스케줄링을 담당한다. Ready Queue 에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 결정하는 Scheduler이다. </p></li><li><p>Medium Term Scheduler</p><p> 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아내는 역할을 한다.<br> 현 시스템에서 메모리에 너무 많은 프로그램이 동시에 올라가는 것을 조절하는 스케줄러.</p></li></ol><p>그리고 CPU를 잘 사용하기 위해서 Process를 잘 배정할 필요가 있다. 이 과정을 CPU Scheduling이라고 부른다. </p><p>이러한 CPU Scheduling은 선점과 비선점 Scheduling으로 나뉜다. </p><ol><li><p>비선점 Scheduling</p><p> 프로세스 종료 or I/O 등의 이벤트가 있을 때까지 실행 보장 (처리시간 예측 용이함)</p><p> 이러한 비선점 Scheduling에도 종류가 여러가지가 있다.</p><ul><li>FCFS (First Come First Served)</li><li>SJF (Shortest Job First)</li><li>HRN (Hightest Response-ratio Next)</li></ul></li><li><p>선점 Scheduling</p><p> OS가 CPU의 사용권을 선점할 수 있는 경우, 강제 회수하는 경우 (처리시간 예측 어려움)</p><p> 이러한 선점 Scheduling에도 종류가 여러가지가 있다.</p><ul><li>Priority Scheduling</li><li>Round Robin</li><li>Multilevel-Queue</li><li>Multilevel-Feedback-Queue</li></ul></li></ol><p>이렇게 여러가지 CPU Scheduling 알고리즘이 있는데 이를 평가할 수 있는 척도가 있어야 한다. 그래야 어떤 알고리즘이 더 좋은지 알 수 있기 때문이다.<br>이러한 척도는 총 5가지가 있다.</p><ol><li><p>CPU utilization : 계속 CPU를 사용할수 있도록 하기 위함. CPU가 컴퓨터가 켜져있는 동안 계속 동작한다면 100% 그리고 CPU가 한번도 동작하지 않는다면 0%이다.</p></li><li><p>Throughput : 특정 시간동안 실행될 수 있는 프로세스 몇개인가?</p></li><li><p>Turnaround time : 메모리에 들어가기 위해 기다리는 시간 + ready queue에서 기다리는 시간 + CPU 실행하는 시간 + I/O하는 시간</p></li><li><p>Waiting time : 프로세스가 ready queue에서 기다리는 시간의 총 합</p></li><li><p>Response time : 프로세스가 응답을 시작할 때까지 걸리는 시간</p></li></ol><h3 id="System-Call"><a href="#System-Call" class="headerlink" title="System Call"></a>System Call</h3><p>fork( ), exec( ), wait( )와 같은 것들을 Process 생성과 제어를 위한 System call이라고 부름.</p><ul><li>fork, exec는 새로운 Process 생성과 관련이 되어 있다.</li><li>wait는 Process (Parent)가 만든 다른 Process(child) 가 끝날 때까지 기다리는 명령어임.</li></ul><ol><li><p>Fork</p><p> 새로운 Process를 생성할 때 사용하는 System Call임.  </p></li></ol><ol><li><p>Exec</p><p> child에서는 parent와 다른 동작을 하고 싶을 때는 exec를 사용할 수 있음.</p></li><li><p>Wait</p><p> child 프로세스가 종료될 때까지 기다리는 Task이다. </p></li></ol><h3 id="Synchronization"><a href="#Synchronization" class="headerlink" title="Synchronization"></a>Synchronization</h3><p>동기화의 정의를 다루기전에 먼저 Race Condition과 Critical Section의 개념을 다룰 필요가 있다.</p><blockquote><p>Race Condition이란 여러 Process들이 동시에 데이터에 접근하는 상황에서 어떤 순서로 데이터에 접근하느냐에 따라서 결과값이 달라질 수 있는 상황을 말한다.</p><p>Critical Section이란 동일한 자원을 접근하는 작업을 실행하는 코드 영역을 일컫는다. 또는 코드 상에서 Race Condition이 발생할 수 있는 특정 부분이라고도 말한다.</p></blockquote><p><em>Process의 동기화란이런 Critical Section에서 발생할 수 있는 Race Condition을 막고 데이터의 일관성을 유지하기 위해서 협력 Process간의 실행 순서를 정해주는 메커니즘이다.</em></p><p>이러한 Critical Section상에서 발생할 수 있는 문제를 해결하기 위해서는 다음 조건들을 만족해야 한다.</p><ol><li><p>Mutual Exculsion (상호 배제)</p><p> 이미 한 Process가 Critical Section에서 작업중이면 다른 모든 Process는 Critical Section에 진입하면 안된다.</p></li><li><p>Progress (진행)</p><p> Critical Secion에서 작업중인 Process가 없다면 Critical Section에 진입하고자 하는 Process가 존재하는 경우에만 진입할 수 있어야 한다.</p></li><li><p>Bounded Waiting (한정 대기)</p><p> Process가 Critical Section에 들어가기 위해 무한정 기다려서는 안된다.</p></li></ol><p>이러한 Critical Section 문제를 해결하기 위해서 다음과 같은 해결책들이 존재한다.</p><ul><li>Mutex Lock (Mutual Exclusion Lock)</li></ul><p>Mutex Lock은 이미 하나의 Process가 Critical Section에서 작업중이면 다른 Process들은 Critical Section에 진입할 수 없도록 한다.<br>하지만 이러한 방식은 <em>Busy Waiting</em>의 단점이 있다. Critical Section에 Process가 존재할때 다른 Process들이 계속 Critical Section에 진입하려고 시도하면서 CPU를 낭비하는 것이다.</p><p>이렇게 lock이 반환될때까지 계속 확인하면서 Process가 대기하고 있는 것을 Spin Lock이라고도 한다. Spin lock은 Critical Section에 진입을 위한 대기 시간이 짧을때 즉, Context Switching을 하는 비용보다 기다리는게 더 효율적인 특수한 상황에서 사용된다.</p><ul><li>Semaphores</li></ul><p>Semaphore는 Busy Waiting이 필요 없는 동기화 도구이며, 여러 Process/Thread가 Critical Section에 진입할 수 있게 하는 Locking 메커니즘이다. </p><p>Semaphore는 Counter를 활용하여 동시에 자원에 접근할 수 있는 Process를 제한한다. 단순히 생각해서 <em>공유 자원의 개수</em>라고 생각하면 편하다. 이러한 Semaphore에는 2 종류가 있다.</p><ol><li>Counting Semaphore: 자원의 개수만큼 존재하는 Semaphore</li><li>Binary Semaphore: 0과 1뿐인 Semaphore</li></ol><h3 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h3><h4 id="Memory-Management-Strategy"><a href="#Memory-Management-Strategy" class="headerlink" title="Memory Management Strategy"></a>Memory Management Strategy</h4><p>각각의 프로세스 는 독립된 메모리 공간을 갖고, 운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다. 단지, 운영체제 만이 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 제약을 받지 않는다.  </p><h4 id="Locality-of-Cache"><a href="#Locality-of-Cache" class="headerlink" title="Locality of Cache"></a>Locality of Cache</h4><h2 id="Database"><a href="#Database" class="headerlink" title="Database"></a>Database</h2><h3 id="SQL-vs-NoSQL"><a href="#SQL-vs-NoSQL" class="headerlink" title="SQL vs NoSQL"></a>SQL vs NoSQL</h3><p>SQL과 NoSQL은 각자 다음과 같은 뜻이 있다.</p><p>SQL: Structured Query Language<br>NoSQL: Not Only SQL</p><p>각자 쓰이는 장소가 다르다. SQL은 관계형 데이터베이스(RDBMS)에서 사용되고 NoSQL은 비 관계형 데이터베이스에서 사용된다. </p><p>이들은 각각 특성이 있을뿐, 장단으로 명확하게 나뉘지 않는다.</p><p>SQL의 특성:</p><ul><li>명확하게 정의된 스키마가 있으며 데이터의 무결성을 보장한다.</li><li>관계는 각 데이터를 중복없이 한번만 저장하면 된다.</li><li>데이터의 스키마를 사전에 계획하고 알려야 한다. (나중에 수정하기 매우 힘들다)</li><li>관계를 맺고 있어서 Join문이 많은 복잡한 쿼리를 사용해야할 수도 있음</li><li>대체적으로 수직적 확장만 가능함. (DB 서버의 성능을 올리는 방향)</li></ul><p>NoSQL의 특성:</p><ul><li>명확하게 정의된 스키마가 없으며 유연한 데이터 구조를 지님</li><li>데이터를 Application이 필요로 하는 형태로 저장할 수 있음. 데이터의 I/O가 빨라짐.</li><li>수직 및 수평적 확장이 용이함. </li><li>데이터의 중복을 계속 업데이트할 필요가 있음.</li></ul><h3 id="Index-1"><a href="#Index-1" class="headerlink" title="Index"></a>Index</h3><p>Index는 DB의 검색 속도를 높이기 위한 테크닉중 하나이다.   </p><p>Index를 통해서 DB는 Table을 Full Scan하지 않고도 원하는 데이터를 찾을 수 있다. 이러한 Index는 대개 B+ Tree 구조로 저장되어 있어서 Index를 통한 검색을 더욱 빠르게 진행할 수 있다.   </p><p>하지만 Index를 사용하게 되면 한 페이지를 동시에 수정할 수 있는 병행성이 줄어들고 Insert, Update, Delete 등의 Write 작업의 성능에 영향을 미칠 수 있다. 또한 Index를 관리하기 위해 저장 공간의 약 10%가 사용되므로 Write 연산이 빈번한 Table에 Index를 잘못 걸게 되면 오히려 성능이 저하될 수 있다.</p><h3 id="Transaction"><a href="#Transaction" class="headerlink" title="Transaction"></a>Transaction</h3><p>Transaction이란 DB의 상태를 변화시키기 위한 수행 단위를 일컫는다.<br>예를 들어서, 은행에서 송금을 처리하는 퀴리문들이 있다고 가정하자. 그렇다면 다음의 쿼리문들이 하나의 Transaction이다. </p><blockquote><p>사용자 A의 계좌에서 만원을 차감한다 : UPDATE 문을 사용해 사용자 A의 잔고를 변경<br>사용자 B의 계좌에 만원을 추가한다 : UPDATE 문을 사용해 사용자 B의 잔고를 변경</p></blockquote><p>위의 2개의 쿼리문이 하나의 Transaction이다. 2개의 쿼리문이 성공적으로 완료되어야만 하나의 Transaction이 성공하고 DB에 반영된다. (이를 Commit한다고 한다.)<br>반대로 둘중 하나라도 실패하게 된다면 모든 쿼리문을 취소하고 DB는 원상태로 돌아간다. (이를 Rollback이라고 한다.)</p><p>RDB에서 Transaction은 다음을 엄격하게 만족시켜야 한다.<br>ACID (Atomicity, Consistency, Isolation, Durability)</p><ul><li>Atomicity: 트랜잭션이 DB에 모두 반영되거나, 혹은 전혀 반영되지 않아야 된다.</li><li>Consistency: 트랜잭션의 작업 처리 결과는 항상 일관성 있어야 한다.</li><li>Isolation: 둘 이상의 트랜잭션이 동시에 병행 실행되고 있을 때, 어떤 트랜잭션도 다른 트랜잭션 연산에 끼어들 수 없다.</li><li>Durability: 트랜잭션이 성공적으로 완료되었으면, 결과는 영구적으로 반영되어야 한다.</li></ul><p>반대로 NoSQL DB에서는 완화된 ACID를 지원하는데, 이를 종종 BASE(Basically Avaliable, Soft state, Eventually consistent)라고 부르기도 한다.</p><ul><li>Basically Avaliable: 기본적으로 언제든지 사용할 수 있다는 의미를 가지고 있다.</li><li>Soft state: 외부의 개입이 없어도 정보가 변경될 수 있다는 의미를 가지고 있다.</li><li>Eventually consistent: 일시적으로 일관적이지 않은 상태가 되어도 일정 시간 후 일관적인 상태가 되어야한다는 의미를 가지고 있다.</li></ul><p>BASE는 ACID와는 다르게, 데이터의 일관성보다는 가용성을 우선시하는 것이 특징이다. 어느 것이 좋다고 말을 할 수 없이 그냥 특성으로 받아들이는 것이 좋다.</p><h3 id="Lock"><a href="#Lock" class="headerlink" title="Lock"></a>Lock</h3><p>DB에서 Lock은 Transaction 처리의 순차성을 보장하기 위해서 나온 개념이다. Lock은 여러 connection에서 동시에 동일한 자원을 요청할 경우 순서대로 한 시점에는 하나의 connection만 변경할 수 있게 해주는 역할을 한다.  </p><p>Lock의 종류로는 Shared Lock과 Exclusive Lock이 있다. Shared Lock은 Read Lock이라고도 불리우며 Exclusive Lock은 Write Lock이라고도 불리운다. </p><ol><li>Shared Lock: 공유 Lock은 데이터를 읽을 때 사용되어지는 Lock이다. 이런 공유 Lock은 공유 Lock 끼리는 동시에 접근이 가능하다.</li><li>Exclusive Lock: 베타 Lock은 데이터를 변경하고자 할 때 사용되며, 트랜잭션이 완료될 때까지 유지된다. 베타락은 Lock이 해제될 때까지 다른 트랜잭션(읽기 포함)은 해당 리소스에 접근할 수 없다.</li></ol><h3 id="deadlock"><a href="#deadlock" class="headerlink" title="deadlock"></a>deadlock</h3><p>교착상태는 두 트랜잭션이 각각 Lock을 설정하고 다음 서로의 Lock에 접근하여 값을 얻어오려고 할 때 이미 각각의 트랜잭션에 의해 Lock이 설정되어 있기 때문에 양쪽 트랜잭션 모두 영원히 처리가 되지않게 되는 상태를 말한다. 교착상태가 발생하면 DBMS가 둘 중 한 트랜잭션에 에러를 발생시킴으로써 문제를 해결합니다. 교착상태가 발생할 가능성을 줄이기 위해서는 접근 순서를 동일하게 하는것이 중요하다.</p><p>교착 상태의 빈도를 낮추는 방법:</p><ol><li>트랜잭션을 자주 커밋한다.</li><li>정해진 순서로 테이블에 접근한다. 트랜잭션들이 동일한 테이블 순으로 접근하게 한다.</li><li>읽기 잠금 획득 (SELECT ~ FOR UPDATE)의 사용을 피한다.</li><li>한 테이블의 복수 행을 복수의 연결에서 순서 없이 갱신하면 교착상태가 발생하기 쉽다, 이 경우에는 테이블 단위의 잠금을 획득해 갱신을 직렬화 하면 동시성을 떨어지지만 교착상태를 회피할 수 있다.</li></ol><h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><blockquote><p>Redis는 In-Memory기반의 Key-Value 데이터 구조의 DB이다.</p></blockquote><p>Redis는 메모리(RAM)에 저장해서 디스크 스캐닝이 필요없어 매우 빠른 장점이 존재한다. 캐싱도 가능해 실시간 채팅에 적합하며 세션 공유를 위해 세션 클러스터링에도 활용된다.</p><h3 id="High-Avaliablity-Strategy"><a href="#High-Avaliablity-Strategy" class="headerlink" title="High Avaliablity Strategy"></a>High Avaliablity Strategy</h3><h4 id="High-Avaliablity-on-SQL-DB"><a href="#High-Avaliablity-on-SQL-DB" class="headerlink" title="High Avaliablity on SQL DB"></a>High Avaliablity on SQL DB</h4><p>MySQL 같은 SQL DB에서 HA를 구축하는 전략중에 가장 보편적인 방법은 Master-Slave Node를 구성하는 방법이다.<br>Master Node는 Read/Write 연산을 둘 다 담당할 수 있고 Slave Node는 Read Only이다.<br>Slave Node가 Master Node의 Binary log를 읽어서 Slave DB의 Relay log로 복사 후 반영하여 변경된 데이터를 동기화하는 방식이 잘 알려진 Replication이다.</p><p>Slave 대수에 따라 수 초의 Delay가 발생할 수 있어 실시간이 매우 중요한 데이터 읽기 트랜잭션은 Master DB에서 읽게 하고 Slave DB는 이외 읽기 트랜잭션을 적용하는 것이 일반적이다.</p><p>필자는 Proxy SQL을 사용하여 Application에서 들어오는 Transaction을 Master/Slave Node에 분류하여 처리하게 하였고 Read 연산의 경우 Slave node들에 Round Robin으로 Load Balancing을 진행하였다. </p><p>그리고 여기서 또 중요한 점이 한가지 존재한다. Master가 죽었을 때 어떻게 Slave들이 데이터의 일관성을 유지할 것인지가 굉장히 중요한 논점이다.  </p><h4 id="High-Avaliablity-on-Redis"><a href="#High-Avaliablity-on-Redis" class="headerlink" title="High Avaliablity on Redis"></a>High Avaliablity on Redis</h4><p>Redis에서 HA를 적용하는 방법은 크게 2가지가 있다.</p><ul><li><p>Master/Slave Node with Redis Sentinel</p><p>  이는 SQL에서와 마찬가지로 Read/Write 연산을 담당하는 Master Node와 Read Only 연산을 담당하는 Slave Node로 나눈 뒤에, 각 Node의 상태를 Redis Sentinel이 감시하게 하는 방법을 사용한다.<br>  Redis Sentinel은 최소 3대로 Cluster를 이루어 Master의 생존 여부를 투표로 결정하고 Master가 죽은 경우에는 투표를 통해서 살아있는 Slave Node를 Master로 승격시킨다.</p></li><li><p>Redis Cluster</p><p>  Redis Cluster의 경우, Redis Sentinel 없이 최소 3대의 Master/Slave Node가 서로를 모니터링 하면서 고 가용성을 만든다.<br>  데이터세트을 여러 노드로 자동분할 하는 기능(샤딩) (최대 1000개)을 가지고 있으며 Gossip Protocol을 통해서 서로 통신을 진행한다.  </p><p>  Master Node에 장애가 발생할 경우, Master의 Slave는 Gossip Protocol을 통해 장애를 파악한다.<br>  이후 스스로 Master로 승격하여 Master를 대신한다. 장애가 발생한 Master가 복구될경우, 스스로 Slave로 강등</p></li></ul><h3 id="ORM"><a href="#ORM" class="headerlink" title="ORM"></a>ORM</h3><p>ORM은 Object Relational Mapping의 약자로써, 풀어서 설명하자면 우리가 OOP(Object Oriented Programming)에서 쓰이는 객체라는 개념을 구현한 클래스와 RDB(Relational DataBase)에서 쓰이는 데이터인 테이블 자동으로 매핑(연결)하는 것을 의미한다.</p><p>쌩 SQL Query를 작성하는 것보다 ORM이 가지는 장단점은 다음과 같다.</p><p>장점)</p><ul><li>완벽한 객체지향적 코드: ORM을 사용하면 SQL문이 아닌 Class의 Method를 통해서 DB를 조작할 수 있다. 이는 개발자가 Object Model만을 이용해서 Programming을 하는데 집중할 수 있게 해준다.</li><li>재사용/유지보수/리펙토링의 용이: ORM은 기존 객체와 독립적으로 작성되어있으며, Object로 작성되어 있기 때문에 재활용이 가능하다. 또한 Mapping하는 정보가 명확하기 때문에 ERD를 보는 의존도를 낮출 수 있다.</li><li>DBMS의 종속성 하락: 객체 간의 관계를 바탕으로 SQL문을 자동으로 생성하고, 객체의 자료형 타입까지 사용할 수 있기 때문에 RDBMS의 데이터 구조와 객체지향 모델 사이의 간격을 좁힐 수 있다.</li></ul><p>단점)</p><ul><li>ORM은 명확한 한계가 존재한다: Project가 커지면 그만큼 구현의 난이도가 올라가고, 이때 설계를 부실하게 하면 오히려 속도가 떨어지는 문제점이 생긴다. 또한 그 뿐만 아니라 일부 SQL의 경우에는 속도를 위해서 별도의 튜닝이 필요한데, 이때는 결국 SQL문을 직접 작성해야 한다.</li><li>Object-Relation 간의 불일치   <ul><li>세분성: 경우에 따라서 데이터베이스에 있는 테이블 수보다 더 많은 클래스를 가진 모델이 생길 수 있다.</li><li>상속성: RDB에서는 객체지향의 특징인 상속 기능이 존재하지 않는다.</li><li>연관성: 객체지향 언어는 방향성이 있는 객체의 참조를 사용하여 연관성을 나타내지만, RDBMS는 방향성이 없는 foreign key를 통해서 이를 나타낸다.</li></ul></li></ul><h2 id="Web"><a href="#Web" class="headerlink" title="Web"></a>Web</h2><h3 id="TCP-UDP"><a href="#TCP-UDP" class="headerlink" title="TCP / UDP"></a>TCP / UDP</h3><p>우선 TCP 통신과 UDP 통신부터 알아보자.</p><ul><li><p>TCP 통신</p><p>  TCP는 TCP/IP 모델의 3계층, Transport 계층의 프로토콜이다.<br>  기본적으로 신뢰성 있는 데이터 전송을 위한 연결 지향형 프로토콜이다.<br>  TCP는 우선 HandShake 방식을 통해서 데이터를 송/수신한다. 예를 들어서 TCP에서는 송신자가 데이터를 전송할 경우, 다음과 같은 검증 과정을 거친다.</p><ol><li>데이터를 제대로 수신했는지</li><li>에러는 발생하지 않았는지</li><li>수신 속도에 비해 전송 속도가 너무 빠르지는 않았는지 (흐름 제어)</li><li><p>네트워크가 혼잡하지는 않은지 (혼잡 제어)</p><p>이러한 기본적인 사항들을 지키는 Protocol이기 때문에 TCP를 높은 신뢰성을 보장한다고 말한다.</p><p>여기서 흐름 제어와 혼잡 제어를 보다 더 정확하게 설명하면 다음과 같다.</p></li></ol><ul><li><p>흐름 제어</p><p>  수신측이 송신측보다 데이터 처리 속도가 빠르면 문제없지만, 송신측의 속도가 빠를 경우 문제가 생긴다. 수신측에서 제한된 저장 용량을 초과한 이후에 도착하는 데이터는 손실 될 수 있으며, 만약 손실 된다면 불필요하게 응답과 데이터 전송이 송/수신 측 간에 빈번히 발생한다.<br>  아래서 설명하겠지만, Receiver Buffer의 크기만큼 수신자는 데이터를 읽을 수 있다. 따라서 수신측의 데이터 처리 속도가 송신측보다 느리면 문제가 발생한다.</p><p>  해결 방법:</p><ul><li>Stop and Wait : 매번 전송한 패킷에 대해 확인 응답을 받아야만 그 다음 패킷을 전송하는 방법</li><li>Sliding Window (Go Back N ARQ): 수신측에서 설정한 윈도우 크기만큼 송신측에서 확인응답없이 세그먼트를 전송할 수 있게 하여 데이터 흐름을 동적으로 조절하는 제어기법</li></ul></li><li><p>혼잡 제어</p><p>  송신측의 데이터는 지역망이나 인터넷으로 연결된 대형 네트워크를 통해 전달된다. 만약 한 라우터에 데이터가 몰릴 경우, 자신에게 온 데이터를 모두 처리할 수 없게 된다.<br>  이런 경우 호스트들은 또 다시 재전송을 하게되고 결국 혼잡만 가중시켜 오버플로우나 데이터 손실을 발생시키게 된다. 따라서 이러한 네트워크의 혼잡을 피하기 위해 송신측에서 보내는 데이터의 전송속도를 강제로 줄이게 되는데, 이러한 작업을 혼잡제어라고 한다.</p></li></ul></li></ul><pre><code>이러한 TCP는 전체적으로 다음과 같은 전송 과정을 거쳐서 데이터를 전송한다.* Application Layer: Sender Application layer가 socket에 data를 전송함.* Transport layer: data를 segment에 감싼다. 그리고 network layer에 넘겨준다.* Network layer - physical layer에서 도착지에 데이터를 전송한다. 이때 Sender의 send buffer에 data를 저장하고 receiver는 receive buffer에 data를 저장한다.* Application에서 준비가 되면 buffer에 있는 데이터를 읽음 (흐름 제어의 핵심은 이 receiver buffer가 넘치지 않게 하는 것에 있다.)* Receiver는 Receive Window : receiver buffer의 남은 공간을 홍보함.</code></pre><ul><li><p>UDP</p><p>  UDP의 경우에는 TCP 처럼 신뢰성을 보장하지 않는다. 하지만 그만큼 신뢰성을 보장하기 위한 흐름 제어/혼잡 제어같은 처리가 필요 없어서 overhead가 발생하지 않고 빠른 처리 및 경량화된 헤더를 가지게 된다. 이러한 이유 때문에 UDP는 다음과 같은 연속성과 성능이 더 중요한 분야에 사용되게 된다.</p><ul><li>인터넷 전화</li><li>온라인 게임</li><li>멀티미디어 스트리밍 </li></ul></li></ul><h3 id="TCP-3-4way-handshake"><a href="#TCP-3-4way-handshake" class="headerlink" title="TCP 3/4way handshake"></a>TCP 3/4way handshake</h3><p>TCP 통신은 연결을 수립/종료할때 각각 3/4 way handshake를 통해서 진행하게 된다.<br>먼저 연결을 수립하는 과정인 3 way handshake를 생각해 보자.   </p><p>3 way handshake는 총 3번의 통신 과정을 거쳐서 내가 누구와 통신중인지, 내가 받아야할 데이터의 sequence number는 몇번인지 등등의 정보를 주고 받으면서 연결의 상태를 생성하게 된다.</p><ol><li>먼저 수신자는 LISTEN 상태로 대기를 하게 된다. 이때, 수신자는 요청자가 요청을 하기 전까지는 대기를 하게 되는데 이 상태를 수동 개방이라고 하고 수신자를 Passive Opener라고 한다.</li><li>요청자가 수신자에게 연결 요청을 하면서 랜덤한 숫자인 Sequence Number를 생성하여 SYN 패킷에 담아 보낸다. 이 Sequence Number를 활용하여 계속 새로운 값을 만들고 서로 확인하며 연결 상태와 패킷의 순서를 확인하게 된다.</li><li>수신자는 요청자가 보낸 SYN 패킷을 잘 받았으면 SYN + ACK 패킷을 보낸다. 여기에는 제대로된 Sequence Number를 받았다는 의미인 승인 번호값이 들어있으며 이는 Sequence Number + 상대방이 보낸 데이터의 크기(byte)의 값을 가지고 있다. 하지만 맨 처음에는 1을 더해서 보낸다.</li><li>요청자가 이러한 ACK의 값이 Sequence Number와 1차이가 나는 것을 확인하였으면 다시 확인차 ACK 패킷을 보내 연결이 수립된다.</li></ol><p>1번이 초기 상태이고 2~4번부터 3 Way Handshake의 과정이다. 이렇게 3단계의 과정을 거쳐서 TCP의 연결을 수립한다.</p><p>이제 4 Way Handshake에 대해서 알아보도록 하겠다.<br>이는 연결을 종료할때 사용하는 과정이다. 굳이 이러한 과정을 거쳐서 연결을 종료하는 이유는 연결을 그냥 끊었다가는 다른 한쪽이 연결이 끊겼는지 아닌지 알 방법이 없기 때문이다. 이러한 과정을 총 4번의 통신을 거치기에 4 way handshake라고 한다.</p><ol><li>먼저, 연결을 종료하고자 하는 요청자가 상대에게 FIN 패킷을 보내면서 FIN_WAIT 상태로 들어가게 된다. </li><li>수신자는 요청자가 보낸 Sequence Number + 1로 승인 번호를 만들어서 다시 요청자에게 ACK로 응답해주면서 CLOSE_WAIT 상태로 들어가게 된다. 이때 요청자는 자신이 받은 값이 Sequence Number + 1이 맞는지 다시 확인해 본다.</li><li>수신자는 자신이 처리할 데이터가 더 없다면 FIN을 다시 한번 요청자에게 보내고 LAST_ACK 상태에 들어간다.</li><li>요청자는 FIN을 수신자로부터 받고 다시 ACK 패킷을 수신자에게 보내준다. 그럼 수신자는 완벽하게 요청을 끊는 것이다.</li></ol><h3 id="TLS-SSL"><a href="#TLS-SSL" class="headerlink" title="TLS/SSL"></a>TLS/SSL</h3><p>TLS는 Transport Layer Security의 약자이고 SSL은 Secure Socket Layer의 약자이다.<br>SSL은 암호화 기반의 인터넷 보안 프로토콜이다. TLS의 전신인 이 프로토콜은 전달되는 모든 데이터를 암호화하고 특정 유형의 사이버 공격 또한 차단한다.<br>하지만 SSL은 3.0 이후로 업데이트 되지 않고 있으며 여러 취약점들이 알려져 사용이 중된되었다. 따가서 이렇게 개발된 최신 암호화 프로토콜이 TLS이다.</p><p>TLS 는 SSL의 업데이트 버전으로 SSL의 최종버전인 3.0과 TLS의 최초버전의 차이는 크지않으며, 이름이 바뀐것은 SSL을 개발한 Netscape가 업데이트에 참여하지 않게 되어 소유권 변경을 위해서였다고 한다.<br>결과적으로 TLS는 SSL의 업데이트 버전이며 명칭만 다르다고 볼 수 있다.</p><p>SSL/TLS는 handshake를 통해서 실제 데이터를 주고 받기 전에 서로 연결 가능한 상태인지 파악을 하게 된다. </p><ol><li><p>Client Hello </p><p> Client는 Server에게 다음과 같은 정보를 넘겨주면서 Hello라는 패킷을 보낸다.</p><ul><li>Client에서 생성한 Random 값</li><li>Client가 지원하는 암호화 방식</li><li>(이전에 HandShake가 일어났을 경우) Session ID</li></ul></li><li><p>Server Hello</p><p> Server는 Client에게 다음과 같은 정보를 전달한다.</p><ul><li>Server에서 생성한 Random 값</li><li>Client가 제공한 암호화 방식중 Serve가 선택한 암호화 방식</li><li>인증서</li></ul></li><li><p>Certificate </p><p> Server가 자신의 TLS/SSL 인증서를 Client에게 전달한다. Client는 Server가 보낸 CA(Certifiacte Authority)의 개인키로 암호화된 SSL 인증서를 이미 모두에게 공개된 CA의 공개키를 사용해 복호화 한다. 즉, 인증서를 검증하는 과정을 거친다. </p></li><li><p>Server Key Exchange / Hello Done</p><p> Server Key Exchange는 Server의 공개키가 TLS/SSL 인증서 내부에 없을 경우 Server가 직접 이를 전달하는 것을 의미한다. 공개키가 인증서 내부에 있으면 이 과정은 생략된다.   </p></li><li><p>Client Key Exchange</p><p> 실제로 데이터를 암호화 하는 키(대칭키)를 Client가 생성해서 SSL 인증서 내부에서 추출한 Server의 공개키를 이용해 암호화한 뒤에, Server에 전달한다. 여기서 전달된 대칭키가 SSL Handshake의 목적이자, 실제 데이터를 암호화 하게될 비밀키이다. </p></li><li><p>Change Cipher Spec / Finished</p><p> Client, Server가 모두 서로에게 보내는 Packet으로 교환할 정보를 모두 교환환 뒤에, 통신을 할 준비가 되었음을 알리는 Packet이다. 이것으로 Handshake는 종료된다.</p></li></ol><p>이를 요약하면 다음과 같다.</p><blockquote><p>ClientHello(암호화 알고리즘 나열 및 전달) - &gt; Serverhello(암호화 알고리즘 선택) - &gt; Server Certificate(인증서 전달) - &gt; Client Key Exchange(데이터를 암호화할 대칭키 전달) - &gt; Client / ServerHello done (정보 전달 완료) - &gt; Fisnied (SSL Handshake 종료)</p></blockquote><h3 id="HTTP-1-0-1-1-2-0"><a href="#HTTP-1-0-1-1-2-0" class="headerlink" title="HTTP 1.0/1.1/2.0"></a>HTTP 1.0/1.1/2.0</h3><p>HTTP의 명확한 정의는 다음과 같다. </p><blockquote><p>WWW 상에서 정보를 주고 받을 수 있는 프로토콜. 주로 HTML 문서를 주고 받는 데에 쓰인다.</p></blockquote><p>HTTP는 TCP위에서 돌아가는 Application Level의 Protocol이며 기본적으로 Stateless Protocol이다.</p><p>HTTP는 1.0과 1.1, 2.0 그리고 최근데 3.0이 나왔는데, 1.0과 1.1의 차이를 비교하면서 1.0과 1.1을 논하도록 하고 1.1과 2.0의 차이를 논하도록 하겠다.</p><p>HTTP 1.0과 1.1의 차이점은 다음과 같다.</p><ul><li><p>Connection 유지</p><p>  1.0과 1.1의 차이는 TCP Session을 유지할 수 있느냐 없느냐이다. TCP는 Handshake를 통해서 연결을 수립하는데 HTTP/1.0를 통해서 통신을 할때마다 이를 끊고 다시 수립하는 과정이 있어야 했다. 이를 보완하려면 Persistence Connection을 지원하는 Client는 Server에게 요청을 보낼때 connection:keep-alive header를 통해서 Persistence Connection을 수립해야 했다. 그리고 Server는 응답에서 똑같은 Header를 넣어서 보낸다.</p><p>  하지만 HTTP/1.1은 이를 기본으로 지원한다. 즉, 굳이 Connection Header 를 사용하지 않아도 모든 요청과 응답은 기본적으로 Persistent Connection을 지원하도록 되어 있으며 필요 없을 경우(HTTP 응답 완료 후 TCP 연결을 끊어야 하는 경우) Connection Header를 사용한다.</p><p>  Keep-Alive 를 통해 얻을 수 있는 장점으로는 단일 시간 내의 TCP 연결을 최소화 함으로써 CPU와 메모리 자원을 절약할 수 있고 네트워크 혼잡이나 Latency 에 대한 경우의 수를 줄일 수 있다는 점이다.</p><ul><li><p>Pipelining</p><p>  HTTP 1.0 에서는 HTTP 요청들의 연결을 반복적으로 끊고 맺음으로서 서버 리소스적으로 비용을 요구한다. </p><p>  HTTP 1.1 에서는 다수의 HTTP Request 들이 각각의 서버 소켓에 Write 된 후, Browser는 각 Request들에 대한 Response를 순차적으로 기다리는 문제를 해결하기 위해 여러 요청들에 대한 응답 처리를 뒤로 미루는 방법을 사용한다.</p><p>  Pipelining이 적용되면 하나의 Connection으로 다수의 Request와 Response를 처리할 수 있고 Network Latency를 줄일 수 있게 된다.</p></li></ul></li><li><p>Host Header</p><p>  HTTP 1.0 환경에서는 하나의 IP에 여러 개의 도메인을 운영할 수 없었지만 HTTP 1.1 부터 가능하게 된다.</p><p>  HTTP 1.1 에서 Host 헤더의 추가를 통해 비로소 Virtual Hosting이 가능해졌다.</p></li><li><p>향상된 Authentication Prcedure</p><p>  HTTP 1.1 에서 다음 2개의 헤더가 추가된다.</p><ul><li>proxy-authentication  </li><li><p>proxy-authorization  </p><p>실제 Server에서 Client 인증을 요구하는 www-authentication 헤더는 HTTP 1.0 에서부터 지원되어 왔으나, Client와 Server 사이에 프록시가 위치하는 경우 프록시가 사용자의 인증을 요구할 수 있는 방법이 없었다.</p></li></ul></li></ul><p>그리고 다음과 같은 특성을 가진 HTTP/2.0이 나왔다.</p><ul><li>Multiplexed Streams (한 커넥션에 여러개의 메세지를 동시에 주고 받을 수 있음)</li><li>요청이 커넥션 상에서 다중화 되므로 HOL(Head Of Line) Blocking 이 발생하지 않음</li><li>Stream Prioritization (요청 리소스간 의존관계를 설정)</li><li>Header Compression (Header 정보를 HPACK 압축 방식을 이용하여 압축 전송)</li><li>Server Push (HTML문서 상에 필요한 리소스를 클라이언트 요청없이 보내줄 수 있음)</li><li>프로토콜 협상 메커니즘 - 프로토콜 선택, 예. HTTP / 1.1, HTTP / 2 또는 기타.</li><li>HTTP / 1.1과의 높은 수준의 호환성 - 메소드, 상태 코드, URI 및 헤더 필드</li><li>페이지 로딩 속도 향상</li></ul><p>기존 HTTP는 Body가 문자열로 이루어져 있지만, HTTP 2.0 부터는 Binary framing layer 라고 하는 공간에 이진 데이터로 전송된다.</p><h3 id="HTTP-Cache"><a href="#HTTP-Cache" class="headerlink" title="HTTP Cache"></a>HTTP Cache</h3><p>HTTP Cache는 이미 가져온 데이터나 계산된 결과값의 복사본을 저장함으로써 처리 속도를 향상시키며, 이를 통해 향후 요청을 더 빠르게 처리할 수 있다. </p><p>브라우저가 시도하는 모든 HTTP 요청은 먼저 브라우저 캐시로 라우팅되어, 요청을 수행하는데 사용할 수 있는 유효한 캐시가 있는지를 먼저 확인한다. 만약 유효한 캐시가 있으면, 이 캐시를 읽어서 불필요한 전송으로 인해 발생하는 네트워크 대기시간, 데이터 비용을 모두 상쇄한다.</p><p>요약하자면 Cache의 효과는 다음과 같다.</p><ul><li>불필요한 데이터 전송을 줄여 네트워킹 비용을 줄여준다.</li><li>거리로 인한 지연시간을 줄여 웹페이지를 빨리 불러올 수 있게 된다.</li><li>서버에 대한 요청을 줄여 서버의 부하를 줄인다.</li></ul><h3 id="RESTful-API"><a href="#RESTful-API" class="headerlink" title="RESTful API"></a>RESTful API</h3><p>Representational State Transfer의 약자로 REST이다. 이는 여러 특성을 가지고 있는데 이 특성에 부합하는 API를 RESTful API라고 한다.<br>결국 REST는 다음과 같이 정의된다.</p><blockquote><p>자원을 이름(자원의 표현)으로 구분하여 해당 자원의 상태(정보)를 주고 받는 모든 것을 의미한다.</p></blockquote><p>자세한 정의를 말해보자면 자원의 표현은 HTTP URI로 하며 HTTP Method를 통해 해당 자원의 CRUD를 적용하는 것을 RESTful 하다고 표현한다.</p><p>Restful API는 흔히 Stateless라고 표현하고 이의 특징이 존재한다.<br>Restful API를 구현하는 절대 조건은 서버가 Client의 정보를 어느 것도 저장하지 않는다는 것이다. 이렇게 구현하는 절대적인 이유는 서버의 Scalablity이다.  </p><h3 id="Sync-Async-Blocking-Non-Blocking"><a href="#Sync-Async-Blocking-Non-Blocking" class="headerlink" title="Sync / Async / Blocking / Non-Blocking"></a>Sync / Async / Blocking / Non-Blocking</h3><p>제목의 4가지 개념은 각기 다른 것이다. Server에서 어떻게 요청을 처리할 것인지를 나타내고 있다. 각각 다음과 같은 의미를 지닌다.</p><ul><li>Synchronous: A함수가 B 함수를 호출할때, B 함수의 결과를 A함수에서 처리함.</li><li>ASynchronous: A함수가 B 함수를 호출할때, B 함수의 결과를 B함수에서 처리함. (Callback)</li><li>Blocking: A함수가 B함수를 호출할때, B함수가 자신의 작업이 종료되기 전까지 A함수에게 제어권을 넘겨주지 않음</li><li>Non-Blocking: A 함수가 B 함수를 호출할때, B함수가 바로 제어권을 A 함수에게 넘겨주면서 A 함수가 다른 일을 할 수 있도록 함.</li></ul><h3 id="Blocking-IO-Non-Blocking-IO"><a href="#Blocking-IO-Non-Blocking-IO" class="headerlink" title="Blocking IO / Non-Blocking IO"></a>Blocking IO / Non-Blocking IO</h3><p>I/O 작업은 Kernel Level에서만 수행이 가능하다. 따라서 Process나 Thread는 Kernel에게 I/O를 요청해야만 한다.</p><p>이때, I/O를 Blocking 방식으로 처리하느냐 Non-Blocking 방식으로 처리하느냐에 따라서 효율성이 다르다.</p><ol><li><p>Blocking I/O</p><p> Blocking 방식으로 I/O를 구현하면 다음과 같이 I/O를 처리해야 한다.</p><ul><li>Process나 Thread가 Kernel에게 I/O를 요청하는 함수를 호출함.  </li><li><p>Kernel이 작업을 완료하면 작업 결과를 반환받음.  </p><p>이렇게 되면 I/O 작업이 진행되는 동안 Process/Thread는 자신의 작업을 중단한 채로 대기한다. 이는 Resource의 낭비가 심하다. (I/O 작업이 CPU를 거의 사용하지 않으므로)</p><p>만약 여러 Client가 접속하는 서버를 Blocking 방식으로 구현하려는 경우 client별로 별도의 Thread를 생성해서 처리해야한다. 이로인해 많아진 Thread들의 Context Switching 비용이 늘어나서 효율성이 감소하게 된다. </p></li></ul></li><li><p>Non-Blocking I/O</p><p> Non-Blocking 방식으로 I/O를 구현하면 I/O 작업이 진행되는 동안 User Process의 작업을 중단하지 않는다.</p><ul><li>User Process가 recvfrom 함수 호출 (커널에게 해당 Socket으로부터 data를 받고 싶다고 요청함)</li><li>Kernel은 이 요청에 대해서, 곧바로 recvBuffer를 채워서 보내지 못하므로, “EWOULDBLOCK”을 return함.</li><li>Blocking 방식과 달리, User Process는 다른 작업을 진행할 수 있음.</li><li>recvBuffer에 user가 받을 수 있는 데이터가 있는 경우, Buffer로부터 데이터를 복사하여 받아옴. 이때, recvBuffer는 Kernel이 가지고 있는 메모리에 적재되어 있으므로, Memory간 복사로 인해, I/O보다 훨씬 빠른 속도로 data를 받아올 수 있음.</li><li>recvfrom 함수는 빠른 속도로 data를 복사한 후, 복사한 data의 길이와 함께 반환함.</li></ul></li></ol><h2 id="Javascript-Nodejs"><a href="#Javascript-Nodejs" class="headerlink" title="Javascript/Nodejs"></a>Javascript/Nodejs</h2><h3 id="Javascript"><a href="#Javascript" class="headerlink" title="Javascript"></a>Javascript</h3><ul><li>var, let, const 차이점</li></ul><p>var: 함수 스코프를 갖는다. 변수를 한번 더 선언해도 에러가 발생하지 않는다. 그래서 es6 업데이트로 let과 const 도입되었다.</p><p>let : 블록 스코프를 갖는다. 예를들어 if문 for문 while문 중괄호{}안에 선언 되었을 경우, 변수가 그 안에서 생성되고 사라진다.</p><p>const : 블록 스코프, 상수를 선언 할 때 사용한다. 선언과 동시에 할당 되어야합니다. (재할당하면 오류발생)</p><ul><li>hoisting</li></ul><p>hoisting은 코드가 실행하기 전 변수선언/함수선언이 해당 스코프의 최상단으로 끌어 올려진 것 같은 현상을 말한다.</p><ul><li>Temporal Dead Zone</li></ul><p>const와 let은 범위가 지정된 변수를 갖는다.<br>이 둘의 호이스팅이 실행 되기전 까지 액세스 할수 없는 것을 TDZ라 한다. </p><blockquote><p>즉, let/const선언 변수는 호이스팅되지 않는 것이 아니다.<br>스코프에 진입할 때 변수가 만들어지고 TDZ(Temporal Dead Zone)가 생성되지만, 코드 실행이 변수가 실제 있는 위치에 도달할 때까지 액세스할 수 없는 것이다.<br>let/const변수가 선언된 시점에서 제어흐름은 TDZ를 떠난 상태가 되며, 변수를 사용할 수 있게 된다.</p></blockquote><h3 id="NodeJS"><a href="#NodeJS" class="headerlink" title="NodeJS"></a>NodeJS</h3><ul><li>NodeJS</li></ul><p>NodeJS는 Single Threaded Event Driven Asynchronous Non-Blocking Javascript Engine이다. 하나의 스레드로 동작하지만, Asynchronous I/O 작업을 통해 요청들을 서로 Blocking하지 않는다.<br>즉, 동시에 많은 요청을 비동기로 처리함으로써 Single Threaded이더라도 많은 요청들을 Asynchronous하게 처리할 수 있다.</p><p>어떻게 그것이 가능하느냐? Single Threaded로 동작하면서 Blocking 작업을 어떻게 Non Blocking으로 Asynchronous하게 처리할 수 있을까?<br>그것은 NodeJS에서 일부 Blocking이 필요한 작업을 libuv의 Thread Pool에서 수행되기 때문이다.    </p><ul><li>Event Loop (JS Engine)</li></ul><p>Event Loop라는 것을 설명하기 전에 Event Driven의 개념부터 짚고 넘어가야 한다.  </p><blockquote><p>Event Driven이라는 것은 Event가 발생할때 미리 지정해둔 작업을 수행하는 방식을 의미한다.</p></blockquote><p>NodeJS는 EventListener에 등록해둔 Callback함수를 수행하는 방식으로 이를 처리한다.  </p><p>Event Loop는 Main Thread 겸 Single Thread로써 Busniess Logic을 수행한다. 이를 수행하는 도중에 Blocking I/O 작업을 만나면 Kernel Asynchronous 또는 자신의 Worker Thread Pool에게 넘겨주는 역할을 한다. GC 또한 Event Loop에서 돌아가고 있다.</p><p>위에서 Blocking Task(api call, DB Read/Write 등)들이 들어오면 Event Loop가 uv_io에게 내려준다고 하였다. libuv는 Kernel단(윈도우의 경우 IOCP, 리눅스는 AIO)에서 어떤 비동기 작업들을 지원해주는지 알고 있기때문에, 그런 종류의 작업들을 받으면, 커널의 Asynchronous 함수들을 호출한다. 작업이 완료되면 시스템콜을 libuv에게 던져준다. libuv 내에 있는 Event Loop에게 Callback으로서 등록된다.  </p><p>그러한 Event Loop는 다음과 같은 phase로 동작하고 있다.<br>각 phase들은 Queue를 가지고 있으며 이 Queue에는 특정 이벤트의 Callback들을 넣고 Event Loop가 해당 Phase를 호출할때 실행된다. </p><blockquote><p><em>Timers</em>: setTimeout()과 setInterval과 같은 Timer 계열의 Callback들이 처리된다.<br><em>I/O Callbacks</em>: Close Callback, Timer로 스케쥴링된 Callback. setImmediate()를 제외한 거의 모든 Callback들을 집핸한다.<br><em>idle, prepare</em>: 내부용으로만 사용 모든 Queue가 비어있으면 idle이 되서 tick frequency가 떨어짐<br><em>poll</em>: Event Loop가 uv__io_poll()을 호출했을때 poll Queue에 있는 Event, Callback들을 처리함.<br><em>check</em>: setImmediate() Callback은 여기서 호출되고 집행된다.<br><em>Close Callback</em>: .on(‘close’, …) 같은 것을이 처리됨. </p></blockquote><p>Event Loop는 round-robin 방식으로 Nodejs Process가 종료될때까지 일정 규칙에 따라 여러개의 Phase들을 계속 순회한다. Phase들은 각각의 Queue들을 관리하고, 해당 Queue들은 FIFO 순서로 Callback Function들을 처리한다.</p><ul><li>NodeJS module</li></ul><blockquote><p>module.exports: nodejs에서 .js파일을 만들어서 객체를 따로 모아놓은 것들을 module이라고 부른다. 그것을 외부로 export하기 위해서 module.exports 객체로 만들어 놓은 것이다.<br>exports: 이는 module.exports를 call by reference로 가리키고 있는 변수이다. 따라서 이를 바로 쓸 수는 없고 다른 property로 지정해서 써야한다. </p></blockquote><ul><li>Async/Await, Promise</li></ul><p>Promise는 JS Asynchoronous 처리에 사용되는 객체이다.<br>그리고 이 Promise 객체를 반환하게 하는 decorator가 async이고 Async 함수 안에서 다른 Async 작업의 Blocking을 담당하는 것이 await이다.</p><h2 id="Object-Oriented-Programming-Basic"><a href="#Object-Oriented-Programming-Basic" class="headerlink" title="Object Oriented Programming Basic"></a>Object Oriented Programming Basic</h2><h3 id="Properties-of-OOP"><a href="#Properties-of-OOP" class="headerlink" title="Properties of OOP"></a>Properties of OOP</h3><p>OOP에는 4가지 특성이 있다. </p><ol><li>추상화: 필요로 하는 속성이나 행동을 추출하는 작업</li><li>캡슐화: 낮은 결합도를 유지할 수 있도록 설계하는 것</li><li>상속: 일반화 관계(Generalization)라고도 하며, 여러 개체들이 지닌 공통된 특성을 부각시켜 하나의 개념이나 법칙으로 성립하는 과정</li><li>다형성: 서로 다른 클래스의 객체가 같은 메시지를 받았을 때 각자의 방식으로 동작하는 능력</li></ol><p>객체 지향 설계 과정</p><ul><li>제공해야 할 기능을 찾고 세분화한다. 그리고 그 기능을 알맞은 객체에 할당한다.</li><li>기능을 구현하는데 필요한 데이터를 객체에 추가한다.</li><li>그 데이터를 이용하는 기능을 넣는다.</li><li>기능은 최대한 캡슐화하여 구현한다.</li><li>객체 간에 어떻게 메소드 요청을 주고받을 지 결정한다.</li></ul><h3 id="5-Principle"><a href="#5-Principle" class="headerlink" title="5 Principle"></a>5 Principle</h3><p>SOLID라고 부르는 5가지 설계 원칙이 존재한다.</p><ul><li><p>SRP(Single Responsibility) - 단일 책임 원칙</p><p>  클래스는 단 한 개의 책임을 가져야 한다.</p><p>  클래스를 변경하는 이유는 단 한개여야 한다.</p><p>  이를 지키지 않으면, 한 책임의 변경에 의해 다른 책임과 관련된 코드에 영향이 갈 수 있다.</p></li></ul><ul><li><p>OCP(Open-Closed) - 개방-폐쇄 원칙</p><p>  확장에는 열려 있어야 하고, 변경에는 닫혀 있어야 한다.</p><p>  기능을 변경하거나 확장할 수 있으면서, 그 기능을 사용하는 코드는 수정하지 않는다.</p><p>  이를 지키지 않으면, instanceof와 같은 연산자를 사용하거나 다운 캐스팅이 일어난다.</p></li></ul><ul><li><p>LSP(Liskov Substitution) - 리스코프 치환 원칙</p><p>  상위 타입의 객체를 하위 타입의 객체로 치환해도, 상위 타입을 사용하는 프로그램은 정상적으로 동작해야 한다.</p><p>  상속 관계가 아닌 클래스들을 상속 관계로 설정하면, 이 원칙이 위배된다.</p></li></ul><ul><li><p>ISP(Interface Segregation) - 인터페이스 분리 원칙</p><p>  인터페이스는 그 인터페이스를 사용하는 클라이언트를 기준으로 분리해야 한다.</p><p>  각 클라이언트가 필요로 하는 인터페이스들을 분리함으로써, 각 클라이언트가 사용하지 않는 인터페이스에 변경이 발생하더라도 영향을 받지 않도록 만들어야 한다.</p></li></ul><ul><li><p>DIP(Dependency Inversion) - 의존 역전 원칙</p><p>  고수준 모듈은 저수준 모듈의 구현에 의존해서는 안된다.</p><p>  저수준 모듈이 고수준 모듈에서 정의한 추상 타입에 의존해야 한다.</p><p>  즉, 저수준 모듈이 변경돼도 고수준 모듈은 변경할 필요가 없는 것이다.</p></li></ul>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Interview/">Interview</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Networking/">Networking</category>
      
      <category domain="https://kimh060612.github.io/tags/Operating-System/">Operating System</category>
      
      <category domain="https://kimh060612.github.io/tags/Javascript/">Javascript</category>
      
      <category domain="https://kimh060612.github.io/tags/DB/">DB</category>
      
      <category domain="https://kimh060612.github.io/tags/Algorithm/">Algorithm</category>
      
      <category domain="https://kimh060612.github.io/tags/Data-Structure/">Data Structure</category>
      
      
      <comments>https://kimh060612.github.io/2022/04/23/interview/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Deep Dark Docker - Introduction</title>
      <link>https://kimh060612.github.io/2022/03/13/docker-start/</link>
      <guid>https://kimh060612.github.io/2022/03/13/docker-start/</guid>
      <pubDate>Sun, 13 Mar 2022 05:57:31 GMT</pubDate>
      
        
        
      <description>&lt;h3 id=&quot;Index&quot;&gt;&lt;a href=&quot;#Index&quot; class=&quot;headerlink&quot; title=&quot;Index&quot;&gt;&lt;/a&gt;Index&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Post의 주제 소개&lt;/li&gt;
&lt;li&gt;강의 내용&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h</description>
        
      
      
      
      <content:encoded><![CDATA[<h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li>Post의 주제 소개</li><li>강의 내용</li></ol><p><br></p><h3 id="Post의-주제-소개"><a href="#Post의-주제-소개" class="headerlink" title="Post의 주제 소개"></a>Post의 주제 소개</h3><hr><p>이 카테고리의 포스트는 Docker에 대해서 더 딥 다크한 부분까지 알고 싶어하는 사람들을 위해서 만들어 나갈 것이다. 먼저 그 전에 Docker에 대해서 잠깐 짚고 넘어가는 것이 좋을 것 같다. </p><blockquote><p>Docker</p></blockquote><p>Docker는 수 많은 Containerization Software 중 하나이다. open source이며 가장 유명하기도 하다. 그렇다면 Containerization은 무엇일까?</p><blockquote><p>Containerization</p></blockquote><p>여기서는 RedHat 공식 홈페이지에서 나온 문구를 인용해 보도록 하겠다. </p><p><em>컨테이너화란 소프트웨어 코드를 라이브러리, 프레임워크 및 기타 종속성과 같은 필수 요소와 함께 패키지에 포함하여 각자의 “컨테이너”로 분리하는 것을 뜻합니다.</em></p><p>간단하게 말하면 우리가 작성한 Application을 운영 체제 내에서 하나의 고립된 공간을 만들어 패키징 하는 것을 말한다. </p><p>주로 사람들이 Virtual Machine하고 비교를 하곤 한다. 하지만 필자의 생각으로는 비교 자체가 조금 잘못되었다. Virtual Machine은 OS Kernel 바로 위에 Hypervisor라는 가상화 layer를 추가하여 별도의 OS를 올릴 수 있게 가상화를 하는 것이다. (밑의 그림이 아주 좋은 예시이다.)<br>그에 반해서 Docker는 기존에 OS에서 돌아가는 Process의 일종이다. 하지만 그 Process가 사용할 수 있는 PID, Network Interface, CPU, Memory 등의 여러 자원들을 다른 Process들과 고립시켜서 마치 독립된 머신 위에서 돌아가는 것 “처럼” 만드는 것이다.<br>둘은 엄밀히 다른 목적을 가지고 사용되어야 한다. 누가 더 좋냐의 문제가 아니라 때에 맞춰서 적절한 기술을 사용해야하는 것이다.</p><p align="center"><img src="https://kimh060612.github.io/img/Virtualization.png" width="100%"></p><p>그래서 이 카테고리에 해당하는 포스트들은 뭔 내용을 다루는가?<br>답은 간단하다</p><blockquote><p>Docker는 어떻게 Process를 Isolation 하는가?</p></blockquote><p>Docker가 어떤 기술을 사용해서 process를 고립시키는지 OS, Computer Network의 관점에서 서술할 것이다.<br>여기서는 어떻게 Docker를 사용하는 방법 같은 것은 일체 다루지 않을 것이다. 이미 Docker를 능숙하게 다룰 수 있는 사람이 어떻게 하면 좀 더 효율적으로 Docker를 사용할 수 있는지에 대한 Insight를 제공하는 목적으로 서술될 것이다. 그래서 제목이 Deep Dark Docker이다. </p><p><del>진짜 이딴걸 누가 볼까 싶다</del></p><h3 id="강의-내용"><a href="#강의-내용" class="headerlink" title="강의 내용"></a>강의 내용</h3><hr><p>강의는 크게 다음과 같은 주제를 필두로 전개될 것이다. </p><ol><li>PID/Network/IPC Isolation - Linux Namespace</li><li>Network Isolation Advanced - Docker Network</li><li>Computing Resource Isolation - Cgorup</li><li>Docker File System Isolation - Docker Volume, linux Namespace</li></ol><p>우선 Docker가 process id, network interface, IPC 같은 자원들을 어떻게 isolation하는지를 다룰 것이다. 이때 주요하게 쓰이는 기술이 바로 Linux Namespace이다. 따라서 이를 Deep Dark하게 다뤄볼 것이다.</p><p>그리고 Web Service를 구축하는데 있어서 가장 중요한 부분인 “어떻게 Network를 구성할 것이가”에 대한 내용을 다룰 것이다. 이는 Docker Network를 통해서 조금 실용적으로 다뤄볼까 한다. </p><p>다음으로는 Docker가 어떻게 CPU, RAM Memory 같은 자원을 Container에게 할당하고 제한하는지를 알아볼 것이다. 이때 사용되는 기술이 Control Group인데, 이 또한 Deep Dark하게 알아보고자 한다.</p><p>그리고 마지막으로 Docker의 File System에 대해서 알아볼 것이다. 이는 비단 Docker가 어떻게 File System을 고립시키는지 알아보고 실습을 통해서 어떻게 하면 안전하게 docker file system을 관리할 수 있는지에 대해서 알아본다.</p><p>진짜 이쯤 설명하고 나니 누가 볼까 싶지만 일단 끄적여 보겠다. 필자도 많이 부족하므로 틀린 부분이 있다면 망설이지 말고 지적해 줬으면 한다.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Containerization/">Containerization</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Containerization/">Containerization</category>
      
      <category domain="https://kimh060612.github.io/tags/Lightweight-Virtualization/">Lightweight Virtualization</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/13/docker-start/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>통신 Protocol 공부 - Introduction</title>
      <link>https://kimh060612.github.io/2022/03/13/Http-Start/</link>
      <guid>https://kimh060612.github.io/2022/03/13/Http-Start/</guid>
      <pubDate>Sat, 12 Mar 2022 17:14:49 GMT</pubDate>
      
        
        
      <description>&lt;h3 id=&quot;Index&quot;&gt;&lt;a href=&quot;#Index&quot; class=&quot;headerlink&quot; title=&quot;Index&quot;&gt;&lt;/a&gt;Index&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;통신 Protocol 공부 배경&lt;/li&gt;
&lt;li&gt;참고할 서적들&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;br</description>
        
      
      
      
      <content:encoded><![CDATA[<h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li>통신 Protocol 공부 배경</li><li>참고할 서적들</li></ol><p><br></p><h3 id="Network-Protocol-공부-배경"><a href="#Network-Protocol-공부-배경" class="headerlink" title="Network Protocol 공부 배경"></a>Network Protocol 공부 배경</h3><hr><p>필자가 DDH라는 스타트업에서 일하며서 가장 크게 느낀 것이 바로 현대적인 Computer Networking에 대한 절대적인 지식 부족이었다.<br>탄탄한 기초를 가지고 있는 좋은 Engineer가 되기 위해서 TCP/IP에 대한 이해와 HTTP, gRPC에 대한 이해는 필수 불가결하다고 생각한다.  </p><p>필자의 통신 프로토콜 공부는 Go언어를 기반으로 진행될 예정이며, 다른 포스트들과는 다르게 실습과 이론을 나누지 않을 예정이다. 이것 만큼은 나누는 것이 오히려 큰 혼란을 불러 일으킬 것 같다.</p><p>다음과 같은 큰 주제를 바탕으로 공부가 진행될 것이다.</p><ol><li>Network System의 개요</li><li>TCP Socket 통신의 기초</li><li>HTTP 기초 (HTTP/1.1 정의 및 응용)</li><li>HTTP 심화 (HTTP/2.0 및 gRPC 관련 내용)</li></ol><p>위의 주제들은 1개당 1개의 포스트로 절대 안 끝나고 소 Chapter로 나뉘어 상세하게 다룰 것이다. 겸사겸사 하면서 Go 언어의 문법도 상세히 다룰 예정이다. (랄까 필자도 공부하면서 다룰 것이라 틀린 내용이 있으면 제발 지적좀 부탁한다.)</p><h3 id="참고할-서적들"><a href="#참고할-서적들" class="headerlink" title="참고할 서적들"></a>참고할 서적들</h3><hr><ol><li><a href="http://www.kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&amp;ejkGb=KOR&amp;barcode=9791191600643">Go 언어를 활용한 네트워크 프로그래밍</a></li><li><a href="http://www.kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&amp;ejkGb=KOR&amp;barcode=9788966261208">HTTP 완벽 가이드</a></li></ol>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Networking/">Networking</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Networking/">Networking</category>
      
      <category domain="https://kimh060612.github.io/tags/Computer-Science/">Computer Science</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/13/Http-Start/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Operating System 공부 - Introduction</title>
      <link>https://kimh060612.github.io/2022/03/13/OS-Start/</link>
      <guid>https://kimh060612.github.io/2022/03/13/OS-Start/</guid>
      <pubDate>Sat, 12 Mar 2022 17:13:29 GMT</pubDate>
      
        
        
      <description>&lt;h3 id=&quot;Index&quot;&gt;&lt;a href=&quot;#Index&quot; class=&quot;headerlink&quot; title=&quot;Index&quot;&gt;&lt;/a&gt;Index&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Operating System 공부 배경&lt;/li&gt;
&lt;li&gt;참고할 서적들&lt;/li&gt;
&lt;/ol&gt;
&lt;</description>
        
      
      
      
      <content:encoded><![CDATA[<h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li>Operating System 공부 배경</li><li>참고할 서적들</li></ol><p><br></p><h3 id="Operating-System-공부-배경"><a href="#Operating-System-공부-배경" class="headerlink" title="Operating System 공부 배경"></a>Operating System 공부 배경</h3><hr><p>필자가 블로그를 시작한 현 시점에서 아직 머학생 2학년이다. (휴학중) 절대적으로 CS관련 전공 지식이 부족한 가운데 스스로 공부를 하지 않으면 뒤처질 것 같다는 느낌을 씨게 받아서 이렇게 공부를 시작하기 위해 블로그 포스팅을 시작한다.<br>주로 <a href="http://www.kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&amp;ejkGb=KOR&amp;barcode=9788997570577">공룡책</a>을 가지고 공부를 할 예정이며 언제나 그랬듯이 필자의 포스팅은 1개의 주제를 이론/실습 2가지 파트로 나누어 진행된다.<br>그리고 언어는 Rust로 진행될 것이다. 공룡책에서는 C로 구현했는데(적어도 필자가 가지고 있는 서적판에서는) 조금 다르게 진행해볼까 한다.  </p><p>Rust는 Stack Overflow에서 “개발자들에게 가장 사랑받는 언어 Top 1”을 6년째 유지중이며, MS는 C/C++로 짜여진 코드를 Rust로 Migration하고 있다고 한다. 그런 의미에서 Rust를 한번이라도 접해보는 것이 나의 개발 능력을 한단계 Upgrade 시켜줄 것이라고 믿고 한번 고난의 길을 걸어볼까 한다.</p><p>또한 필자의 Toy Project에서도 Rust를 사용할 예정이라 일석 이조라고 생각한다. 이 기회에 Rust를 한번 찐하게 공부해 봐야할 것 같다.</p><h3 id="참고할-서적들"><a href="#참고할-서적들" class="headerlink" title="참고할 서적들"></a>참고할 서적들</h3><hr><ol><li><a href="http://www.kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&amp;ejkGb=KOR&amp;barcode=9788997570577">공룡책</a></li><li><a href="http://www.yes24.com/Product/Goods/90124877">운영체제와 정보기술의 원리</a></li></ol>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Operating-System/">Operating System</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Computer-Science/">Computer Science</category>
      
      <category domain="https://kimh060612.github.io/tags/Operating-System/">Operating System</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/13/OS-Start/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Deep learning Model Serving 강의 part.B</title>
      <link>https://kimh060612.github.io/2022/03/05/Serve-B/</link>
      <guid>https://kimh060612.github.io/2022/03/05/Serve-B/</guid>
      <pubDate>Sat, 05 Mar 2022 10:29:16 GMT</pubDate>
      
        
        
      <description>&lt;h3 id=&quot;Index&quot;&gt;&lt;a href=&quot;#Index&quot; class=&quot;headerlink&quot; title=&quot;Index&quot;&gt;&lt;/a&gt;Index&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;del&gt;Tensorflow Serving Server&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;T</description>
        
      
      
      
      <content:encoded><![CDATA[<h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li><del>Tensorflow Serving Server</del></li><li><del>Tensorflow Serving Client</del></li><li>Tensorflow Serving Application</li></ol><p><br></p><h3 id="Tensorflow-Serving-Application"><a href="#Tensorflow-Serving-Application" class="headerlink" title="Tensorflow Serving Application"></a>Tensorflow Serving Application</h3><hr><p>이번 파트에서는 flask를 이용해서 간단한 웹 페이지를 만들어서 배포해보고 tensorflow serving과 통신하는 것까지 구현해 보도록 하겠다.</p><p>일단 간단하게 HTML 페이지를 작성해 보도록 하겠다.</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>Upload Your Image<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">form</span> <span class="attr">id</span>=<span class="string">&quot;upload&quot;</span> <span class="attr">action</span>=<span class="string">&quot;/predict&quot;</span> <span class="attr">method</span>=<span class="string">&quot;POST&quot;</span> <span class="attr">enctype</span>=<span class="string">&quot;multipart/form-data&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">button</span> <span class="attr">class</span>=<span class="string">&quot;btn&quot;</span>&gt;</span>Upload<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;file&quot;</span> <span class="attr">value</span>=<span class="string">&quot;Upload&quot;</span> <span class="attr">name</span>=<span class="string">&quot;image&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">br</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>Result<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        &#123;% if label %&#125;</span><br><span class="line">            <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;result&quot;</span>&gt;</span></span><br><span class="line">                &#123;&#123; label &#125;&#125;</span><br><span class="line">            <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">        &#123;% endif %&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">form</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure><p>귀찮아서 body만 가져왔다.<br>대충 이렇게 페이지를 짜주자. 왜냐면 메인은 이게 아니니깐.</p><p>그리고 다음과 같이 flask server를 구성해 보겠다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">classes = [<span class="string">&quot;airplane&quot;</span>, <span class="string">&quot;car&quot;</span>, <span class="string">&quot;bird&quot;</span>, <span class="string">&quot;cat&quot;</span>, <span class="string">&quot;deer&quot;</span>, <span class="string">&quot;dog&quot;</span>, <span class="string">&quot;frog&quot;</span>, <span class="string">&quot;horse&quot;</span>, <span class="string">&quot;boat&quot;</span>, <span class="string">&quot;truck&quot;</span>]</span><br><span class="line">headers = &#123;<span class="string">&quot;content-type&quot;</span>: <span class="string">&quot;application/json&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/&#x27;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">index</span>():</span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">&#x27;index.html&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/predict&#x27;</span>, methods=[<span class="string">&quot;POST&quot;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>():</span><br><span class="line">    data = request.files[<span class="string">&quot;image&quot;</span>].read()</span><br><span class="line">    image = Image.<span class="built_in">open</span>(io.BytesIO(data))</span><br><span class="line">    </span><br><span class="line">    image = image.convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">    image = image.resize((<span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">    image = img_to_array(image)</span><br><span class="line">    image = np.expand_dims(image, axis=<span class="number">0</span>)</span><br><span class="line">    image = np.asarray(image, dtype=np.uint8)</span><br><span class="line">    </span><br><span class="line">    data = json.dumps(&#123;<span class="string">&quot;signature_name&quot;</span>: <span class="string">&quot;serving_default&quot;</span>, <span class="string">&quot;instances&quot;</span>: image.tolist()&#125;)</span><br><span class="line">    json_response = requests.post(<span class="string">&#x27;http://localhost:8501/v1/models/ViT:predict&#x27;</span>, data=data, headers=headers)</span><br><span class="line">    <span class="built_in">print</span>(json_response.text)</span><br><span class="line">    predictions = np.array(json.loads(json_response.text)[<span class="string">&quot;predictions&quot;</span>])</span><br><span class="line">    index = np.argmax(predictions[<span class="number">0</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">&quot;index.html&quot;</span>, label=classes[index])</span><br></pre></td></tr></table></figure><p>굉장히 심플하게 구성했다. 이제 서버를 구동해 주면 이미지를 띄울 수 있는 창이 뜨고 사진을 업로드 하면 inference 결과를 보여준다.</p><p align="center"><img src="https://kimh060612.github.io/img/page1.png" width="100%"></p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Deep-Learning/">Deep Learning</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="https://kimh060612.github.io/tags/Tensorflow2/">Tensorflow2</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/05/Serve-B/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Deep learning Model Serving 강의 part.A</title>
      <link>https://kimh060612.github.io/2022/03/05/Serve-A/</link>
      <guid>https://kimh060612.github.io/2022/03/05/Serve-A/</guid>
      <pubDate>Sat, 05 Mar 2022 10:29:08 GMT</pubDate>
      
        
        
      <description>&lt;h3 id=&quot;Index&quot;&gt;&lt;a href=&quot;#Index&quot; class=&quot;headerlink&quot; title=&quot;Index&quot;&gt;&lt;/a&gt;Index&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Tensorflow Serving Server&lt;/li&gt;
&lt;li&gt;Tensorflow Servin</description>
        
      
      
      
      <content:encoded><![CDATA[<h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li>Tensorflow Serving Server</li><li>Tensorflow Serving Client</li><li>Tensorflow Serving Application</li></ol><p>여기서는 1~2은 Part. A이고 3는 Part. B에서 다루도록 하겠다.<br><br></p><h3 id="Tensorflow-Serving-Server"><a href="#Tensorflow-Serving-Server" class="headerlink" title="Tensorflow Serving Server"></a>Tensorflow Serving Server</h3><hr><p>Tensorflow Serving은 tensorflow로 학습시킨 model을 보다 효율적으로 배포하기 위해 나온 것이다. 이번 포스트에서는 docker를 이용하여 학습시킨 ViT model을 배포하고 HTTP를 통해서 입력과 출력을 주고 받는 예제를 만들어 보겠다.</p><p>우선 그러려면 Tensorflow Serving이 뭔지부터 알아야 한다. Tensorflow serving은 tensorflow로 만들어진 모델을 서비스에 배포하기 위해서 만들어진 하나의 application이라고 생각하면 된다. </p><p align="center"><img src="https://kimh060612.github.io/img/Serving.png" width="100%"></p><p>위의 그림과 같이 Docker와 함께 사용하여 우리가 만든 모델을 Tensorflow Serving에 넣어주면 HTTP/HTTPS/gRPC를 통해서 model의 inference 결과를 받아볼 수 있다.</p><p>종래의 Tensorflow model serving의 경우, 대체적으로 flask를 사용해서 REST API 형식으로 Serving을 했었다. 하지만 그것보다는 tensorflow serving의 성능이 좋다. 이유는 대체적으로 여러 요인이 있지만 대표적으로는 2가지가 있다.</p><ol><li>python의 overhead 해소</li><li>HTTP/2.0을 사용하는 gRPC를 지원하기 때문</li></ol><p>즉, tensorflow serving을 제일 완벽하게 활용하려면 gRPC를 사용해야 하지만 현재로써는 필자의 지식이 부족하기 때문에 일단 HTTP 통신을 사용해 보도록 하겠다. 하지만 그렇더라도 tensorflow serving이 일반 flask를 활용한 serving 보다는 빠르다.</p><p>그렇다면 어떻게 Docker를 사용하여 우리가 만든 모델을 Tensorflow Serving으로 배포할 수 있을까?<br>우선 예제를 보기 전에 자신만의 모델을 만들자. 필자는 ViT를 예시로 들겠다.<br>모델을 만들었다면, 다음과 같은 폴더 구조에 .pb와 함께 다양한 파일들이 모델로써 저장될 것이다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ViT/1/</span><br><span class="line">├── assets</span><br><span class="line">├── variables</span><br><span class="line">│   ├── variables.data-00000-of-00001</span><br><span class="line">│   └── variables.index</span><br><span class="line">├── keras_metadata.pb</span><br><span class="line">└── saved_model.pb</span><br></pre></td></tr></table></figure><p>그렇다면 우리는 이 폴더를 Docker Container에 mount해주고 8501번 포트를 열어주면 된다. 다음과 같은 명령어로 말이다.</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run -p 8501:8501 --name tf_serving -v /path/to/your/model/ViT/:/models/ViT -e MODEL_NAME=ViT -t tensorflow/serving &amp;</span><br></pre></td></tr></table></figure><p>그렇다면 준비 완료이다. 이제 Tensorflow Serving으로 ViT 모델을 Serving한 것이다.<br>물론, 실제 production 할때는 이따구로 하면 큰일난다. 어디까지 예제로 만들기 위해서 간단하게 만든 것이다.</p><h3 id="Tensorflow-Serving-Client"><a href="#Tensorflow-Serving-Client" class="headerlink" title="Tensorflow Serving Client"></a>Tensorflow Serving Client</h3><hr><p>이제 띄워놓은 ViT model에게 HTTP를 통해서 Shiba견의 이미지를 보내고 결과를 받아와보자.</p><p align="center"><img src="https://kimh060612.github.io/img/Shiba.jpg" width="100%"></p><p><del>(머스크형 제발 닥쳐줘)</del></p><p>한번 예제 소스코드를 다음과 같이 짜 보았다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">image = cv2.imread(<span class="string">&quot;./image/Shiba.jpg&quot;</span>)</span><br><span class="line">image = cv2.resize(image, dsize=(<span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">image = np.expand_dims(image, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">data = json.dumps(&#123;<span class="string">&quot;signature_name&quot;</span>: <span class="string">&quot;serving_default&quot;</span>, <span class="string">&quot;instances&quot;</span>: image.tolist()&#125;)</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">&quot;content-type&quot;</span>: <span class="string">&quot;application/json&quot;</span>&#125;</span><br><span class="line">json_response = requests.post(<span class="string">&#x27;http://localhost:8501/v1/models/ViT:predict&#x27;</span>, data=data, headers=headers)</span><br><span class="line">predictions = np.array(json.loads(json_response.text)[<span class="string">&quot;predictions&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(np.argmax(predictions[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><p>우선 데이터는 위와 같은 형식을 유지해주면 된다. 그리고 POST method로 HTTP request를 보내면 결과 tensor가 text 형식으로 온다.</p><p>우리는 그걸 json으로 바꾸고 안에 있는 list를 꺼내서 inference 결과를 받으면 되는 것이다.</p><p>다음 포스트에서는 이걸 이용해서 간단한 application을 flask로 만들어보는 시간을 가져보자.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Deep-Learning/">Deep Learning</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="https://kimh060612.github.io/tags/Tensorflow2/">Tensorflow2</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/05/Serve-A/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Vision Transformer 강의 내용 part.B</title>
      <link>https://kimh060612.github.io/2022/03/05/ViT-B/</link>
      <guid>https://kimh060612.github.io/2022/03/05/ViT-B/</guid>
      <pubDate>Sat, 05 Mar 2022 10:28:46 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;&lt;em&gt;본 포스트는 &lt;a href=&quot;https://medium.com/towards-data-science/is-this-the-end-for-convolutional-neural-networks-6f944dccc2e9&quot;&gt;블로그&lt;/a&gt;와논문 “A</description>
        
      
      
      
      <content:encoded><![CDATA[<p><em>본 포스트는 <a href="https://medium.com/towards-data-science/is-this-the-end-for-convolutional-neural-networks-6f944dccc2e9">블로그</a>와논문 “An Image is Worth 16x16 Words: Transformers for iamge recognition at scale”을 참조하여 작성되었음을 알립니다.</em></p><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li><del>CNN의 종말</del></li><li><del>Vision Transformer의 구조</del></li><li><del>ViT Inspection</del><ul><li><del>Embedding Filters</del></li><li><del>Positional Encoding</del></li><li><del>Attention Distance</del></li></ul></li><li>practice</li></ol><p><br></p><h3 id="practice"><a href="#practice" class="headerlink" title="practice"></a>practice</h3><hr><p>이제 필자의 Deep learning 포스트도 꽤나 현대적인 수준의 모델을 다루게 되었다. 그리고 이번에는 2019년도에 나온 ViT의 구현이다. ViT의 구현은 생각보다 어렵지 않다. 왜냐면 Transformer의 연장선이기 때문이다. 따라서 기존 Transformer의 부분인 Multi-Head Attention과 Encoder 부분이 아닌 다른 부분만 이 포스트에서 다루도록 하겠다.</p><p>먼저, ViT 모델부터 보고 시작하자.</p><p><em>file: model/model.py</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ViT</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, patch_size, out_dim, mlp_dim, </span></span><br><span class="line"><span class="params">                 num_layer, d_model, num_haed, d_ff, drop_out_prob = <span class="number">0.2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ViT, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.patch_size = patch_size</span><br><span class="line">        </span><br><span class="line">        self.patch_gen = GeneratePatch(patch_size=patch_size)</span><br><span class="line">        self.linear_proj = keras.layers.Dense(d_model, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        self.encoders = [ Encoder(d_model=d_model, num_head=num_haed, d_ff=d_ff, drop_out_prob=drop_out_prob, name = <span class="string">&quot;Encoder_&quot;</span> + <span class="built_in">str</span>(i + <span class="number">1</span>)) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layer) ]</span><br><span class="line">        </span><br><span class="line">        self.dense_mlp = keras.layers.Dense(mlp_dim, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        self.dropout = keras.layers.Dropout(drop_out_prob)</span><br><span class="line">        self.dense_out = keras.layers.Dense(out_dim, activation=<span class="string">&quot;softmax&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build</span>(<span class="params">self, x_shape</span>):</span><br><span class="line">        num_patch = (x_shape[<span class="number">1</span>] * x_shape[<span class="number">2</span>]) // (self.patch_size * self.patch_size) </span><br><span class="line">        </span><br><span class="line">        self.pos_emb = self.add_weight(<span class="string">&quot;pos_emb&quot;</span>, shape=(<span class="number">1</span>, num_patch + <span class="number">1</span>, self.d_model))</span><br><span class="line">        self.class_emb = self.add_weight(<span class="string">&quot;class_emb&quot;</span>, shape=(<span class="number">1</span>, <span class="number">1</span>, self.d_model)) </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x, training</span>):</span><br><span class="line">        </span><br><span class="line">        patches = self.patch_gen(x)</span><br><span class="line">        x = self.linear_proj(patches)</span><br><span class="line">        </span><br><span class="line">        batch_size = tf.shape(x)[<span class="number">0</span>]</span><br><span class="line">        class_emb = tf.broadcast_to(self.class_emb, [batch_size, <span class="number">1</span>, self.d_model])    </span><br><span class="line">        x = tf.concat([class_emb, x], axis=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        x = x + self.pos_emb</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.encoders:</span><br><span class="line">            x = layer(x, training)</span><br><span class="line">        </span><br><span class="line">        x = self.dense_mlp(x[:, <span class="number">0</span>, :])</span><br><span class="line">        x = self.dropout(x)</span><br><span class="line">        x = self.dense_out(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>먼저, 시작 전에 이번에는 다른 모델들과는 사뭇 다르게 build 함수를 overriding해서 사용하였다. 그 이유는 뭐냐? 이전에 ViT의 정의를 보면 명확해 진다. </p><ol><li>$x_{class}$는 BERT에서 사용되는 것과 똑같은 token이다. 이의 구현 방법은 part.B에서 더욱 자세히 다루어 보도록 하겠다.</li><li>각 Image Patch들은 1 개의 FCNN layer를 거치게 된다. 이때, Bias는 없다.</li><li>위 표기 중에 $LN$은 Layer Normalization의 약자이다. </li><li>Encoder를 $L$번 반복하고 나온 결과를 MLP에 넣는다.</li><li>최종 결과에 다시 한번 Layer Normalization을 진행한다. 이때, sequence의 마지막 Component만을 가져와서 진행한다.</li></ol><p>여기서 논문을 보면 learnable class token $x<em>{class}$라고 나온다. 한마디로 맨 앞에 꼽사리 끼는 $x</em>{class}$ token 또한 학습이 가능한 weight여야 한다는 것이다. 그리고 여기서는 positional encoding 또한 학습이 가능한 weight 여야 한다. 그래서 입력 dimension을 사전에 받아서 모델을 빌드할때 이들을 정의해 줘야한다.</p><p>그리고 Image를 Flatten하고 Dense에 넣어줘야 하는데, 이 과정은 다른 layer를 통해서 진행할 것이다. 다음을 보자.</p><p><em>file: model/layer.py</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GeneratePatch</span>(keras.layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, patch_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(GeneratePatch, self).__init__()</span><br><span class="line">        self.patch_size = patch_size</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, images</span>):</span><br><span class="line">        batch_size = tf.shape(images)[<span class="number">0</span>]</span><br><span class="line">        patches = tf.image.extract_patches(images=images, </span><br><span class="line">                                        sizes=[<span class="number">1</span>, self.patch_size, self.patch_size, <span class="number">1</span>], </span><br><span class="line">                                        strides=[<span class="number">1</span>, self.patch_size, self.patch_size, <span class="number">1</span>], rates=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">&quot;VALID&quot;</span>)</span><br><span class="line">        patch_dims = patches.shape[-<span class="number">1</span>]</span><br><span class="line">        patches = tf.reshape(patches, [batch_size, -<span class="number">1</span>, patch_dims]) <span class="comment">#here shape is (batch_size, num_patches, patch_h*patch_w*c) </span></span><br><span class="line">        <span class="keyword">return</span> patches</span><br></pre></td></tr></table></figure><p>이 layer를 이용해서 image를 patch로 나눈 뒤에 flatten하고 ViT에서 Dense를 거쳐서 Transformer의 입력으로써 사용한다.<br>나머지는 Transformer와 같다. 딱히 다를 것이 없다.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Deep-Learning/">Deep Learning</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="https://kimh060612.github.io/tags/Tensorflow2/">Tensorflow2</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/05/ViT-B/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Vision Transformer 강의 내용 part.A</title>
      <link>https://kimh060612.github.io/2022/03/05/ViT-A/</link>
      <guid>https://kimh060612.github.io/2022/03/05/ViT-A/</guid>
      <pubDate>Sat, 05 Mar 2022 10:28:43 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;&lt;em&gt;본 포스트는 &lt;a href=&quot;https://medium.com/towards-data-science/is-this-the-end-for-convolutional-neural-networks-6f944dccc2e9&quot;&gt;블로그&lt;/a&gt;와논문 “A</description>
        
      
      
      
      <content:encoded><![CDATA[<p><em>본 포스트는 <a href="https://medium.com/towards-data-science/is-this-the-end-for-convolutional-neural-networks-6f944dccc2e9">블로그</a>와논문 “An Image is Worth 16x16 Words: Transformers for iamge recognition at scale”을 참조하여 작성되었음을 알립니다.</em></p><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li>CNN의 종말</li><li>Vision Transformer의 구조</li><li>ViT Inspection<ul><li>Embedding Filters</li><li>Positional Encoding</li><li>Attention Distance</li></ul></li><li>practice</li></ol><p>여기서는 1~2은 Part. A이고 3는 Part. B에서 다루도록 하겠다.<br><br></p><h3 id="CNN의-종말"><a href="#CNN의-종말" class="headerlink" title="CNN의 종말"></a>CNN의 종말</h3><hr><p>그렇다. 자연어 처리에서 큰 활약을 보여주던 Transformer는 Vision 영역에도 침범한 것이다. 필자가 이 논문을 처음 보았을때 느꼈던 감정은 아쉬움이었다. 마치 떠나보낸 옛 애인같은 느낌이랄까..? 무슨 헛소리냐 느낄텐데, 고딩학생때부터 필자는 CNN에 미친듯이 시간을 할애하였기에 (필자의 CNN 포스팅 내용은 고딩때 정리한 것을 조금 다듬어서 쓴 것이다. 심지어 그걸 C++로까지 구현했으니 말 다했다 ㅋㅋ;;) 이제 기술의 진보가 내가 가장 아끼던 도구를 구식 취급하는 것이다. 하지만 동시에 온 몸에 전율을 느끼기도 하였다. 시대가 흐른다는 것을 몸소 느끼고 있었기 때문이다.</p><p>각설하고, CNN은 Vision 분야에서 Transformer에 비해 다음과 같은 패배 요인이 있다.</p><p>“CNN은 공간적인 정보를 Encoding하는데 실패했다.”</p><p>이게 머선 소리냐? CNN은 Filter를 학습해서 정보를 습득하였는데, 그것들 간의 연결점이 없다는 것이다. 이를 비유적으로 표현한 그림이 다음과 같다.</p><p align="center"><img src="https://kimh060612.github.io/img/Face.png" width="100%"></p><p>위 그림은 CNN의 관점으로 왼쪽이나 오른쪽이나 별반 다를게 없다. 이러한 부분이 CNN이 transformer에 밀리게 되는 요인이 되었다.<br>이 과정에 대해서는 다다음 파트에서 자세히 알아보도록 하자.</p><h3 id="Vision-Transformer-ViT-의-구조"><a href="#Vision-Transformer-ViT-의-구조" class="headerlink" title="Vision Transformer(ViT)의 구조"></a>Vision Transformer(ViT)의 구조</h3><hr><p>우선 논문에서 제시하는 ViT의 구조를 보자.</p><p align="center"><img src="https://kimh060612.github.io/img/ViT.png" width="100%"></p><p>간단하게 요약하면 다음과 같다.</p><ol><li>Image를 일정 크기의 Patch로 분할한다.</li><li>Image를 Flatten하고 FCNN Layer에 거쳐서 일정 크기의 벡터로 만든다.</li><li>Positional Encoding과 함께 Encoder-Only Transformer에 넣는다. </li><li>결과를 MLP에 넣고 Classification한다.</li></ol><p><del>참 쉽죠?</del></p><p>여기까지만 보면 매우 간단하다. 물론 Transformer를 알고 있다는 가정 하에.<br>따라서 필자도 그렇게까지 자세히 파고 들지는 않고 딱 논문에 나와 있는 수준으로만 구조 분석을 하도록 하겠다. 참고로 이번 포스트 시리즈에서는 딱히 성능 분석은 하지 않고 구조만 분석하고 구현하는 것을 목표로 할 예정이다. 필자는 아직 공부중인 학생이기에 너무 많은걸 목표로 하기 보다는 일단 연산을 똑바로 파악하고 구현하는 것 부터 하는 것이 정도라고 생각한다.</p><p>해당 논문에는 매우 친절하게 모델 구조에 대한 수식이 그대로 나와 있다. </p><p align="center"><img src="https://kimh060612.github.io/img/ViTAr.png" width="100%"></p><p>앞선 Transformer 포스트를 읽고 왔다면 이해가 한층 쉬울 것이다. 다만 몇가지만 부연 설명을 하고 자세한 것은 part.B에서 다루도록 하겠다.</p><ol><li>$x_{class}$는 BERT에서 사용되는 것과 똑같은 token이다. 이의 구현 방법은 part.B에서 더욱 자세히 다루어 보도록 하겠다.</li><li>각 Image Patch들은 1 개의 FCNN layer를 거치게 된다. 이때, Bias는 없다.</li><li>위 표기 중에 $LN$은 Layer Normalization의 약자이다. </li><li>Encoder를 $L$번 반복하고 나온 결과를 MLP에 넣는다.</li><li>최종 결과에 다시 한번 Layer Normalization을 진행한다. 이때, sequence의 마지막 Component만을 가져와서 진행한다.</li></ol><p>구조만 놓고 보자면 Transformer만 안다면 전혀 어려운 것이 없다. 다만 구현이 조금 복잡하니 다음 part에서 자세히 다루어 보도록 하자.</p><h3 id="ViT-Inspection"><a href="#ViT-Inspection" class="headerlink" title="ViT Inspection"></a>ViT Inspection</h3><hr><p>양산형 블로그답게, 논문에 있는 내용을 한번 정리해 보도록 하겠다. 밑의 사진은 크게 ViT를 3가지 측면으로 분석한 것에 대한 Figure이다.</p><p align="center"><img src="https://kimh060612.github.io/img/3Component.png" width="100%"></p><h4 id="Embedding-Filters"><a href="#Embedding-Filters" class="headerlink" title="Embedding Filters"></a>Embedding Filters</h4><p>논문의 저자들은 먼저 첫번째로 들어가는 layer에서 Image Patch를 Linear Embedding하는 Dense Weight를 분석해 보았다.<br>그 결과 위의 맨 왼쪽의 사진처럼 보였다는 내용이다. 하지만 이로써는 그럴듯하게 보이는 기저 함수와 비슷하게 보일 뿐이라고 한다. 필자가 보기에도 이걸로 뭔가를 더 해석하기에는 비약이 너무 심하다고 생각한다.</p><h4 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h4><p>그 후에 논문의 저자들은 Positional Encoding Layer의 Weight를 조사했다. Part.B에서도 다루겠지만, 여기서의 Positional Encoding은 learnable한 weight이다. 이를 시각화 한 것이 위의 사진에서 중간 사진이다. 어떻게 시각화 한 것이냐면, 사진의 각 patch들은 7 <em> 7의 크기인데, 해당하는 position의 patch에 대해서 다른 모든 patch들과 cosine similarity를 구한 것이다. 그래서 7 </em> 7 크기의 그리드에 사진들이 붙어있는 것이다.<br>위 그림에 따르면 </p><ol><li>각자 자기 자신의 위치 근처에서 Cosine Similarity가 높다. </li><li>또한 같은 열/행일 수록 유사도가 높다는 것 또한 알 수 있었다. </li><li>그리고 가끔씩 큰 그리드에서 측정하면 sin파동 구조가 발생하였다.</li></ol><p>그리고 저자들의 추가적인 연구에 의해서 2D Positional Encoding을 수행했을때는 성능의 Improvement가 없었다.</p><p>이 4가지 사실을 종합해 보았을때 저자들은 position embedding이 image의 2차원 공간 정보의 형상을 학습할 수 있다고 결론을 지었다. </p><h4 id="Attention-Distance"><a href="#Attention-Distance" class="headerlink" title="Attention Distance"></a>Attention Distance</h4><p>Encoder의 Self-Attention 구조는 얕은 층에서도 Image의 전체적인 정보를 통합하게 해준다. (Attention의 구조상 한개의 층에서도 전체적인 정보를 통합시켜주니깐) 저자들은 각 층별로 나온 Attention Distribution를 이용하여 그들을 Weight로 각 Image Patch들의 Pixel 값들의 차이의 평균을 구하였다.<br>그 결과, 네트워크의 깊이가 깊어질수록 분산은 적어지고 값은 높아지는 것을 확인하였다. 또한 이러한 특성상, 얕은 층의 attention layer들에서 일부 head에 대해서도 높은 attention distance를 보인다. 즉, 얕은 층에서도 전체적인 이미지의 정보를 어느 정도는 통합하고 있었다느 말이 된다. </p><p align="center"><img src="https://kimh060612.github.io/img/AttentionDistribution.png" width="100%"></p><p>저자들은 논문 “Quantifying Attention Flow in Transformers<br>“에 나온 방법을 통해서 Attention score를 input token에 적용하여 계산해본 결과, 꽤나 국지적으로 분류에 의미있는 결과를 얻어낼 수 있었다고 한다. 다음 그림과 같이 말이다.</p><p align="center"><img src="https://kimh060612.github.io/img/AttentionInput.png" width="100%"></p><p>필자도 얼추 이해만 하고 글을 작성하는 것이라 틀린 부분이 있다면 언제든 지적 부탁한다.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Deep-Learning/">Deep Learning</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="https://kimh060612.github.io/tags/Mathematics/">Mathematics</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/05/ViT-A/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Transformer 강의 내용 part.C</title>
      <link>https://kimh060612.github.io/2022/03/05/Transformer-C/</link>
      <guid>https://kimh060612.github.io/2022/03/05/Transformer-C/</guid>
      <pubDate>Sat, 05 Mar 2022 10:28:31 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;&lt;em&gt;본 포스트는 해당 링크의 &lt;a href=&quot;https://wikidocs.net/22893&quot;&gt;블로그&lt;/a&gt;와 논문 “Attention is all you need”를 참조하여 작성되었음을 알립니다.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;Index&quot;</description>
        
      
      
      
      <content:encoded><![CDATA[<p><em>본 포스트는 해당 링크의 <a href="https://wikidocs.net/22893">블로그</a>와 논문 “Attention is all you need”를 참조하여 작성되었음을 알립니다.</em></p><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li><del>Attention!</del><ul><li><del>Seq2Seq</del></li><li><del>Attention in Seq2Seq</del></li></ul></li><li><del>Transformer Encoder</del><ul><li><del>Attention in Transformer</del></li><li><del>Multi-Head Attention</del></li><li><del>Masking</del></li><li><del>Feed Forward</del></li></ul></li><li><del>Transformer Decoder</del></li><li><del>Positional Encoding</del></li><li>Partice<ul><li>Seq2Seq Attention</li><li>Transformer</li></ul></li></ol><p><br></p><h3 id="Partice"><a href="#Partice" class="headerlink" title="Partice"></a>Partice</h3><hr><p>이 파트에서는 지난 시간부터 쭉 다뤄온 Attention과 Transformer를 구현해 보는 시간을 가질 것이다. 본격적으로 Model Subclassing API를 제대로 활용하는 시간이 될 것이다.</p><h4 id="Seq2Seq-Attention"><a href="#Seq2Seq-Attention" class="headerlink" title="Seq2Seq Attention"></a>Seq2Seq Attention</h4><p>Transformer 구조를 보기 전에 Attention을 Seq2Seq 모델에 적용시켜 보도록 하겠다. 먼저 소스코드부터 보고 가자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(keras.layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Attention, self).__init__()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, q, k, v, mask=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># q: (batch_size, seq_len, d_model)</span></span><br><span class="line">        <span class="comment"># k: (batch_size, seq_len, d_model)</span></span><br><span class="line">        <span class="comment"># v: (batch_size, seq_len, d_model)</span></span><br><span class="line"></span><br><span class="line">        matmul_qk = tf.matmul(q, k, transpose_b=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># qk^T : (batch_size, seq_len, seq_len)</span></span><br><span class="line"></span><br><span class="line">        dk = tf.cast(tf.shape(k)[-<span class="number">1</span>], tf.float32)</span><br><span class="line">        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)</span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            scaled_attention_logits += (mask * -<span class="number">1e9</span>)</span><br><span class="line">        </span><br><span class="line">        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-<span class="number">1</span>)</span><br><span class="line">        output = tf.matmul(attention_weights, v)</span><br><span class="line">        <span class="comment"># output: (batch_size, seq_len, d_model)</span></span><br><span class="line">        <span class="keyword">return</span> output, attention_weights</span><br></pre></td></tr></table></figure><p>우선 우리가 사용할 Attention 구조이다. 지난 Transformer part.A에서 정의한 연산(masking 포함)을 고대로 구현한 것이다.<br>이를 어떻게 Seq2Seq 모델에 적용하는지는 밑의 그림과 소스코드를 보자.</p><p align="center"><img src="https://kimh060612.github.io/img/Attention.png" width="100%"></p><p>위 그림에 따르면 일단 Seq2Seq는 Encoder와 Decoder가 각기 다른 모델로 있다. 그리고 Encoder에서 나온 모든 time step의 출력과 Decoder의 출력을 같이 사용해서 연산을 해야할 필요가 있다.</p><p>필자는 일단 Decoder에 Encoder의 모든 Time step의 출력을 넣는 형식으로 구현을 하였다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, WORDS_NUM, emb_dim, hidden_unit, batch_size, *args, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(*args, **kwargs)</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.hidden_unit = hidden_unit</span><br><span class="line">        self.embedding = keras.layers.Embedding(WORDS_NUM, emb_dim)</span><br><span class="line">        self.LSTM = keras.layers.LSTM(hidden_unit, return_state=<span class="literal">True</span>, return_sequences=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, enc_hidden = <span class="literal">None</span></span>):</span><br><span class="line">        x = self.embedding(inputs)</span><br><span class="line">        y, h, _ = self.LSTM(x, initial_state=enc_hidden)</span><br><span class="line">        <span class="keyword">return</span> y, h</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, WORDS_NUM, emb_dim, hidden_unit, *args, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(*args, **kwargs)</span><br><span class="line">        self.embedding = keras.layers.Embedding(WORDS_NUM, emb_dim)</span><br><span class="line">        self.lstm = tf.keras.layers.LSTM(hidden_unit, return_sequences=<span class="literal">True</span>, return_state=<span class="literal">True</span>)</span><br><span class="line">        self.attention = Attention()</span><br><span class="line">        self.dense = tf.keras.layers.Dense(WORDS_NUM, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x, hidden, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        _, h, c = self.lstm(x)</span><br><span class="line">        context_vec, attention_weight = self.attention(h, hidden, hidden, mask=mask)</span><br><span class="line">        </span><br><span class="line">        x_ = tf.concat([context_vec, c], axis=-<span class="number">1</span>)</span><br><span class="line">        out = self.dense(x_)</span><br><span class="line">        <span class="keyword">return</span> out, h, attention_weight</span><br></pre></td></tr></table></figure><p>소스코드를 보기 전에 Attention의 $Q$, $K$, $V$의 정의를 먼저 상기하고 가자.</p><p>$Q$ : 특정 시점의 디코더 셀에서의 은닉 상태<br>$K$ : 모든 시점의 인코더 셀의 은닉 상태들<br>$V$ : 모든 시점의 인코더 셀의 은닉 상태들  </p><p>Encoder에서는 Decoder에서 활용하기 위해서 2개의 출력을 내놓는다. 본인의 출력값과 hidden state의 값이다.</p><p>Decoder에서는 Encoder에서의 Hidden state를 입력으로 받아서 자신의 hidden state와 같이 attention! 을 진행한다.</p><p>이렇게 만들어진 vector와 마지막 출력 값을 concatenation한 값을 dense에 넣어서 최종적인 출력을 내 놓는다.</p><p>이의 training loop를 보면 더 이해가 잘 될 것이다. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@tf.function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">inp, targ, enc_hidden</span>):</span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        _, enc_hidden = encoder(inp, enc_hidden)</span><br><span class="line">        dec_hidden = enc_hidden</span><br><span class="line">        dec_input = tf.expand_dims([targ_lang.word_index[<span class="string">&#x27;&lt;start&gt;&#x27;</span>]] * BATCH_SIZE, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, targ.shape[<span class="number">1</span>]):</span><br><span class="line">            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden)</span><br><span class="line">            loss += loss_function(targ[:, t], predictions)</span><br><span class="line">            dec_input = tf.expand_dims(targ[:, t], <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        batch_loss = (loss / <span class="built_in">int</span>(targ.shape[<span class="number">1</span>]))</span><br><span class="line">        </span><br><span class="line">        variables = encoder.trainable_variables + decoder.trainable_variables</span><br><span class="line">        gradients = tape.gradient(loss, variables)</span><br><span class="line">        optimizer.apply_gradients(<span class="built_in">zip</span>(gradients, variables))</span><br><span class="line">        <span class="keyword">return</span> batch_loss</span><br></pre></td></tr></table></figure><h4 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h4><p>이제 대망의 Transformer이다. 먼저 Transformer를 구현하기 위해서 어떤 Component들이 필요했는지 알아보자.</p><ol><li>Multi-head Attention</li><li>Positional Encoding</li><li>Encoder Blocks</li><li>Decoder Blocks</li></ol><p>우리는 이 4가지 Component들을 각각 순차적으로 구현하고 이를 통해서 최종 모델을 구현할 것이다.</p><p><em>file: model/layer.py</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(keras.layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, num_head</span>):</span><br><span class="line">        <span class="built_in">super</span>(MultiHeadAttention, self).__init__()        </span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> d_model % num_head  == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;Invalid head and d_model!&quot;</span>)</span><br><span class="line">        self.d_k = d_model // num_head</span><br><span class="line">        self.num_head = num_head</span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        </span><br><span class="line">        self.Wq = keras.layers.Dense(self.d_model)</span><br><span class="line">        self.Wk = keras.layers.Dense(self.d_model)</span><br><span class="line">        self.Wv = keras.layers.Dense(self.d_model)</span><br><span class="line">        </span><br><span class="line">        self.dense = keras.layers.Dense(self.d_model, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">split_head</span>(<span class="params">self, batch_size, x</span>):</span><br><span class="line">        x = tf.reshape(x, (batch_size, -<span class="number">1</span>, self.num_head, self.d_k))</span><br><span class="line">        <span class="keyword">return</span> tf.transpose(x, perm=[<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, q, k, v, mask = <span class="literal">None</span></span>):</span><br><span class="line">        batch_size = q.shape[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        q, k, v = self.Wq(q), self.Wk(k), self.Wv(v)</span><br><span class="line">        <span class="comment"># q: (batch_size, seq_len, d_model)</span></span><br><span class="line">        <span class="comment"># k: (batch_size, seq_len, d_model)</span></span><br><span class="line">        <span class="comment"># v: (batch_size, seq_len, d_model)</span></span><br><span class="line">        </span><br><span class="line">        q, k, v = self.split_head(batch_size, q), self.split_head(batch_size, k), self.split_head(batch_size, v)</span><br><span class="line">        <span class="comment"># q: (batch_size, num_head, seq_len, d_k)</span></span><br><span class="line">        <span class="comment"># k: (batch_size, num_head, seq_len, d_k)</span></span><br><span class="line">        <span class="comment"># v: (batch_size, num_head, seq_len, d_v)</span></span><br><span class="line">        </span><br><span class="line">        qkT = tf.matmul(q, k, transpose_b=<span class="literal">True</span>) <span class="comment"># (batch_size, num_head, seq_len, seq_len)</span></span><br><span class="line">        d_k = tf.cast(self.d_k, dtype=tf.float32)</span><br><span class="line">        scaled_qkT = qkT / tf.math.sqrt(d_k)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> mask == <span class="literal">None</span>:</span><br><span class="line">            scaled_qkT += (mask * -<span class="number">1e9</span>)</span><br><span class="line">        </span><br><span class="line">        attention_dist = tf.nn.softmax(scaled_qkT, axis=-<span class="number">1</span>)</span><br><span class="line">        attention = tf.matmul(attention_dist, v) <span class="comment"># (batch_size, num_head, seq_len, d_k)</span></span><br><span class="line">        </span><br><span class="line">        attention = tf.transpose(attention, perm=[<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>]) <span class="comment"># (batch_size, seq_len, num_head, d_k)</span></span><br><span class="line">        concat_attention = tf.reshape(attention, (batch_size, -<span class="number">1</span>, self.d_model)) <span class="comment"># (batch_size, seq_len, d_model)</span></span><br><span class="line">        output = self.dense(concat_attention)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><p>각 연산 뒤에 차원을 적어 두었으니 이해하기는 어렵지 않을 것이다. 구체적인 정의가 떠오르지 않을 독자들을 위해서 Multi-Head Attention의 수식을 적어두고 가겠다.</p><script type="math/tex; mode=display">\text{Attention}(Q, K, V) = \text{Softmax}(\frac{Q_iK_i^T}{\sqrt{d_k}})V_i\tag{definition 3}</script><script type="math/tex; mode=display">M_{out} = \text{Concat}(O_1, O_2, ..., O_{H_n}) W^O\tag{equation 1}</script><p>위 수식을 고대~로 구현한 것 밖에 되지 않는다.</p><p>그리고 positional Encoding은 다음과 같이 구현했다.</p><p><em>file: model/layer.py</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_angles</span>(<span class="params">pos, i, d_model</span>):</span><br><span class="line">    angle_rates = <span class="number">1</span> / np.power(<span class="number">10000</span>, (<span class="number">2</span> * (i//<span class="number">2</span>)) / np.float32(d_model))</span><br><span class="line">    <span class="keyword">return</span> pos * angle_rates</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">positional_encoding</span>(<span class="params">position, d_model</span>):</span><br><span class="line">    angle_rads = get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)</span><br><span class="line"></span><br><span class="line">    angle_rads[:, <span class="number">0</span>::<span class="number">2</span>] = np.sin(angle_rads[:, <span class="number">0</span>::<span class="number">2</span>])</span><br><span class="line">    angle_rads[:, <span class="number">1</span>::<span class="number">2</span>] = np.cos(angle_rads[:, <span class="number">1</span>::<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    pos_encoding = angle_rads[np.newaxis, ...]</span><br><span class="line">    <span class="keyword">return</span> tf.cast(pos_encoding, dtype=tf.float32)</span><br></pre></td></tr></table></figure><p>이것 또한 정의를 고대로 구현한 것이다. <del>(참 쉽죠?)</del></p><script type="math/tex; mode=display">\begin{aligned}    PE_{(pos, 2i)} = \sin(pos/10000^{2i/d_{model}}) \\    PE_{(pos, 2i + 1)} = \cos(pos/10000^{2i/d_{model}})\end{aligned}</script><p>이제 Encoder와 Decoder Block을 구현할 차례이다. 귀찮으니 한번에 소스를 적어 두도록 하겠다.</p><p><em>file: model/layer.py</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(keras.layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, num_head, d_ff, drop_out_prob = <span class="number">0.2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()</span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.num_head = num_head</span><br><span class="line">        </span><br><span class="line">        self.MultiHeadAttention = MultiHeadAttention(d_model=d_model, num_head=num_head)</span><br><span class="line">        </span><br><span class="line">        self.dense_1 = keras.layers.Dense(d_ff, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        self.dense_2 = keras.layers.Dense(d_model, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        self.layernorm1 = keras.layers.LayerNormalization(epsilon=<span class="number">1e-6</span>)</span><br><span class="line">        self.layernorm2 = keras.layers.LayerNormalization(epsilon=<span class="number">1e-6</span>)</span><br><span class="line"></span><br><span class="line">        self.dropout1 = keras.layers.Dropout(drop_out_prob)</span><br><span class="line">        self.dropout2 = keras.layers.Dropout(drop_out_prob)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x, training=<span class="literal">True</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        </span><br><span class="line">        out_atten = self.MultiHeadAttention(x, x, x, mask)</span><br><span class="line">        out_atten = self.dropout1(out_atten, training=training)</span><br><span class="line">        x = self.layernorm1(out_atten + x)</span><br><span class="line">        </span><br><span class="line">        out_dense = self.dense_1(x)</span><br><span class="line">        out_dense = self.dense_2(out_dense)</span><br><span class="line">        out_dense = self.dropout2(out_dense, training=training)</span><br><span class="line">        x = self.layernorm2(out_dense + x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(keras.layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, num_head, d_ff, drop_out_prob = <span class="number">0.2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.num_head = num_head</span><br><span class="line">        self.MultiHeadAttention1 = MultiHeadAttention(d_model, num_head)</span><br><span class="line">        self.MultiHeadAttention2 = MultiHeadAttention(d_model, num_head)</span><br><span class="line">        </span><br><span class="line">        self.dense_1 = keras.layers.Dense(d_ff, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        self.dense_2 = keras.layers.Dense(d_model, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=<span class="number">1e-6</span>)</span><br><span class="line">        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=<span class="number">1e-6</span>)</span><br><span class="line">        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=<span class="number">1e-6</span>)</span><br><span class="line">        self.dropout1 = tf.keras.layers.Dropout(drop_out_prob)</span><br><span class="line">        self.dropout2 = tf.keras.layers.Dropout(drop_out_prob)</span><br><span class="line">        self.dropout3 = tf.keras.layers.Dropout(drop_out_prob)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x, enc_output, training, look_ahead_mask, padding_mask</span>):</span><br><span class="line">        </span><br><span class="line">        out_atten1 = self.MultiHeadAttention1(x, x, x, look_ahead_mask)</span><br><span class="line">        out_atten1 = self.dropout1(out_atten1, training=training)</span><br><span class="line">        x = self.layernorm1(out_atten1 + x)</span><br><span class="line">        </span><br><span class="line">        out_atten2 = self.MultiHeadAttention2(enc_output, enc_output, x, padding_mask)</span><br><span class="line">        out_atten2 = self.dropout2(out_atten2, training=training)</span><br><span class="line">        x = self.layernorm2(out_atten2 + x)</span><br><span class="line">        </span><br><span class="line">        out_dense = self.dense_1(x)</span><br><span class="line">        out_dense = self.dense_2(out_dense)</span><br><span class="line">        out_dense = self.dropout3(out_dense, training=training)</span><br><span class="line">        x = self.layernorm3(out_dense + x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>Encoder는 별로 볼게 없고, Decoder를 보자면 지난번 정의에서 다뤘듯이, 첫번째 Multi-Head Attention과 두번째 Mutli-Head Attention은 다른 입력이 주어지고, 다른 masking이 주어진다.</p><p>따라서 Decoder의 입력으로 출력 sequence, encoder 출력, look ahead masking, padding masking이 들어가야 한다.</p><p>자세한 정의는 part.B를 다시 참고하자.</p><p>참고로, masking은 다음 함수로 만들었다.</p><p><em>file: model/model.py</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_padding_mask</span>(<span class="params">seq</span>):</span><br><span class="line">    seq = tf.cast(tf.math.equal(seq, <span class="number">0</span>), tf.float32)</span><br><span class="line">    <span class="comment"># add extra dimensions to add the padding</span></span><br><span class="line">    <span class="comment"># to the attention logits.</span></span><br><span class="line">    <span class="keyword">return</span> seq[:, tf.newaxis, tf.newaxis, :]  <span class="comment"># (batch_size, 1, 1, seq_len)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_look_ahead_mask</span>(<span class="params">size</span>):</span><br><span class="line">    mask = <span class="number">1</span> - tf.linalg.band_part(tf.ones((size, size)), -<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> mask  <span class="comment"># (seq_len, seq_len)</span></span><br></pre></td></tr></table></figure><p>그리고 최종적으로 이렇게 만든 Encoder, Decoder Block을 쌓아서 Transformer 모델을 만들어야 한다.</p><p>편의상, Encoder모델, Decoder 모델을 만들고 이를 하나로 합쳐서 Transformer 모델을 만들었다.</p><p><em>file: model/model.py</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EncoderModel</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_voc_size, num_layers, max_seq_len, d_model, num_head, d_ff, drop_out_prob = <span class="number">0.2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(EncoderModel, self).__init__()</span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.embedding = tf.keras.layers.Embedding(input_voc_size, d_model)</span><br><span class="line">        self.pos_encoding = positional_encoding(max_seq_len, self.d_model)</span><br><span class="line">        self.enc_layers = [ Encoder(d_model, num_head, d_ff, drop_out_prob) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_layers) ]</span><br><span class="line">        self.dropout = tf.keras.layers.Dropout(drop_out_prob)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x, training, mask</span>):</span><br><span class="line">        </span><br><span class="line">        seq_len = tf.shape(x)[<span class="number">1</span>]</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        x += self.pos_encoding[:, :seq_len, :]</span><br><span class="line">        x = self.dropout(x, training=training)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_layers):</span><br><span class="line">            x = self.enc_layers[i](x, training, mask)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">        </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecoderModel</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, output_voc_size, num_layers, max_seq_len, d_model, num_head, d_ff, drop_out_prob = <span class="number">0.2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(DecoderModel, self).__init__()</span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.embedding = tf.keras.layers.Embedding(output_voc_size, d_model)</span><br><span class="line">        self.pos_encoding = positional_encoding(max_seq_len, self.d_model)</span><br><span class="line">        </span><br><span class="line">        self.dec_layers = [ Decoder(d_model, num_head, d_ff, drop_out_prob) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_layers) ]</span><br><span class="line">        self.dropout = tf.keras.layers.Dropout(drop_out_prob)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x, enc_output, training, look_ahead_mask, padding_mask</span>):</span><br><span class="line">        </span><br><span class="line">        seq_len = tf.shape(x)[<span class="number">1</span>]</span><br><span class="line">        x = self.embedding(x)</span><br><span class="line">        x += self.pos_encoding[:, :seq_len, :]</span><br><span class="line">        x = self.dropout(x, training=training)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_layers):</span><br><span class="line">            x = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Transformer</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_voc_size, output_voc_size, num_layers, max_seq_len_in, max_seq_len_out, d_model, num_head, d_ff, drop_out_prob = <span class="number">0.2</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.Encoder = EncoderModel(input_voc_size, num_layers, max_seq_len_in, d_model, num_head, d_ff, drop_out_prob)</span><br><span class="line">        self.Decoder = DecoderModel(output_voc_size, num_layers, max_seq_len_out, d_model, num_head, d_ff, drop_out_prob)</span><br><span class="line">        </span><br><span class="line">        self.final_layer = tf.keras.layers.Dense(output_voc_size)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training</span>):</span><br><span class="line">        inp, tar = inputs</span><br><span class="line">        </span><br><span class="line">        enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(inp, tar)</span><br><span class="line">        enc_output = self.Encoder(inp, training, enc_padding_mask)</span><br><span class="line">        dec_output = self.Decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)</span><br><span class="line">        </span><br><span class="line">        final_output = self.final_layer(dec_output)</span><br><span class="line">        <span class="keyword">return</span> final_output</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_masks</span>(<span class="params">self, inp, tar</span>):</span><br><span class="line">        enc_padding_mask = create_padding_mask(inp)</span><br><span class="line">        dec_padding_mask = create_padding_mask(inp)</span><br><span class="line"></span><br><span class="line">        look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[<span class="number">1</span>])</span><br><span class="line">        dec_target_padding_mask = create_padding_mask(tar)</span><br><span class="line">        look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> enc_padding_mask, look_ahead_mask, dec_padding_mask</span><br></pre></td></tr></table></figure><p>그리고 Transformer에서 보면 Embedding layer를 사용하는데, 이는 Dense와 결과적인 측면에서는 다를 것이 없디. 하지만 token을 vector로 Embedding하는데 있어서 훨씬 효율적이니 되도록 token을 vector로 임베딩할때 이걸 사용하도록 하자.</p><p>각 Encoder와 Decoder는 num_layer(hyper parameter)만큼 Encoder, Decoder 블록을 반복해서 쌓고, 그것들을 차례로 출력으로 내놓는다. 이제 2개를 합쳐서 간단하게 Transformer 모델이 완성되는 것이다.</p><p>이쯤되면 필자들도 느낄 것이다. 이럴때 Model Subclassing API가 빛을 발휘한다. 이 각각의 Component들을 함수로만 구현하는 것 보다는 class로 묶어서 관리하는 것이 가독성, 유지보수 측면에서 훨씬 이득이다.</p><p>그리고 논문에 의하면, Transformer는 독자적인 learning rate scheduler를 가진다. 이 수식은 다음과 같다.</p><p align="center"><img src="https://kimh060612.github.io/img/lr_schedule.png" width="50%"></p><p>이를 구현하기 위해서 다음과 같이 Custom Scheduler를 만들 수 있다.</p><p><em>file: model/model.py</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CustomSchedule</span>(keras.optimizers.schedules.LearningRateSchedule):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, warmup_steps=<span class="number">4000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(CustomSchedule, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.d_model_save = d_model</span><br><span class="line">        self.d_model = tf.cast(d_model, tf.float32)</span><br><span class="line"></span><br><span class="line">        self.warmup_steps = warmup_steps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, step</span>):</span><br><span class="line">        arg1 = tf.math.rsqrt(step)</span><br><span class="line">        arg2 = step * (self.warmup_steps ** -<span class="number">1.5</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_config</span>(<span class="params">self</span>):</span><br><span class="line">        config = &#123;</span><br><span class="line">            <span class="string">&#x27;d_model&#x27;</span>: self.d_model_save,</span><br><span class="line">            <span class="string">&#x27;warmup_steps&#x27;</span>: self.warmup_steps,</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> config</span><br></pre></td></tr></table></figure><p>여기까지 구현하면 Transformer의 구현은 끝이 난다. 굳이 여기서는 Training loop까지는 다루지 않겠다. 한번 필자가 직접 완성해 보도록 하자. 정 모르겠다면 필자의 github에 완성판이 있으니 직접 가서 찾아 보기를 바란다.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Deep-Learning/">Deep Learning</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="https://kimh060612.github.io/tags/Tensorflow2/">Tensorflow2</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/05/Transformer-C/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Transformer 강의 내용 part.B</title>
      <link>https://kimh060612.github.io/2022/03/05/Transformer-B/</link>
      <guid>https://kimh060612.github.io/2022/03/05/Transformer-B/</guid>
      <pubDate>Sat, 05 Mar 2022 10:28:27 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;&lt;em&gt;본 포스트는 해당 링크의 &lt;a href=&quot;https://wikidocs.net/22893&quot;&gt;블로그&lt;/a&gt;와 논문 “Attention is all you need”를 참조하여 작성되었음을 알립니다.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;Index&quot;</description>
        
      
      
      
      <content:encoded><![CDATA[<p><em>본 포스트는 해당 링크의 <a href="https://wikidocs.net/22893">블로그</a>와 논문 “Attention is all you need”를 참조하여 작성되었음을 알립니다.</em></p><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li><del>Attention!</del><ul><li><del>Seq2Seq</del></li><li><del>Attention in Seq2Seq</del></li></ul></li><li>Transformer Encoder<ul><li>Attention in Transformer</li><li>Multi-Head Attention</li><li>Masking</li><li>Feed Forward</li></ul></li><li>Transformer Decoder</li><li>Positional Encoding</li><li>Partice<ul><li>Seq2Seq Attention</li><li>Transformer</li></ul></li></ol><p>여기서는 1은 Part. A이고 2~4는 Part. B에서, 5는 part. C에서 다루도록 하겠다.<br><br></p><h3 id="Transformer-Encoder"><a href="#Transformer-Encoder" class="headerlink" title="Transformer Encoder"></a>Transformer Encoder</h3><hr><p>자 드디어 대망의 Transformer이다. 현대 Deep learning model의 기초라고도 할 수 있을 만큼 많이 쓰이는 모델이므로 블로그 주제에 선정되었다. 이를 위해서 하고 싶지도 않았던 Attention 공부를 해왔는데, 공부하고 보니 보람 넘치는 시간이었던 것 같다.</p><h4 id="Attention-in-Transformer"><a href="#Attention-in-Transformer" class="headerlink" title="Attention in Transformer"></a>Attention in Transformer</h4><p>우선 Transformer를 제시한 논문의 이름이 “Attention is all you need”라는 것을 파악하고 가자. (필자 생각에는 이때부터 살짝 논문 이름이 제목학원이 된 것 같기도 하다.. ㅋㅋ;;) 한마디로, 기존에 Seq2Seq 같은 경우에는 RNN/LSTM/GRU의 보완제로써 Attention을 사용했다면, Transformer에서는 Attention만을 사용하여 신경망을 구성한다.</p><p align="center"><img src="https://kimh060612.github.io/img/Transformer.png" width="50%"></p><p>일단, 양산형 블로그글의 클리셰답게, Transformer의 논문에서 Model Architecture의 모식도를 가져와 봤다. 여기에 들어가는 Component를 하나하나 분해해 보면 다음과 같이 정리할 수 있다.</p><ol><li>Multi-Head Attention</li><li>Feed Forward Network</li><li>Masked Multi-Head Attention</li><li>Positional Encoding</li><li>*$N$ ?</li><li>Residual Connection</li></ol><p>우리는 이 모두를 하나하나 분해해서 살펴볼 것이다. (5번인 Residual Connection은 다른 Post에서 집중적으로 다루어 볼 것이다.) 그 전에 먼저 Transformer에서 Attention이 어떻게 정의되고 쓰이는지를 알아볼 것이다. 우선, 우리는 Attention을 정의하려면 먼저 $Q$, $K$, $V$를 정의해야한다는 것을 이전 포스트에서 다루었다.</p><p>위 행렬의 크기/정의는 어떤 attention이냐에 따라서 달라진다. 이때 attention의 종류는 이전 포스트에서 언급했던 “누가 만든 attention”이냐가 아니라 어떤 식으로 Attention 연산이 이루어 지냐이다. Transformer에서는 아래의 3가지 타입의 attention이 사용된다.</p><p align="center"><img src="https://kimh060612.github.io/img/attention_type.png" width="50%"></p><p>출처: 위 링크에 나와있는 블로그</p><p>위 3가지 attention에 따라서 $Q$, $K$, $V$의 출처가 달라진다.<br>정리하자면 다음과 같다.</p><p>Encoder의 Self Attention : Query = Key = Value<br>Decoder의 Masked Self Attention : Query = Key = Value<br>Decoder의 Encoder-Decoder Attention : Query : 디코더 벡터 / Key = Value : 인코더 벡터  </p><p>자, 이제 어떻게 $Q$, $K$, $V$가 정의되는지 파트별로 나눠놨으니 남은 것은 본격적으로 연산에 들어가는 것이다.</p><p>그 전에 Transformer에서 사용되는 Hyper Parameter를 먼저 알아보도록 하겠다.</p><ol><li>$d_{model}$ = 512: Transformer의 인코더와 디코더의 입력과 출력의 크기를 결정하는 parameter이다.</li><li>$N$ = 6: Transformer에서 Encoder와 Decoder가 총 몇 개의 층으로 이루어져 있는지를 나타내는 기준이다.</li><li>$H_n$ = 8: Multi head Attention에서 Attention을 병렬로 수행하고 합치는 방식을 사용하는데, 그때 몇개로 분할할지를 결정하는 hyper parameter이다.</li><li>$d<em>{ff}$ = 2048: Transformer의 내부에 Feed Forward 신경망이 존재하는데, 이 신경망의 은닉 unit의 개수를 의미함. 물론, 이 layer의 출력은 당연히 $d</em>{model}$ 이 된다.</li></ol><h4 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h4><p>또 양산형 블로그 클리셰답게 논문에 있는 Figure를 가지고 왔다. </p><p align="center"><img src="https://kimh060612.github.io/img/MHAttention.png" width="75%"></p><p>위 그림을 보면서 설명을 읽으면 이해가 잘 될 수 있도록 글을 구성해 보도록 하겠다.<br>우선 가장 보편적으로 활용되는 자연어 처리를 예로 들고 싶지만, 필자의 성격상 그런 것 보다는 조금 일반적으로 이야기를 하도록 하겠다. 어떤 연속열 데이터 $x<em>1, x_2, x_3 …x_n$ 이 있다고 가정해 보자. 이들 각각이 $x_i \in \mathbb{R}^{d</em>{model}}$ 인 벡터라고 해보자. 자연어 처리라면 Word Embedding으로 생성된 단어 벡터라고 할 수 있고 설령 다른 문제더라도 이것과 비슷하게 representation이 가능하다면 뭐든 학습이 가능하다는 것이다. 이러한 input을 활용해서 $Q$,$K$,$V$를 얻어 보도록 하자.</p><p>우리는 3개의 FCNN Layer를 활용해서 입력으로부터 $Q$,$K$,$V$를 얻어낼 것이다.<br>다음과 같이 FCNN Layer의 Weight를 정의해 보도록 하겠다.</p><script type="math/tex; mode=display">\begin{aligned}    W^Q_i \in \mathbb{R}^{d_{model} * d_k} \\    W^K_i \in \mathbb{R}^{d_{model} * d_k} \\    W^V_i \in \mathbb{R}^{d_{model} * d_v} \end{aligned}\tag{definition 1}</script><p>여기서 $d<em>k = d_v = d</em>{model}/H_n$이다. 그리고 sequence length를 $n$이라고 가정하자. 그렇다면 우리는 결과로써 나오는 각 $Q$,$K$,$V$ 행렬의 결과의 크기를 다음과 같다고 생각할 수 있다. 그리고 여기서 $i$는 $1 \leq i \leq H_n$이다. 나중에 각 i별로 병렬로 계산하고 Concatenation을 진행하는 과정을 거칠 것이다. 그래서 Multi Head Attention이다.</p><script type="math/tex; mode=display">\begin{aligned}    Q_i \in \mathbb{R}^{n * d_k} \\    K_i \in \mathbb{R}^{n * d_k} \\    V_i \in \mathbb{R}^{n * d_v} \end{aligned}\tag{definition 2}</script><p>이 상태에서 지난 포스트에서 주로 다뤘던 Scaled Dot Attention에 대해서 다시 한번 상기하고, 적용해 보자.</p><script type="math/tex; mode=display">\text{Attention}(Q, K, V) = \text{Softmax}(\frac{Q_iK_i^T}{\sqrt{d_k}})V_i\tag{definition 3}</script><p>이 Attention의 결과 행렬을 $O_i$라고 했을때, $O_i \in \mathbb{R}^{n * d_v}$이다.<br>이제 각기 계산한 $O_i$들에 대해서 concatenation을 진행한다. 그 후에 다시 한번 FCNN Layer에 통과시키게 된다. </p><script type="math/tex; mode=display">M_{out} = \text{Concat}(O_1, O_2, ..., O_{H_n}) W^O\tag{equation 1}</script><p>그렇다면 결과적으로는 다음이 성립한다.</p><script type="math/tex; mode=display">\begin{aligned}    W^O \in \mathbb{R}^{H_nd_v * d_{model}} \\     M_{out} \in \mathbb{R}^{n * d_{model}}\end{aligned}\tag{definition 4}</script><p>여기까지가 Encoder에 적용시킬 Multi Head Self Attention 이다.</p><h4 id="Masking"><a href="#Masking" class="headerlink" title="Masking"></a>Masking</h4><p>Masking은 Sequential한 데이터에서 쓸데없는 데이터까지 학습되지 않도록, 또는 원하는 방향으로 데이터를 학습시킬 수 있게 해주는 좋은 도구이다. Transformer에서는 $Q_iK_i^T$룰 계산하면서 나오는 $\mathbb{R}^{n*n}$ 행렬에 적용시키게 된다. 몇가지 예시를 들면서 설명해 보도록 하겠다.</p><ol><li>padding의 학습을 막기 위한 용도 (Padding Mask)</li></ol><p>sequence의 길이를 통일시키기 위해, 길이가 모자란 데이터에는 으례 padding을 넣게 된다. 하지만 padding은 실질적인 의미를 가진 데이터가 아니기에 학습에서 배제를 해야한다. 그래서 우리는 $Q_iK_i^T$의 행렬에서 Softmax 함수를 거치기 전에 $-\inf$ 값을 곱하므로써 Attention Distribution에서 Padding에 해댱하는 위치의 값을 0으로 만들어 버린다. 학습에서 배제를 시키는 것이다.</p><p>해설이 어렵다면 다음 그림을 보자.</p><p align="center"><img src="https://kimh060612.github.io/img/softmax.png" width="50%"></p><ol><li>자신보다 앞의 데이터를 학습하지 않게 하는 용도</li></ol><p>이 Masking은 Decoder에서 사용된다. $Q_iK_i^T$ 행렬에서 자기 자신보다 앞서 있는 데이터를 참조하는 현상이 일어난다. 이는 Transformer가 데이터를 순차적으로 받는 것이 아닌, 한번에 받기 때문에 그런 것이다. 이 문제를 해결하기 위해서 $Q_iK_i^T$ 행렬에 자신보다 앞선 값에는 $-\inf$를 곱해서 Attention Distribution의 값을 0으로 만들어 버린다.</p><p>이것도 해석이 어렵다면 다음 그림을 보자.</p><p align="center"><img src="https://kimh060612.github.io/img/lookahead.png" width="50%"></p><p>이를 look ahead masking 이라고 한다.</p><h4 id="Feed-Forward"><a href="#Feed-Forward" class="headerlink" title="Feed Forward"></a>Feed Forward</h4><p>Transformer에서는 다음과 같은 형태의 FCNN Layer 2개를 겹쳐서 Encoder/Decoder에 사용하고 있다.</p><script type="math/tex; mode=display">\begin{aligned}    W_1 \in \mathbb{R}^{d_{model} * d_{ff}} \\    W_2 \in \mathbb{R}^{d_{ff} * d_{model}}\end{aligned}</script><p>위 2개의 $W$행렬은 각 FCNN layer의 가중치 행렬의 크기이다. 이 2개의 FCNN Layer에 사이에 ReLU activation function을 끼워 넣어서 사용한다.</p><h3 id="Transformer-Decoder"><a href="#Transformer-Decoder" class="headerlink" title="Transformer Decoder"></a>Transformer Decoder</h3><hr><p>자, 이제 Decoder에 대한 이야기를 해볼 것이다. 하지만 여기까지 읽었다면 Decoder를 굳이 다뤄야 할지도 의문일 정도로 유추하기 쉬워졌다. </p><p align="center"><img src="https://kimh060612.github.io/img/Decoder.png" width="50%"></p><p>Decoder와 Encoder가 다른 점은 위 그림에서 있는 것이 전부이다.</p><ol><li>첫번째 Multi Head Attention에서 Look Ahead Masking을 사용했다는점</li><li>2번째 Multi Head Attention에서 Encoder의 Output을 Key와 Value 행렬로써 사용 한다는점 </li></ol><p>Residual Connection 특성상, 같은 차원으로 입/출력 행렬이 일괄되기 때문에 위화감 없이 전개가 가능할 것이다. 이 부분은 독자에게 어떤 식으로 연산이 이루어지는지 생각할 시간을 가져보는 것을 추천한다.</p><h3 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h3><hr><p>마자믹으로 Positional Encoding에 대해서 알아볼 것이다. Positional Encoding은 입력의 데이터의 위치 정보를 신경망에 알려주는 한가지의 수단이다. 이것이 필요한 이유는 다양하다. 대표적으로 NLP에서는 어순 또한 언어의 뜻을 이해하는데 중요한 정보이기 때문이다. </p><p>대표적인 몇가지 예시를 들자면 다음과 같다.</p><ol><li>Simple Indexing</li></ol><p>이는 단순하게 입력이 들어온 순서대로 0, 1, 2, 3, … 의 값을 할당하여 Embedding Layer 같은 것을 거쳐서 벡터로 만드는 방법이다. 가장 단순하지만 딱히 추천하지는 않는다고 한다.</p><ol><li>Sin 함수를 이용한 Positional Encoding</li></ol><p>이는 position에 따라서 다음과 같은 수식으로 계산되는 값을 사용하는 방법이다.</p><script type="math/tex; mode=display">\begin{aligned}    PE_{(pos, 2i)} = \sin(pos/10000^{2i/d_{model}}) \\    PE_{(pos, 2i + 1)} = \cos(pos/10000^{2i/d_{model}})\end{aligned}</script><p>이때, $pos$는 Sequence 내에서 입력의 위치를 나타내며, $i$는 Embedding vector 내에서의 위치를 나타낸다.</p><p>자세한 것은 다음 그림을 보면 더 자세히 알 수 있다.</p><p align="center"><img src="https://kimh060612.github.io/img/transformer6_final.png" width="50%"></p><p>이걸로 기나긴 Transformer의 이야기는 끝났다. 다음 포스팅은 이것을 구현해 보는 시간을 가질 것이다.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Deep-Learning/">Deep Learning</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="https://kimh060612.github.io/tags/Mathematics/">Mathematics</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/05/Transformer-B/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Transformer 강의 내용 part.A</title>
      <link>https://kimh060612.github.io/2022/03/05/Transformer-A/</link>
      <guid>https://kimh060612.github.io/2022/03/05/Transformer-A/</guid>
      <pubDate>Sat, 05 Mar 2022 10:28:17 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;&lt;em&gt;본 포스트는 해당 링크의 &lt;a href=&quot;https://wikidocs.net/22893&quot;&gt;블로그&lt;/a&gt;을 참조하여 작성되었음을 알립니다.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;Index&quot;&gt;&lt;a href=&quot;#Index&quot; class=&quot;headerl</description>
        
      
      
      
      <content:encoded><![CDATA[<p><em>본 포스트는 해당 링크의 <a href="https://wikidocs.net/22893">블로그</a>을 참조하여 작성되었음을 알립니다.</em></p><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li>Attention!<ul><li>Seq2Seq</li><li>Attention in Seq2Seq</li></ul></li><li>Transformer Encoder<ul><li>Attention in Transformer</li><li>Multi-Head Attention</li><li>Masking</li><li>Feed Forward</li></ul></li><li>Transformer Decoder</li><li>Positional Encoding</li><li>Partice<ul><li>Seq2Seq Attention</li><li>Transformer</li></ul></li></ol><p>여기서는 1은 Part. A이고 2~4는 Part. B에서, 5는 part. C에서 다루도록 하겠다.<br><br></p><h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention!"></a>Attention!</h3><hr><h4 id="Seq2Seq"><a href="#Seq2Seq" class="headerlink" title="Seq2Seq"></a>Seq2Seq</h4><p>자~ 주목! ㅋㅋㅋ;;<br>우선 몇몇 사람들은 의아해 할 것이다. 순서상으로는 다음과 같이 가는 것이 국룰이기 때문이다.</p><blockquote><p>RNN -&gt; LSTM -&gt; (GRU) -&gt; Seq2Seq -&gt; Attention</p></blockquote><p>흠… 일단 필자가 생각하기에는 LSTM과 GRU는 RNN에서 구조를 바꾼 것이다. 그리고 이들끼리는 언제나 서로 바뀔 수 있는, 마치 기계 공장의 나사와 같은 존재이기에, 기본이 되는 RNN만을 다루고 넘어간 것이다. 물론! Gradient 입장에서 말한다면 할 말은 많다. 이들이 나온 이론적인 토대는 명확하지만, 굳이? 이걸? 필자의 블로그에서? 다루기에는 너무 흔해 빠진 내용이라 바로 Attention 부터 죠지고 가도록 하겠다. (물론 Attention 또한 요즘은 흔해 빠진 내용 맞다 ㅋ;;)</p><p>그래서 왜 Attention에 part 하나를 다 써먹나? 얼마나 중요한 내용이길래?</p><p>중요한 내용인 것도 맞지만, 필자가 더 자세히 공부하려고 이런 것이다. 그리고 필자는 이 이후 포스팅에서는 일반화된 델타 규칙을 내세우지 않을 것이다. 왜냐하면 이제부터는 진짜 의미가 없다고 생각하기 때문이다. 이걸 굳이 일반화된 델타 규칙으로 풀어서 구현할 바에는 그냥 AutoGrad를 직접 구현하는게 빠르다.</p><p>우선 그렇다면 Attention이 왜 나왔나부터 생각해 보도록 하자.<br>그러기 위해서는 우선 Seq2Seq부터 알아야 하는데, 간단하게만 알아보도록 하자. 다음 그림으로 Seq2Seq의 구조를 파악할 수 있다.</p><p align="center"><img src="https://kimh060612.github.io/img/Seq2Seq.png" width="100%"></p><p>이 Seq2Seq는 그림과 같이 동작한다.<br>Encoder에서는 입력 벡터의 분석을, Decoder에서는 출력을 결정하는 역할을 한다. 여기서 Encoder는 입력의 Context를 분석하는 역할을 한다고 한다. </p><p>Seq2Seq의 단점 </p><ol><li>입력을 Encoder에서 고정된 크기로 압축하여 context vector로 만든다. 그런 구조는 정보 손실을 가져오기 마련이다.</li><li>이러한 Context Vector는 Encoder의 마지막 출력인데 이것만을 사용하게 된다면 초반의 정보는 유실되기 마련이다.  </li><li>RNN의 고질적인 문제인 Gradient Vanishing 문제가 발생한다.</li></ol><p>이를 보완하기 위해서 나온 것이 Attention 구조이다.</p><h4 id="Attention-in-Seq2Seq"><a href="#Attention-in-Seq2Seq" class="headerlink" title="Attention in Seq2Seq"></a>Attention in Seq2Seq</h4><p>먼저, Attention의 큰 구조 부터 알고 넘어가자. Attention은 다음과 같은 함수로 표현될 수 있다.</p><p>Attention($Q$, $K$, $V$) = Attention Value</p><p>그렇다면 우리는 Attention 함수 자체에 대해서 알기 전에 먼저 $Q$, $K$, $V$를 먼저 정의할 필요가 있다.<br>Seq2Seq 모델에서 $Q$, $K$, $V$는 다음과 같이 정의될 수 있다.</p><p>$Q$ : 특정 시점의 디코더 셀에서의 은닉 상태<br>$K$ : 모든 시점의 인코더 셀의 은닉 상태들<br>$V$ : 모든 시점의 인코더 셀의 은닉 상태들  </p><p>Seq2Seq 모델에서 순전파를 한다면 위의 행렬들을 전부 구할 수 있을 것이다. 그렇다면 우리는 Attention 연산을 정의할 수 있어야 한다. Attention 연산은 되게 다양한 종류가 있다. 간단하게 정리해보자면 다음과 같다.</p><ol><li>Dot Attention</li><li>Scaled Dot Attention</li><li>Bahdanau Attention</li></ol><p>우리는 이 중에서 Scaled Dot Attention을 다뤄볼 것이다. 왜냐? Transformer에 쓰이니깐.</p><p>Scaled Dot Attention의 수식을 써보자면 다음과 같이 간단하게 쓸 수 있다.</p><script type="math/tex; mode=display">\text{Attention}(Q, K, V) = \text{Softmax}(\frac{QK^T}{\sqrt{n}})V\tag{definition 1}</script><p>여기서 $n$은 RNN(LSTM이든 뭐든)의 출력 벡터의 크기이다. 즉, $Q$의 크기와 같다.<br>결국 Attention 구조는 다음과 같은 형식을 띄고 Seq2Seq와 결합한다.</p><p align="center"><img src="https://kimh060612.github.io/img/Attention.png" width="100%"></p><p>출처: Luong’s <a href="https://arxiv.org/abs/1508.04025v5">paper</a></p><p>위 그림에서 볼 수 있듯이, 각 $Q$ 벡터들은 RNN(또는 LSTM 또는 GRU)의 Decoder 부분의 은닉 상태이다. 각 시간 스텝에서의 출력을 바탕으로 위의 Attention 함수를 Encoder의 출력 값과 같이 계산할 수 있고, 그를 이용해서 Attention Vector를 만들고 다시 $Q$와 결합한 것을 FCNN에 입력하여 최종 출력 vector를 얻어낸 뒤에 Softmax를 씌워서 예측 단어를 분류한다.</p><p>말로 길게 설명하였는데, 이를 수식으로 표현해 보자.</p><script type="math/tex; mode=display">Q^t \in \mathbb{R}^n \\ K \in \mathbb{R}^{n * T} \\V \in \mathbb{R}^{T * n}\tag{definition 2}</script><p>우선 각 행렬들의 크기는 위와 같이 표현이 가능하다. $Q^t$는 Decoder에서 time step $t$에서의 출력이다. 여기까지 이해가 되었으면 다시 Scaled Dot Attention의 정의에서 성분별로 하나씩 뜯어서 살펴보자.</p><ol><li>$Q^tK^{\textbf{T}}$: $K$의 경우, input의 각 time step의 출력을 한데 모아놓은 Matrix이다. 이를 $Q^t$ 벡터와 곱한다. 이를 앞으로 편의상 $e^t$라고 정의하도록 하겠다.</li><li>$\text{Softmax}$: 위의 $e^t$에 $\sqrt{n}$로 나눈 값을 Softmax에 집어 넣으므로써 Attention Distribution을 뽑아낸다. 이를 편의상 $\alpha^t$라고 부르도록 하겠다.</li><li>$V$: 위의 $\alpha^t$는 $\mathbb{R}^{T}$인 벡터이다. 이 벡터의 각 성분으로 Input Encoder의 각 출력을 가중합한다. 이 결과를 Context vector라고도 부른다.</li></ol><p>이렇게 Context Vector를 얻은 후에 우리는 $Q^t$와 Context vector를 Concatenation한 뒤에 FCNN Layer에 입력으로 넣는다.</p><script type="math/tex; mode=display">W_c \in \mathbb{R}^{n * 2n}: \text{FCNN의 가중치 벡터}\tag{definition 3}</script><p>Context vector와 $Q^t$를 concatenation한 vector의 크기가 $2n$이니, FCNN의 가중치 벡터가 위와 같이 정의되어야 한다.<br>그리고 그 결과 출력을 Softmax 함수에 넣으면 timestep $t$의 출력이 된다.</p><p>이렇게 Attention을 알아 보았는데 다음 파트에서는 Attention이 어떻게 Transformer에 사용되는지를 알아보도록 하겠다.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Deep-Learning/">Deep Learning</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="https://kimh060612.github.io/tags/Mathematics/">Mathematics</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/05/Transformer-A/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Optimization 강의 내용 part.B</title>
      <link>https://kimh060612.github.io/2022/03/05/Optimization-B/</link>
      <guid>https://kimh060612.github.io/2022/03/05/Optimization-B/</guid>
      <pubDate>Sat, 05 Mar 2022 10:27:39 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;&lt;em&gt;본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document, Pattern Recognition and Machine Learning, Deep learning</description>
        
      
      
      
      <content:encoded><![CDATA[<p><em>본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document, Pattern Recognition and Machine Learning, Deep learning(Ian Goodfellow 저)을 참조하여 작성되었음을 알립니다.</em></p><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li><del>Essential Mathematics</del>  <ul><li><del>Basic of Bayesian Statistics</del></li><li><del>Information Theory</del></li><li><del>Gradient</del></li></ul></li><li><del>Loss Function Examples</del></li><li><del>What is Optimizer?</del></li><li><del>Optimizer examples</del></li><li>Partice</li></ol><p><br></p><h3 id="Partice"><a href="#Partice" class="headerlink" title="Partice"></a>Partice</h3><hr><p>자, 이제 구현의 난이도 측면에서는 가장 어렵다고 말할 수 있는 파트가 왔다. 이번에도 Model Subclassing API를 활용하여 Custom Optimizer를 만들어 보도록 하겠다. Custom이라고 해서 뭔가 새로운건 아니고, 간단하게 SGD를 구현해 볼 것이다. 근데 솔직히 이건 별로 쓸데가 없다. 이것까지 건드려야하는 사람은 아마도 직접 짜는게 빠르지 않을까 싶다.<br>여기서 가장 중요한 것은 Custom Training loop와 Custom loss이다. SGD는 간단하게 소스코드만 보고 Training loop와 Custom loss를 자세히 설명하도록 하겠다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CustomSGDOptimizer</span>(keras.optimizers.Optimizer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, learning_rate = <span class="number">0.001</span>, name = <span class="string">&quot;CustomSGDOptimizer&quot;</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(name, **kwargs)</span><br><span class="line">        self._set_hyper(<span class="string">&quot;learning_rate&quot;</span>, kwargs.get(<span class="string">&quot;lr&quot;</span>, learning_rate))</span><br><span class="line">        self._is_first = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_create_slots</span>(<span class="params">self, var_list</span>):</span><br><span class="line">        <span class="keyword">for</span> var <span class="keyword">in</span> var_list:</span><br><span class="line">            self.add_slot(var, <span class="string">&quot;pv&quot;</span>) <span class="comment"># previous variable</span></span><br><span class="line">        <span class="keyword">for</span> vat <span class="keyword">in</span> var_list:</span><br><span class="line">            self.add_slot(var, <span class="string">&quot;pg&quot;</span>) <span class="comment"># previous gradient</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @tf.function</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_resource_apply_dense</span>(<span class="params">self, grad, var</span>):</span><br><span class="line">        var_dtype = var.dtype.base_dtype</span><br><span class="line">        lr_t = self._decayed_lr(var_dtype)</span><br><span class="line"></span><br><span class="line">        new_var_m = var - lr_t * grad</span><br><span class="line"></span><br><span class="line">        pv_var = self.get_slot(var, <span class="string">&quot;pv&quot;</span>)</span><br><span class="line">        pg_var = self.get_slot(var, <span class="string">&quot;pg&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self._is_first :</span><br><span class="line">            self._is_first = <span class="literal">False</span></span><br><span class="line">            new_var = new_var_m</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cond = grad * pg_var &gt;= <span class="number">0</span></span><br><span class="line">            avg_weight = (pv_var + var) / <span class="number">2.0</span></span><br><span class="line">            new_var = tf.where(cond, new_var_m, avg_weight)</span><br><span class="line">        </span><br><span class="line">        pv_var.assign(var)</span><br><span class="line">        pg_var.assign(grad)</span><br><span class="line"></span><br><span class="line">        var.assign(new_var)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_resource_apply_sparse</span>(<span class="params">self, grad, var</span>):</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_config</span>(<span class="params">self</span>):</span><br><span class="line">        base_config = <span class="built_in">super</span>().get_config()</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            **base_config,</span><br><span class="line">            <span class="string">&quot;learning_rate&quot;</span> : self._serialize_hyperparameter(<span class="string">&quot;lr&quot;</span>)</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><blockquote><p>그만 알아보자.</p></blockquote><p>장난 안치고 이건 나중에 하나의 포스트를 다 써서 설명할 것이다. 그 정도로 다른 중요한 topic과 같이 다루기에는 무겁다.</p><p>일단, Custom Training loop를 어떻게 만드는지를 알아보도록 하겠다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">train_dataset = tf.data.Dataset.from_tensor_slices((train_img, train_labels))</span><br><span class="line">                            <span class="comment"># 섞어.                        # 배치 사이즈 만큼 나눠.</span></span><br><span class="line">train_dataset = train_dataset.shuffle(buffer_size=<span class="number">1024</span>).batch(BatchSize)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optimizer &amp; Loss Function 정의</span></span><br><span class="line">optimizer = keras.optimizers.Adam(learning_rate=LR)</span><br><span class="line">loss_function = keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train_accuracy = keras.metrics.SparseCategoricalAccuracy()</span><br><span class="line">val_acc_metric = keras.metrics.SparseCategoricalAccuracy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Epoch %d start&quot;</span>%epoch)</span><br><span class="line">    <span class="comment"># step, 1개의 batch ==&gt; 의사 코드에서 batch 뽑는 역할</span></span><br><span class="line">    <span class="keyword">for</span> step, (x_batch, y_batch) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataset):</span><br><span class="line">        <span class="comment"># **********************************************************************************************</span></span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            logits = model(x_batch, training=<span class="literal">True</span>)</span><br><span class="line">            loss_val = loss_function(y_batch, logits)</span><br><span class="line">            <span class="comment"># 여기서 신경망의 Feed Forward &amp; Expectation of Loss 계산을 진행함.</span></span><br><span class="line">        <span class="comment"># tape.gradient를 호출하면 ==&gt; gradient 계산이 진행됨.</span></span><br><span class="line">        grad = tape.gradient(loss_val, model.trainable_weights)</span><br><span class="line">        <span class="comment"># 정의된 Optimizer를 이용해서 Update를 진행함.</span></span><br><span class="line">        optimizer.apply_gradients(<span class="built_in">zip</span>(grad, model.trainable_weights))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># train에서의 정확도를 계산함.</span></span><br><span class="line">        train_accuracy.update_state(y_batch, logits)</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">0</span> :</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Training loss at step %d: %.4f&quot;</span>%(step, loss_val))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 정확도 뽑아 보겠다.</span></span><br><span class="line">    train_acc = train_accuracy.result()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Training acc over epoch: %.4f&quot;</span> % (<span class="built_in">float</span>(train_acc),))</span><br><span class="line">    train_accuracy.reset_states()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x_batch_val, y_batch_val <span class="keyword">in</span> validation_dataset:</span><br><span class="line">        val_logits = model(x_batch_val, training = <span class="literal">False</span>)</span><br><span class="line">        val_acc_metric.update_state(y_batch_val, val_logits)</span><br><span class="line">    val_acc = val_acc_metric.result()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Validation acc: %.4f&quot;</span> % (<span class="built_in">float</span>(val_acc),))</span><br><span class="line">    val_acc_metric.reset_states()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>기본적으로 Custom Training Loop는 위와 같이 구현된다. 이걸 하나하나 뜯어서 설명해 보도록 하겠다.</p><ol><li><p>tf.GradientTape()</p><p> tensorflow 2의 핵심인 AutoGrad를 구동시켜주는 친구이다. 이 tape scope 안에서 실행된 tensorflow operation들은 back propagation을 위한 AutoGrad 미분 그래프의 구축이 시작된다.  </p></li><li><p>tape.gradient</p><p> 이 함수를 실행하면 구축된 AutoGrad 미분 그래프를 따라서 미분이 시작된다. </p></li><li><p>apply_gradients</p><p> 이는 optimizer(ex. Adam)의 method이고 tape.gradient에서 구한 gradient를 사용자가 정한 optimizing algorithm을 통해서 Weight를 업데이트 해준다.</p></li><li><p>update_state</p><p>이는 학습 과정중에서 측정할 수 있는 Metric들을 구하는데 사용된다. (ex. 정확도) keras에서 제공하거나 직접 만든 Metric 객체를 새로 Nerual Network에서 계산된 batch에 적용하고 싶을때 사용한다.</p></li></ol><p>이렇게 Custom Training loop는 크게 4가지 요소로 구성된다.<br>필자는 이것을 보통 템플릿으로 가지고 개발할때마다 조금씩 바꿔서 사용하는 편이다. 독자들도 조금 복잡한 트릭이 필요한 Neural Network를 구현할때 본인만의 Training loop를 구성하고 조금씩 바꿔가면서 사용하는 것을 추천한다. </p><p>다음으로 다룰 것은 Custom loss이다. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Custom Loss</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomMSE</span>(keras.losses.Loss):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, y_true, y_pred</span>):</span><br><span class="line">        <span class="comment"># tf.math.square : 성분별 제곱</span></span><br><span class="line">        <span class="comment"># [1,2,3] ==&gt; [1,4,9]</span></span><br><span class="line">        L = tf.math.square(y_true - y_pred)</span><br><span class="line">        <span class="comment"># tf.math.reduce_sum: 벡터 합.</span></span><br><span class="line">        <span class="comment"># [1,2,3] ==&gt; 6</span></span><br><span class="line">        L = tf.math.reduce_mean(L)</span><br><span class="line">        <span class="keyword">return</span> L</span><br><span class="line"></span><br><span class="line"><span class="comment"># Custom Regularizer(규제 ==&gt; MAP)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomRegularizer</span>(keras.regularizers.Regularizer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, _factor</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.factor = _factor</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, weights</span>):</span><br><span class="line">        <span class="keyword">return</span> tf.math.reduce_sum(tf.math.<span class="built_in">abs</span>(self.factor * weights))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_config</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;factor&quot;</span> : self.factor&#125; <span class="comment"># 모델을 저장할때 custom layer, loss, 등등을 저장할때 같이 저장해 주는 역할.</span></span><br></pre></td></tr></table></figure><p>tensorflow는 사용자가 Loss나 Regularizer까지도 자유롭게 구성할 수 있도록 허락해준다. 사용 방법은 기존 loss들과 똑같다. 그저 자신이 원하는 연산들을 생각해서 구현하면 된다.</p><p>이걸로 Optimization part.B를 마치도록 하겠다. 이 정도까지 Custom해서 사용할 사람들은 많이 없겠지만 혹시라도 필요한 사람들이 있을까 싶어서 적어 보았다.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Deep-Learning/">Deep Learning</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="https://kimh060612.github.io/tags/Tensorflow2/">Tensorflow2</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/05/Optimization-B/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Optimization 강의 내용 part.A</title>
      <link>https://kimh060612.github.io/2022/03/05/Optimization-A/</link>
      <guid>https://kimh060612.github.io/2022/03/05/Optimization-A/</guid>
      <pubDate>Sat, 05 Mar 2022 10:27:37 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;&lt;em&gt;본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document, Pattern Recognition and Machine Learning, Deep learning</description>
        
      
      
      
      <content:encoded><![CDATA[<p><em>본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document, Pattern Recognition and Machine Learning, Deep learning(Ian Goodfellow 저)을 참조하여 작성되었음을 알립니다.</em></p><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li>Essential Mathematics  <ul><li>Basic of Bayesian Statistics</li><li>Information Theory</li><li>Gradient</li></ul></li><li>Loss Function Examples</li><li>What is Optimizer?</li><li>Optimizer examples</li><li>Partice</li></ol><p>여기서는 1~4는 Part. A이고 5는 Part. B에서 다루도록 하겠다.<br><br></p><h3 id="Essential-Mathematics"><a href="#Essential-Mathematics" class="headerlink" title="Essential Mathematics"></a>Essential Mathematics</h3><hr><h4 id="Basic-of-Bayesian-Statistics"><a href="#Basic-of-Bayesian-Statistics" class="headerlink" title="Basic of Bayesian Statistics"></a>Basic of Bayesian Statistics</h4><p>이 파트에서는 Bayesian Statistics에 대해서 매~우 간단하게 다루어 보도록 하겠다. 실은 다룬다고 말하는 것도 부끄러울 정도록만 할 예정이니 너무 기대는 하지 않아 주었으면 한다.</p><p>여기서는 조금 익숙하지 않은 통계학, Bayesian 통계학을 소개하도록 할 것이다. 이 분야는 패턴 인식에서 아주 많이 활용되며, 기존의 확률론에 익숙해져 있다면 이를 받아들이기 매우 힘들다.</p><p>우선, “확률”이란 무엇인지에 대해 논하고 넘어가자.<br>Frequentist – “빈도”에 대한 척도, 어떤 일이 앞으로 얼마나 일어날 수 있겠는가?<br>Bayesian – 불확실성에 대한 척도, 이 가설에 대해 얼마나 확신할 수 있는가?</p><p>Bayesian 관점에서의 확률을 그림으로 표현하자면 대충 아래와 같다</p><p align="center"><img src="https://kimh060612.github.io/img/BP.png" width="100%"></p><p>간단하게만 말하자면, 확률이 1에 가까울수록 “명제의 참에 대한 확신”을 가질 수 있고 0에 가까울 수록 그 반대인 것이다. 그리고 0.5에 가까워 질수록 점점 애매해 지는 것이다.</p><p>그리고 이 관점에서 우리는 다음 3가지 개념을 다뤄 볼 것이다.</p><ol><li>Prior Probability</li><li>Likelihood</li><li>Posterior Probability</li></ol><p>이 3가지를 말로 풀어서 설명하면 다음과 같다.</p><ol><li>Prior Probability: 데이터가 주어지기 전에 우리의 가설은 얼마나 타당한가?</li><li>Likelihood: 어떤 데이터들이 특정 확률 분포에서 추출되었을 확률</li><li>Posterior Probability: 주어진 데이터에 한에서 우리의 가설이 얼마나 타당한가?</li></ol><p>우리는 이들애 대해서 엄밀한 정의를 다루는 것이 아닌, 좀 더 실용적인 측면에서 예제와 함께 다루어 볼 것이다.</p><p>이를 활용하는 예제로써 한번 Curve fitting 문제를 생각해 보자. Curve fitting을 하기 위해서 우리는 어떤 parameter $w$를 가지고 이를 우리가 원하는 곡선에 맞게 fitting하는 과정을 거칠 것이다.</p><p>우리는 이때 이런 가정을 할 수 있다.<br>“parameter $𝑤$로 생성된 곡선 $𝐶$는 주어진 데이터 $𝐷$를 잘 설명할 수 있다.”<br>이 문장은 특정한 불확실성을 가지고 있다. 당연히 처음부터 Fitting이 잘 될 리도 없고, 특정한 에러를 가지고 있음이 분명하다.</p><p>이렇다면 우리는 그 불확실성을 어떻게 확률로 표현 가능하겠는가? 한번 다음과 같이 해보자.</p><p>$Pr(w)$: 데이터가 주어지기 이전에 위의 가설이 얼마나 확실한가<br>$Pr(D|w)$: 주어진 모델에서 데이터가 얼마나 잘 설명되는 가의 척도<br>$Pr(w|D)$: 데이터가 주어졌을 때, 이 모델이 데이터를 잘 설명하는 가의 척도</p><p>이때, 좋은 모델을 만드는 방법은 크게 2가지가 있다.</p><ol><li>Likelihood를 최대화하는 parameter 만들기 ==&gt; MLE(Maximum Likelihood Estimation)</li><li>Posterior Probability를 최대화하는 parameter 만들기 ==&gt;  MAP (Maximum A Posterior)</li></ol><p>즉, 1번 방법은 최대한 좋은 주어진 모델에서 최대한 좋은 데이터의 설명을 얻어내는 방법이고, 2번 방법은 데이터를 가지고 최대한 좋은 모델을 얻어내는 방법이다.</p><p>이 관점에서 1번부터 차근차근 설명해 보도록 하겠다. 어떻게 하면 likelihood를 최대화할 수 있을까?</p><p>우선 $Pr(D|w)$의 함수를 찾아서 이를 최대로 만들어 주면 되는 것이다. 최대로 만들어 주는 방법은 여러가지 방법이 있겠지만, 우선 그것보다 $Pr(D|w)$를 찾는 것부터 진행하는  것이 순서일 것이다.</p><p>그 전에 표현을 좀 정리하고 가겠다.</p><script type="math/tex; mode=display">\begin{aligned}    x_i, t_i \text{: 주어진 데이터의 점들. 즉,} (x_i, t_i) \in D \\    y(x_i, w) \text{: parameter가 $w$일 때의 모델의 예측 값.}\end{aligned}\tag{definition 1}</script><p>자, 그리고 우리는 다음과 같이 “가정”을 해보자.<br><em>데이터에서 주어진 target값과 우리의 예측 값의 차이가 Gaussian Distribution을 따른다</em></p><p>이를 수식으로 표현하면 다음과 같다.</p><script type="math/tex; mode=display">\epsilon_i \sim \mathcal{N}(0, \beta^{-1})\tag{definition 2}</script><p>여기서 $\epsilon_i$는 실측값과 데이터 간의 오차이다. ($\epsilon_i = t_i - y(x_i;w)$) </p><p>즉, 우리가 고등학교에서 확률과 통계를 착실히 배웠다면 다음과 같이 변형이 가능할 것이다.</p><script type="math/tex; mode=display">\begin{aligned}    t_i \sim \mathcal{N}(y(x_i;w), \beta^{-1}) \\    Pr(t_i | x_i, w, \beta) = \mathcal{N}(y(x_i;w), \beta^{-1})\end{aligned}\tag{equation 1}</script><p>위의 내용을 시각화 하면 대충 다음과 같다.</p><p align="center"><img src="https://kimh060612.github.io/img/CF.png" width="100%"></p><p>이제 각각의 데이터에 대해서 이를 정의해 놓았으니, 데이터 전체에 대해서는 각각의 데이터가 i.i.d라는 가정 하게 그냥 곱해주면 된다. 다음과 같이 말이다.</p><script type="math/tex; mode=display">\begin{aligned}    D = \{(x_i, t_i) | 1 \leq i \leq N\} \\    Pr(\textbf{t} | \textbf{x}, w, \beta) = \prod^{N}_{n = 1} \mathcal{N}(t_n | y(x_n;w), \beta^{-1})\end{aligned}\tag{equation 2}</script><p>자, 이제야 뭔가 손에 잡히는 느낌이 든다(아닌가?!?)<br>자세히 보면 위 식이 likelihood 아닌가? 정의 그대로이다.</p><p>이제 위의 Probability를 최대화 하면 되는 것이다.<br>근데 product는 다루기 어려우니 만능 툴인 로그를 씌워 보자.</p><script type="math/tex; mode=display">\ln Pr(\textbf{t} | \textbf{x}, w, \beta) = -\frac{\beta}{2} \sum^{N}_{n = 1} (y(x_n;w) - t_n)^2 + \frac{N}{2} \ln \beta - \frac{N}{2} \ln 2\pi\tag{equation 3}</script><p>이때, 우리는 2가지 parameter에 대해서 위 식의 최대값을 구해야 한다. 첫번째가 $w$이고 두번째가 $\beta$이다.<br>우선 $\beta$부터 해보자면 다음과 같이 가능하다.</p><script type="math/tex; mode=display">\frac{\partial}{\partial \beta} \ln Pr(\textbf{t} | \textbf{x}, w, \beta) = -\frac{1}{2} \sum^{N}_{n = 1} (y(x_n;w) - t_n)^2 + \frac{N}{2} \frac{1}{\beta}\tag{equation 4}</script><p>결국 이 미분 값을 0으로 만드는 값이 최대값일 것이므로 다음과 같이 식을 풀어낼 수 있다.</p><script type="math/tex; mode=display">\frac{1}{\beta_{ML}} = \frac{1}{2} \sum^{N}_{n = 1} (y(x_n;w) - t_n)^2\tag{equation 5}</script><p>이제 $w$에 대해서 최대값을 구해보면 다음과 같다.</p><script type="math/tex; mode=display">w_{ML} = \argmax_w \ln Pr(\textbf{t} | \textbf{x}, w, \beta) = \argmin_w \sum^{N}_{n = 1} (y(x_n;w) - t_n)^2</script><p>어..? 어디서 많이 본 것 같지만 일단 넘어가자. (실은 나중에 loss function 부분에서 한번 더 다루겠다.)</p><p>여기서의 최적화는 다양한 방법으로 시도할 수 있다.</p><p>이의 원리를 다시 한번 떠올려보자.</p><ol><li>에러가 Gaussian Distribution을 따를 때,</li><li>주어진 데이터 𝐷를 우리의 model이 데이터를 잘 설명할 수 있다는 가설이</li><li>참일 것이라는 확률(확실성)을 높이는 과정 </li></ol><p>이것이 바로 우리가 진행한 것이다.  </p><p>그렇다면, 이제 MAP를 활용해서 이를 구해보면 어떻게 될까?<br>Bayes’ Theorem에 따라 구하면 다음과 같이 작성 가능하다.</p><script type="math/tex; mode=display">Pr(w | \textbf{t}, \textbf{x}, \alpha, \beta) \propto Pr(\textbf{t} | \textbf{x}, w, \beta) Pr(w|\alpha) \tag{eqaution 6}</script><p>위 식에서 뭔가 낯설지만 익숙한 것이 보인다. 바로 $Pr(w|\alpha)$이다. 이것이 바로 “사전 확률”이다.</p><p>사전 확률 또한 우리가 모르지만, 일단 만능인 Gaussian 이라고 가정해 보자. (이 가정이 나름의 타당성을 갖춘다는 것을 알고 싶으면 확률 및 랜덤 변수를 조금 깊게 공부해 보자.)</p><script type="math/tex; mode=display">\begin{aligned}    w \sim \mathcal{N}(0, \alpha^{-1}\textbf{I}) \\     Pr(w|\alpha) = \mathcal{N}(w|0, \alpha^{-1}\textbf{I}) = (\frac{\alpha}{2\pi})^{\frac{M + 1}{2}} e^{-\frac{\alpha}{2}w^{\textbf{T}}w}\end{aligned}\tag{equation 7}</script><p>그렇다면, 우리는 이를 통해서 최대 (로그)사후 확률을 마찬가지로 미분을 통해서 구해보면 다음과 같다.</p><script type="math/tex; mode=display">w_{ML} = \argmax_w \ln Pr(w | \textbf{t}, \textbf{x}, \alpha, \beta) = \argmin_w \frac{\beta}{2} \sum^{N}_{n = 1} (y(x_n;w) - t_n)^2 + \frac{\alpha}{2}w^{T}w\tag{equation 8}</script><p>이것도 뭔가 어디서 본 것 같은데..? 라고 생각한다면 당신은 멋진 사람 :)</p><p>이걸로 Bayesian Statistics에서 말하는 likelihood와 prior/posterior 확률이 어떤 개념인지 조금이라도 와 닿았으면 좋겠다 ㅎㅎ.</p><h4 id="Information-Theory"><a href="#Information-Theory" class="headerlink" title="Information Theory"></a>Information Theory</h4><p>이 파트에서는 정보 이론을 매~~~~우 간단하게만 다루어볼 예정이다. 이것도 다룬다고 말하기도 부끄럽다고 할 수 있을 정도로만 다루도록 하겠다.</p><p>정보 이론은 “정보량”의 개념으로부터 시작한다. 이것이 현대에 들어서 통신, 패턴 인식 등 여러 분야에 사용되고 있다.<br>그리고 이러한 정보량의 평균을 “엔트로피”라고 부른다.</p><p>정보량은 다음과 같이 정의된다.</p><script type="math/tex; mode=display">h(x) = -\log_2 p(x) \space \text{bits}</script><script type="math/tex; mode=display">h(x) = -\ln p(x) \space \text{nats}</script><p>한가지 예를 들어 보겠다. 다음과 같이 정의되는 랜덤 변수가 있다고 가정해 보자.</p><p align="center"><img src="https://kimh060612.github.io/img/PVR.png" width="100%"></p><p>이의 엔트로피를 구해보면 다음과 같다.</p><p align="center"><img src="https://kimh060612.github.io/img/PVR_Entropy.png" width="100%"></p><p>이 내용을 갑자기 왜 하느냐? 우리는 다른 2개의 확률분포의 상대적 엔트로피와 상호 정보량을 계산하여 2개의 확률분포의 차이를 정량화 할 수 있기 때문이다.</p><p>우선, 우리가 근사를 목표로 하는 확률 분포를 $𝑝(𝑥)$라고 해보자.<br>이를 근사하기 위해서 모델을 학습시켜서 확률 분포 $𝑞(𝑥)$를 얻어 냈다고 치자.<br>이때, $𝑞(𝑥)$를 통해서 얻어낸 정보는 원래 $𝑝(𝑥)$를 통해서 얻을 수 있는 정보와 상이할 것이고, 우리는 이에 추가로 필요한 정보량의 평균을 다음과 같이 구할 수 있을 것이다.</p><script type="math/tex; mode=display">KL(p||q) = - \int p(x)\ln q(x) dx - ( - \int p(x)\ln p(x)dx) \\= - \int p(x)\ln q(x) - H_p[x]\tag{definition 3}</script><p>자, 그렇다면 우리는 대충 궤가 보인다. 우리가 결국 학습시켜야 하는 분포 $𝑞(𝑥)$와 정답인 분포 $𝑝(𝑥)$사이의 차이를 정량화 해주는 함수가 바로 이것인 것이다.<br>이를 “쿨백-라이브러리 발산”이라고 하며, 이를 통해서 우리는 두 확률 분포의 차이를 알 수 있는데,<br>자세히 보니, 뒤의 목표 분포의 엔트로피는 그냥 상수나 다름이 없다. 따라서 앞의 항만을 따서 따로 “Cross-Entropy”라고 하며, 다음과 같이 표현할 수 있다.</p><script type="math/tex; mode=display">KL(p||q) = CE(p||q) - H_p[x]\tag{definition 3}</script><h4 id="Gradient"><a href="#Gradient" class="headerlink" title="Gradient"></a>Gradient</h4><p>이 파트에서는 대학교에서 Calculus를 배우지 않은 (배웠다 하더라도 다변수 함수의 미분 파트를 안 들은 이들) 사람들이 꼭 보아 주었으면 한다. Gradient의 기초 중의 기초를 다룰 예정이다.</p><p>우리는 이전 시간에 결국에는 미분을 구해서 가중치를 update하는 것이라고 배워왔다.<br>근데, 이때 “Gradient”라는 것에 대한 명확한 설명 없이, 그냥 하면 된다는 식으로 짚고 넘어갔던 기억이 난다.</p><p>우선, 함수에서 몇가지 예시부터 생각하고 넘어가자.</p><ol><li>$f: \mathbb{R}^1 \rightarrow \mathbb{R}^1$</li><li>$f: \mathbb{R}^N \rightarrow \mathbb{R}^1$</li><li>$f: \mathbb{R}^1 \rightarrow \mathbb{R}^N$</li><li>$f: \mathbb{R}^N \rightarrow \mathbb{R}^M$</li></ol><p>이때, $N,M \geq 2$이다.</p><p>$\mathbb{R}^1$을 따로 분리한 이유가 있다. 함수에서 입/출력이 벡터(또는 행렬)인 것과 입/출력이 Scalar인 것은 다소 상이한 과정을 도입해야 하기 때문이다. 우리는 이 중에서도 2번을 특히 중요하게 다룰 것이다.</p><p>이렇게 함수는 여러가지 형태가 있을 수 있는데 이때, 각각 정의역에 대한 미분이 어떻게 정의될까?<br>이 파트에서는 그 예시를 들어볼 것이다. </p><p>우선, $f: \mathbb{R}^N \rightarrow \mathbb{R}^1$ 에서의 경우를 보자. 일 변수 스칼라 함수의 경우는 빼겠다. 그걸 모르면 이걸 들을 자격이 없다.</p><p>우리는 이러한 함수를 vector-scalar함수라고 부르겠다.<br>이러한 함수의 미분은 다음과 같이 정의할 수 있다. </p><script type="math/tex; mode=display">\textbf{x} \in \mathbb{R}^N, y \in \mathbb{R}^1</script><script type="math/tex; mode=display">\textbf{x} = [x_1, x_2, ..., x_N], y = f(\textbf{x})</script><p>이렇게 정의되어 있을 때, 함수 $f$에 대한 Gradient는 다음과 같이 표현되고 정의된다.</p><script type="math/tex; mode=display">\nabla_{\textbf{x}} f(\textbf{x}) = [\frac{\partial y}{\partial x_1}, \frac{\partial y}{\partial x_2}, ...,\frac{\partial y}{\partial x_N}]</script><p>여기서 만약 입력이 행렬이면 어떻게 되어야 할까?<br>즉, 다음과 같이 출력이 Scalar이고 입력이 벡터인 함수이다. (Matrix-Scalar함수)</p><script type="math/tex; mode=display">\textbf{x} \in \mathbb{R}^{N*M}, y \in \mathbb{R}^1</script><script type="math/tex; mode=display">\nabla_{\textbf{x}} f(\textbf{x}) = \begin{bmatrix}    \frac{\partial y}{\partial x_{11}} \cdots \frac{\partial y}{\partial x_{1M}} \\    \vdots \space \space \space \ddots \space \space \space \vdots \\    \frac{\partial y}{\partial x_{N1}} \cdots \frac{\partial y}{\partial x_{NM}}\end{bmatrix}</script><h3 id="Loss-Function-Examples"><a href="#Loss-Function-Examples" class="headerlink" title="Loss Function Examples"></a>Loss Function Examples</h3><hr><p>이 파트에서는 위에서 배운 수학적인 기초를 토대로 Loss function의 예시를 한번 볼 것이다. </p><p>우선 MSE부터 생각해 보자. 결국 MSE는 MLE/MAP를 이론적인 기저로 두고 있었다는 것을 위 글을 읽었다면 이해할 수 있었을 것이다. $equation 5$를 다시 한번 봐보자.</p><p>그렇다면 Cross-Entropy를 어떻게 사용할 것인가?<br>신경망에서는 이를 분류 문제를 어떻게 풀까? 우리는 Softmax 함수를 같이 사용하여 이를 해결할 수 있다.</p><p>먼저 softmax 함수부터 생각해 보자.</p><script type="math/tex; mode=display">y_i = \frac{e^{u^K_i}}{\sum^{n_{out}}_{j = 1}e^{u^K_j}}</script><p>위 함수를 Neural Network에서 output layer의 각 출력 값을 확률 분포로 바꾸어 준다고 생각하면 된다. 실제로 모든 unit의 값을 다 더하면 1이 되니깐 말이다.</p><p>이제 이러한 확률 분포를 토대로 실제 우리가 원하는 target 확률 분포와의 거리를 구하는 과정을 Cross entropy로 진행할 수 있을 것이다. 다음과 같이 말이다.</p><script type="math/tex; mode=display">E = -\sum^{n_{out}}_{i = 1} t_i \ln y_i</script><p>이때, target 분포는 class에 따라 one-hot encoding이 되어 있음<br>이때, 이 함수를 미분하면 어떻게 될까? 다음을 한번 보자.</p><p align="center"><img src="https://kimh060612.github.io/img/CE_Loss.png" width="100%"></p><p>결국 형태가 One hot encoding이 되어 있다면, MSE와 딱히 다를 것이 없다는 것을 알 수 있다.</p><h3 id="What-is-Optimizer"><a href="#What-is-Optimizer" class="headerlink" title="What is Optimizer?"></a>What is Optimizer?</h3><hr><p>이 파트에서는 위에서 배운 수학적 기초를 토대로 Optimizer가 어떻게 동작을 하는 놈들인지 배워 보도록 하겠다.</p><p>그래서 Deep learning에서의 Optimizer는 어떤 역할인지 알아보자. 결국 Deep learning은 해당 문제를 해결하는 것에 중심을 두고 있다. 이때, 우리는 특정한 문제를 해결한다고 했을 때, 특정 지표(ex. 정확도)를 최대화 한다는 것이다.<br>우리는 이때 정확도를 최대화 하기 위해서 데이터에서 얻을 수 있는 손실(Loss)를 최소화하는 것을 진행한다. 이는 기존 최적화와는 조금 다르다. 직접 지표를 최대화하는 것이 아닌, 간접적인 지표를 최소화하는 방향으로 가는 것이니 말이다. </p><p>그래서, 결국 Optimizer의 역할이 무엇인가?<br>다음과 같다.</p><script type="math/tex; mode=display">\min_w \mathbf{E}_{x,y \sim \hat{P}(x,y)} [L(f(x^i;w), y^i)]</script><p>이게 뭐냐? 즉 데이터에 대한 손실을 최소화 하는 것이다. 이것이 Optimizer 의 궁극적인 역할인 것이다.<br>이 문제는 1줄만 생각해 보면 간단해 보이지만 실은 겁나게 어렵고 복잡한 문제이다.<br>이 문제를 풀기 위해서 우리는 Gradient Descent라는 방법을 사용하는 것이다. </p><p>여기서 Gradient Descent의 수렴성을 설명하고 싶지만…. 강의에서는 생략하도록 하겠다. 더 자세히 알고 싶으면 Talyor 급수를 키워드로 잘 찾아보기를 바란다. 만약 나중에 시간이 된다면 다시 다루어 보도록 하겠다.</p><p>이쯤에서 미니 배치의 의미를 설명하고 가도록 하겠다.<br>이 것은 다음 그림으로 설명이 될 수 있다.</p><p align="center"><img src="https://kimh060612.github.io/img/MiniBatch.png" width="100%"></p><p>~역시 필자는 필자 스스로 생각해도 발 그림이다. 당도췌 어떤 정신머리로 이딴걸 그리는지 모르겠다.~</p><p>자 각설하고, 전체 데이터에서 정해진 Batch Size 만큼을 뽑아서 만든 데이터를 Mini Batch라고 한다. 이를 신경망에 넣어서 Feed Forward를 하고 Back propagation 연산을 하면서 가중치를 업데이트한다. 이것이 학습의 1개의 step이다. 그리고 이 mini batch set으로 전부의 데이터를 학습 했을때, 그것을 1개의 epoch이라고 한다. (통상적으로) 이렇게만 간단하게 생각하고 나머지는 Optimizer 별로 따로 생각하면 편할 것이다.</p><h3 id="Optimizer-examples"><a href="#Optimizer-examples" class="headerlink" title="Optimizer examples"></a>Optimizer examples</h3><hr><p>이 파트에서는 Optimizer의 종류가 어떤 것들이 있는지 알아보도록 하겠다.</p><ol><li>Stochastic Gradient Descent</li></ol><p>이 Optimizer는 가장 간단한 Optimizer라고 생각해도 된다. 위에서 설명한 대로, 간단하게 Mini Batch를 뽑아서 Update를 진행한다.</p><p align="center"><img src="https://kimh060612.github.io/img/SGD.png" width="100%"></p><ol><li>Adagrad</li></ol><p>이 방법은 이전에 사용했던 gradient들을 축적해서 사용하는 방법이다. gradient를 원소별로 제곱해서 step별로 더해가는 행렬을 하나 만들고, 그 행렬을 update할때 gradient에 원소별로 곱해주는 것이다. 제목 그대로 Adaptive gradient 방법인 것이다.</p><p align="center"><img src="https://kimh060612.github.io/img/Adagrad.png" width="100%"></p><ol><li>RMSProp</li></ol><p>이 방법은 위의 Adagrad 방법에서 조금 더 나아가, gradient를 더해나갈때 가중치를 두는 방법이다. </p><p align="center"><img src="https://kimh060612.github.io/img/RMSProp.png" width="100%"></p><ol><li>Adam</li></ol><p>현재 가장 많이들 쓰는 Optimizer이다. 이것도 별거 없다. RMSProp 처럼 가중합을 진행하는데, 이번에는 원소별로 제곱하지 않은 gradient도 누적 합을 저장해서 사용한다. 자세한 것을 수식을 보면 바로 감이 올 것이다.</p><p align="center"><img src="https://kimh060612.github.io/img/Adam.png" width="100%"></p><p>이걸로 Optimization 파트 A는 끝이 났다. 다음 파트는 위에서 배운 것들을 구현하면서 찾아 오도록 할 것이다.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Deep-Learning/">Deep Learning</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="https://kimh060612.github.io/tags/Mathematics/">Mathematics</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/05/Optimization-A/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Recurrent Neural Network 강의 내용 part.A</title>
      <link>https://kimh060612.github.io/2022/03/05/RNN-A/</link>
      <guid>https://kimh060612.github.io/2022/03/05/RNN-A/</guid>
      <pubDate>Sat, 05 Mar 2022 10:26:50 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;&lt;em&gt;본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document를 참조하여 작성되었음을 알립니다.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;Index&quot;&gt;&lt;a href=&quot;#Ind</description>
        
      
      
      
      <content:encoded><![CDATA[<p><em>본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document를 참조하여 작성되었음을 알립니다.</em></p><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li>Definition of Recurrent Neural Network(RNN)</li><li>Back Propagation of RNN</li><li>Partice</li></ol><p>여기서는 1,2는 Part. A이고 3은 Part. B에서 다루도록 하겠다.<br><br></p><h3 id="Definition-of-Recurrent-Neural-Network-RNN"><a href="#Definition-of-Recurrent-Neural-Network-RNN" class="headerlink" title="Definition of Recurrent Neural Network(RNN)"></a>Definition of Recurrent Neural Network(RNN)</h3><hr><p>RNN(Recurrent Neural Network)은 시계열 데이터를 처리하는데 특화된 신경망 구조이다.<br>이는 전의 입력이 연속해서 다음 입력에 영향을 주는 신경망 구조로써, 같은 구조가 계속 순환되어 나타나기 때문에 이러한 이름이 붙어져 있다.<br>다음 그림을 보자. </p><p align="center"><img src="https://kimh060612.github.io/img/RNN.png" width="100%"></p><p>하지만 이 그림으로는 자세한 구조까지는 잘 모르겠다. 그래서 필자가 직접 그린 그림을 보면서 설명하도록 하겠다. 말해두겠지만 필자는 그림을 심각하게 못 그리니 양해 바란다.</p><p align="center"><img src="https://kimh060612.github.io/img/RNND.png" width="100%"></p><p>이처럼 각 RNN Cell에 FCNN의 Unit이 들어가 있는 형식으로 구현된다. 이의 Feed Forward 연산을 생각해 보면 정말 간단하다.</p><script type="math/tex; mode=display">z_t = f(z_{t - 1}W_{re} + x_tW_{in} + b)\tag{equation 1}</script><p>$equation\space 1$에서 각 변수들의 정의는 다음과 같다.</p><blockquote><p>Definition 1</p></blockquote><ul><li>$z_t$: time step $t$에 unit의 값에 activation function에 넣은 값</li><li>$W_{re}$: Reccurent 가중치</li><li>$W_{in}$: input layer에서의 가중치</li><li>$x_t$: input vector</li></ul><p>그림으로 정리하면 대충 다음과 같다.</p><p align="center"><img src="https://kimh060612.github.io/img/RNND2.png" width="100%"></p><p>결국 이렇게 Sequential한 데이터 $x$에 대해서 Sequential한 output $y$를 뽑을 수 있는 것이다.</p><h3 id="Back-Propagation-of-RNN"><a href="#Back-Propagation-of-RNN" class="headerlink" title="Back Propagation of RNN"></a>Back Propagation of RNN</h3><hr><p>RNN의 Back Propagation 방법은 다음의 2가지가 있다. </p><ul><li>Back Propagation Through Time - (BPTT)</li><li>Real Time Recurrent Learning (RTRL)</li></ul><p>여기서는 BPTT만을 다루도록 하겠다. RNN을 그렇게 자세하게 다루지 않는 이유는 FCNN의 연장선 느낌이 강해서이고 또한 현대에서는 딱히 잘 쓰이지 않기 때문이다. 그냥 지적 유희를 위해서 또는 기본기를 잘 닦기 위해서로만 읽어주기를 바란다.</p><p>또는 AutoGrad 계열의 알고리즘을 공부하는 사람들은 미분 그래프를 사용한 AutoGrad이전에는 이런 식으로 역전파 알고리즘을 구현했었구나 라고 역사책 읽는 느낌으로 읽어주면 매우 감사하겠다. </p><p>이러한 RNN의 Back Propagation을 진행하기 위해서는 다음을 구하면 된다.</p><script type="math/tex; mode=display">\begin{aligned}    \frac{\partial E}{\partial w^{out}_{ij}} =\space ? \\    \frac{\partial E}{\partial w^{re}_{ij}} = \space ? \\    \frac{\partial E}{\partial w^{in}_{ij}} = \space?\end{aligned}\tag{definition 2}</script><p>이제 위 미분들에 chain rule을 적용해 보자. 그렇다면 다음과 같이 표현할 수 있다.</p><script type="math/tex; mode=display">\frac{\partial E}{\partial w^{out}_{ij}} = \sum^T_{t = 1} \frac{\partial E}{\partial v^{out}_{i}} \frac{\partial v^{out}_{i}}{\partial w^{out}_{ij}}\tag{equation 2}</script><script type="math/tex; mode=display">\frac{\partial E}{\partial w^{re}_{ij}} = \sum^T_{t = 1} \frac{\partial E}{\partial u^{t + 1}_{i}} \frac{\partial u^{t + 1}_{i}}{\partial w^{re}_{ij}}\tag{equation 3}</script><script type="math/tex; mode=display">\frac{\partial E}{\partial w^{in}_{ij}} = \sum^T_{t = 1} \frac{\partial E}{\partial u^{in}_{i}} \frac{\partial u^{in}_{i}}{\partial w^{out}_{ij}}\tag{equation 4}</script><p>자, 그렇다면 여기서 delta를 정의해서 일반화된 delta 규칙을 적용해 보아야 Back Propagation이 효율적으로 될 것이다. </p><p>그렇다면 각 미분들에 대한 delta는 다음과 같이 정의될 수 있다.</p><script type="math/tex; mode=display">\delta^{out}_{k,t} = \frac{\partial E}{\partial v^t_k} = \frac{\partial E}{\partial y^t_k} \frac{\partial y^t_k}{\partial v^t_k} = \frac{\partial E}{\partial y^t_k} f'(v^t_k)\tag{definition 3}</script><p>input layer에서의 가중치는 output layer처럼 FCNN과 완전히 같다. 굳이 적어두지는 않도록 하겠다. 그렇다면 남은 것은 recurrent layer에서의 delta이다. 전개해보면 대략 다음과 같이 표현할 수 있다.</p><p align="center"><img src="https://kimh060612.github.io/img/RNNDBPTT.png" width="100%"></p><p>이를 수식으로 표현하면 다음과 같이 표현할 수 있다.</p><script type="math/tex; mode=display">\delta^{re}_{j,t} = \sum^{n_{out}}_{i = 1} \frac{\partial E}{\partial v^t_i} \frac{\partial v^t_i}{\partial u^t_j} + \sum^{n_{re}}_{i = 1} \frac{\partial E}{\partial u^{t + 1}_i} \frac{\partial u^{t + 1}_i}{\partial u^t_j}\tag{definition 4}</script><p>각 Summation Term들의 delta를 이용해서 표현해 보면 다음과 같다.</p><script type="math/tex; mode=display">\delta^{re}_{j,t} = \sum^{n_{out}}_{i = 1} \delta^{out}_{i,t} \frac{\partial v^t_i}{\partial u^t_j} + \sum^{n_{re}}_{i = 1} \delta^{re}_{i, t} \frac{\partial u^{t + 1}_i}{\partial u^t_j}  \\ = \sum^{n_{out}}_{i = 1} \delta^{out}_{i,t} w^{out}_{ij} f'(u^t_j) + \sum^{n_{re}}_{i = 1} \delta^{re}_{i, t} w^{re}_{ij} f'(u^t_j)\tag{equation 4}</script><p>즉, 이와 같이 RNN Cell의 기본 형태의 BPTT는 정말 단순하게도 FCNN의 연장선이다. 별게 없다.</p><p>그리고 이의 변형판으로 시간을 분할해서 Update하는 방법도 있다. 이를 Truncated BPTT라고 하는데 관심이 있다면 찾아보도록 하자. 이것도 진짜 별거 없다.</p><p>그저 위의 미분에서 시간 term을 잘라서 update 해주면 된다.</p><p>이걸로 RNN 또한 끝이 났다. 다음 파트에서는 이를 구현해 보도록 하겠다.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Deep-Learning/">Deep Learning</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="https://kimh060612.github.io/tags/Mathematics/">Mathematics</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/05/RNN-A/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Recurrent Neural Network 강의 내용 part.B</title>
      <link>https://kimh060612.github.io/2022/03/05/RNN-B/</link>
      <guid>https://kimh060612.github.io/2022/03/05/RNN-B/</guid>
      <pubDate>Sat, 05 Mar 2022 10:26:47 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;&lt;em&gt;본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document를 참조하여 작성되었음을 알립니다.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;Index&quot;&gt;&lt;a href=&quot;#Ind</description>
        
      
      
      
      <content:encoded><![CDATA[<p><em>본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document를 참조하여 작성되었음을 알립니다.</em></p><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li><del>Definition of Recurrent Neural Network(RNN)</del></li><li><del>Back Propagation of RNN</del></li><li>Partice</li></ol><p><br></p><h3 id="Partice"><a href="#Partice" class="headerlink" title="Partice"></a>Partice</h3><hr><p>진짜 여기까지 과연 읽은 사람이 있을까 싶다. 있다면 압도적 감사의 의미로 그랜절을 박고 싶은 마음이다. ㅋㅋ </p><p>장난은 그만하고 오늘도 시작하자. 오늘도 역시 Model Subclassing API를 활용하여 간단하게 RNN을 활용하는 예제를 구현해볼 것이다.</p><p>우선 RNN을 tensorflow에서 어떻게 사용할 수 있는지부터 보자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RNNLayer</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_hidden=<span class="number">128</span>, num_class=<span class="number">39</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(RNNLayer, self).__init__()</span><br><span class="line">        self.RNN1 = keras.layers.SimpleRNN(num_hidden, activation=<span class="string">&#x27;tanh&#x27;</span>, return_sequences=<span class="literal">True</span>)</span><br><span class="line">        self.out = keras.layers.Dense(num_class, activation=<span class="string">&quot;softmax&quot;</span>)</span><br><span class="line">        self.out = keras.layers.TimeDistributed(self.out)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.RNN1(x)</span><br><span class="line">        out = self.out(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>보면 알다시피 아주 간단하다. 그래서 이번 포스트에서는 간단하게 2개의 관전 포인트만을 다루려고 한다.</p><ol><li>SimpleRNN layer의 특징</li><li>TimeDistributed layer의 특징</li></ol><p>1번부터 차례로 시작하자.</p><p>우선 SimpleRNN을 이해하려면 입력으로는 어떤 tensor를 받아먹어서 출력으로는 어떤 tensor를 뱉어내는지를 알아야 한다.<br>지난 포스트에서 RNN의 구조를 보았다면 당연히 입력은 시간순서대로 벡터가 들어가니 적어도 3차원(배치까지 포함해서) 일 것이고 출력도 시간 순서대로 나와야 하니 같은 3차원이라는 것 쯤은 유추가 가능할 것이다. 하지만 실제로는 이것 또한 조절이 가능하다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.SimpleRNN(</span><br><span class="line">    units, activation=<span class="string">&#x27;tanh&#x27;</span>, use_bias=<span class="literal">True</span>,</span><br><span class="line">    kernel_initializer=<span class="string">&#x27;glorot_uniform&#x27;</span>,</span><br><span class="line">    recurrent_initializer=<span class="string">&#x27;orthogonal&#x27;</span>,</span><br><span class="line">    bias_initializer=<span class="string">&#x27;zeros&#x27;</span>, kernel_regularizer=<span class="literal">None</span>,</span><br><span class="line">    recurrent_regularizer=<span class="literal">None</span>, bias_regularizer=<span class="literal">None</span>, activity_regularizer=<span class="literal">None</span>,</span><br><span class="line">    kernel_constraint=<span class="literal">None</span>, recurrent_constraint=<span class="literal">None</span>, bias_constraint=<span class="literal">None</span>,</span><br><span class="line">    dropout=<span class="number">0.0</span>, recurrent_dropout=<span class="number">0.0</span>, return_sequences=<span class="literal">False</span>, return_state=<span class="literal">False</span>,</span><br><span class="line">    go_backwards=<span class="literal">False</span>, stateful=<span class="literal">False</span>, unroll=<span class="literal">False</span>, **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>이는 tensorflow 공식 문서에 적혀 있는 SimpleRNN에 관한 내용이다. 여기서 우리가 관심 있게 봐야 할 것은 return_sequences와 return_state이다.</p><p>만약, return_sequences가 False면, SimpleRNN layer는 맨 마지막의 출력만을 뱉어낸다. 즉, 2차원 출력이 되는 것이다. ([Batch_size, output_dim]) 하지만 이 파라미터가 True이면 모든 시간의 출력을 출력으로 내뱉는다. 즉, 3차원 출력이 되는 것이다. </p><p>그리고 return_state의 경우, 이것이 True이면 출력의 Hidden State를 출력으로 같이 내뱉는다. 즉, 출력이 tuple이 되는 것이다. (출력 벡터, hidden 벡터)</p><p>이렇게 되면 우리는 여러가지 경우의 수를 고려해서 모델을 만드는 것이 가능해진다.</p><ol><li>맨 마지막 출력만을 고려하여 예측하는 모델</li><li>입력마다 다음에 나올 출력을 예측하는 모델</li></ol><p>전자를 Many to One, 후자를 Many to Many라고 한다.</p><p>그렇다면 Many to Many를 해주기 위해서는 시간 순서에 맞춰서 <em>같은</em> Dense layer를 적용해줄 필요가 있다. 이를 위해서 필요한 것이 바로 TimeDistributed layer이다. 이는 각 시간 step에 대해서 같은 Dense layer의 weight로 연산을 진행해 준다.</p><p>하지만 기본적으로 tensorflow에서 Dense layer는 broadcast 기능을 제공한다. 따라서 굳이 TimeDistributed layer 없이도 3차원 텐서가 들어오면 맨 마지막 차원에 대해서 Dense 연산을 진행하게 된다. </p><p>따라서, Dense만을 사용할거면 굳이 TimeDistributed layer가 필요 없다.</p><p>RNN의 포스팅은 이걸로 마치도록 하겠다. 딱히 크게 어려운 점도 없고 나중에 나올 Attention이 훨씬 더 어그로가 끌려야할 주제이기 때문이다.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Deep-Learning/">Deep Learning</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="https://kimh060612.github.io/tags/Tensorflow2/">Tensorflow2</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/05/RNN-B/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Convoltional Neural Network 강의 내용 part.B</title>
      <link>https://kimh060612.github.io/2022/03/05/CNN-B/</link>
      <guid>https://kimh060612.github.io/2022/03/05/CNN-B/</guid>
      <pubDate>Sat, 05 Mar 2022 10:26:43 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;&lt;em&gt;본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document를 참조하여 작성되었음을 알립니다.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;Index&quot;&gt;&lt;a href=&quot;#Ind</description>
        
      
      
      
      <content:encoded><![CDATA[<p><em>본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document를 참조하여 작성되었음을 알립니다.</em></p><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li><del>Introduction of Convolution Operation</del></li><li><del>Definition of Convolutional Neural Network(CNN)</del></li><li><del>Back Propagation of CNN</del></li><li>Partice</li></ol><h4 id="6-Partice"><a href="#6-Partice" class="headerlink" title="6. Partice"></a>6. Partice</h4><hr><p>이 파트는 Convolutional Nerual Network를 직접 구현하는 파트이다. 비단 Convolutional Neural Network 뿐만 아니라 그를 이용한 다양한 현대적인 네트워크 구조들을 구현해 보는 시간을 가지도록 하겠다. 필자의 Deep learning 구현 관련 블로그 포스팅은 전부 Model Subclassing API로 구현될 예정이다. 왜냐? 필자 맘이다 <del>(꼬우면 보지 말든가)</del> 장닌이고, 필자가 생각하기에는 Model Subclassing API의 활용 장점은 확실히 있는 것 같다.</p><ol><li><p>모델을 가독성 있게 관리할 수 있다.</p><p>이는 전적으로 OOP에 대한 기본 개념 및 디자인 패턴을 잘 아는 사람에 한에서 그런거다.<br>Vision Transformer쯤 가면 알겠지만, 정말 짜야하는 연산들이 엄청 많다. 그런걸 하나하나 함수로 짜거나 Sequential API로 구성하면 지옥문이 열리게 된다. 아 물론 짜는건 무리가 없겠지만, 유지보수 관점에서는 정말 지옥일 것이다.<br>그런 의미에서 Model Subclassing API는 원하는 연산을 Class단위로 묶어서 설계하고 그들을 체계적으로 관리할 수 있는 지식이 조금이라도 있다면 (복잡한 디자인 패턴까지는 필요도 없다) 훨씬 가독성이 높은 코드를 짤 수 있다.</p></li><li><p>Low Level한 연산을 자유롭게 정의할 수 있다.</p><p> Model Subclassing API를 사용하면 Custom Layer, Scheduler 등등 여러 연산을 사용자의 입맛에 맞게 정의할 수 있다. 이러면 내가 세운 새로운 가설, 연구 아이디어를 보다 쉽게 구현할 수 있는 판로가 열리는 것이다. 물론 이는 전적으로 자신이 새로운 연산을 구상하고 구현할만한 경지에 도달했을때의 이야기이다.</p></li><li><p>특히 Pytorch로 소스코드 전환을 비교적 쉽게 할 수 있다.</p><p>이건 지극히 필자의 개인적인 생각이다. 필자는 pytorch와 tensorflow를 동시에 써가면서 일을 하고 있다. 모델 개발 및 연구는 pytorch로 배포는 tensorflow를 사용하고 있는데, 모델을 tensorflow로 완전히 포팅해야할 일이 가끔씩 있다. 이때 model subclassing API를 활용하는 편이 소스코드의 구조나 뽄새가 비슷해서 편했던 기억이 난다.</p></li></ol><p>하지만 단점도 명확하게 있다.</p><ol><li><p>못쓰면 이도 저도 안된다.</p><p> 보면 알다시피, OOP의 기초 지식과 low level로 연산을 정의해서 사용할 수 있는 사람이 아니라면 굳이 Subclassing API를 쓰겠다고 깝치다가 되려 오류만 범할 가능성이 높다.</p></li></ol><p>하지만 필자는 앞으로 잘하고 싶어서 힘든 길을 골라 보았다. 독자들도 이에 동의하리라고 믿는다. <del>(아니면 뒤로 가든가)</del></p><p>사족이 길었는데, 앞으로도 계속 Model Subclassing API만을 사용해서 포스팅을 할 예정이다.</p><p>우선, 지난 FCNN처럼 tensorflow 2로 어떻게 CNN layer를 정의할 수 있는지부터 알아보자.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CustomConv2D</span>(keras.layers.Layer):</span><br><span class="line">    <span class="comment">#              1. output image의 채널  2. 커널의 이미지 사이즈  3. Stride를 정해줬어야함. 4. Pooling을 정해줬어야함.(Optional) 5. Padding을 정해야함.</span></span><br><span class="line">    <span class="comment">#                                                       i  x 방향으로의 stride y 방향으로의 stride      i</span></span><br><span class="line">    <span class="comment"># &quot;SAME&quot; OH = H, &quot;VALID&quot; 가능한 패딩 필터 중에서 가장 작은 패딩(양수)으로 설정  </span></span><br><span class="line">    <span class="comment"># OH = (H + 2*P - KH)/S + 1 = 15.5</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, out_channel, kernel_size, Strides = (<span class="params"><span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span></span>), Padding = <span class="string">&quot;SAME&quot;</span>, trainable=<span class="literal">True</span>, name=<span class="literal">None</span>, dtype=<span class="literal">None</span>, dynamic=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(trainable=trainable, name=name, dtype=dtype, dynamic=dynamic, **kwargs)</span><br><span class="line">        <span class="comment"># &quot;3,4&quot; </span></span><br><span class="line">        self.out_channel = out_channel</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(kernel_size) == <span class="built_in">type</span>(<span class="number">1</span>):</span><br><span class="line">            self.kernel_size = (kernel_size, kernel_size)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">type</span>(kernel_size) == <span class="built_in">type</span>(<span class="built_in">tuple</span>()):</span><br><span class="line">            self.kernel_size = kernel_size</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;Not a Valid Kernel Type&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(Strides) == <span class="built_in">type</span>(<span class="number">1</span>):</span><br><span class="line">            self.Stride = (<span class="number">1</span>, Strides, Strides, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">type</span>(Strides) == <span class="built_in">type</span>(<span class="built_in">tuple</span>()):</span><br><span class="line">            self.Stride = Strides</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;Not a Valid Stride Type&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(Padding) == <span class="built_in">type</span>(<span class="built_in">str</span>()):</span><br><span class="line">            self.Padding = Padding</span><br><span class="line">        <span class="keyword">else</span> :</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;Not a Valid Padding Type&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build</span>(<span class="params">self, input_shape</span>):</span><br><span class="line">        WeightShape = (self.kernel_size[<span class="number">0</span>], self.kernel_size[<span class="number">1</span>], input_shape[-<span class="number">1</span>], self.out_channel)</span><br><span class="line">        self.Kernel = self.add_weight(</span><br><span class="line">            shape=WeightShape,</span><br><span class="line">            initializer=<span class="string">&quot;random_normal&quot;</span>,</span><br><span class="line">            trainable= <span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.Bias = self.add_weight(</span><br><span class="line">            shape=(self.out_channel, ),</span><br><span class="line">            initializer=<span class="string">&quot;random_normal&quot;</span>,</span><br><span class="line">            trainable=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, Input</span>):</span><br><span class="line">        Out = tf.nn.conv2d(Input, self.Kernel, strides=self.Stride, padding=self.Padding)</span><br><span class="line">        Out = tf.nn.bias_add(Out, self.Bias, data_format=<span class="string">&quot;NHWC&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> Out</span><br></pre></td></tr></table></figure><p>이전에도 설명했듯이 build에서 필요한 Weight를 정의한 뒤에 call에서 그것을 사용한다. 다행이게도 tensorflow에서는 최소한 convolution 연산을 정의해 주었다.<br>앞으로도 필요한 연산이 있다면 이렇게 정의해 주면 된다.</p><p>하지만 우리는 굳이 이렇게 convolution layer를 정의해줄 필요가 없다. 왜냐면 tensorflow keras에서 이미 정의되어 있는 좋은 함수가 있기 때문이다. 이에 대한 아주 간단한 사용 예제로써 Alexnet과 ResNet을 구현해 보도록 하겠다. 부록으로 GoogLeNet을 구현한 예제도 있는데, 이는 필자의 Github에 올려 두도록 할테니 시간이 되면 가서 봐 주었으면 한다.</p><p>우선 AlexNet부터 가보자. 모델의 구조를 사진으로 한번 봐보도록 하자.</p><p align="center"><img src="http://kimh060612.github.io/img/AlexNet.jpg" width="70%" height="70%"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AlexNet</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 원래 여기에는 커널 사이즈로 (11, 11)이 들어가고 padding은 valid이다. 하지만 메모리 때문에 돌아가지 않는 관계로 이미지 크기를 줄아느라 부득이하게 모델을 조금 변경했다.</span></span><br><span class="line">        self.Conv1 = keras.layers.Conv2D(<span class="number">96</span>, (<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">4</span>, <span class="number">4</span>), padding=<span class="string">&quot;SAME&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        <span class="comment"># LRN 1</span></span><br><span class="line">        self.BatchNorm1 = keras.layers.BatchNormalization()</span><br><span class="line">        self.MaxPool1 = keras.layers.MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">&quot;VALID&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.Conv2 = keras.layers.Conv2D(<span class="number">256</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), padding=<span class="string">&quot;SAME&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        <span class="comment"># LRN2</span></span><br><span class="line">        self.BatchNorm2 = keras.layers.BatchNormalization()</span><br><span class="line">        self.MaxPool2 = keras.layers.MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">&quot;VALID&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.Conv3 = keras.layers.Conv2D(<span class="number">384</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&quot;SAME&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        self.Conv4 = keras.layers.Conv2D(<span class="number">384</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&quot;SAME&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        self.Conv5 = keras.layers.Conv2D(<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&quot;SAME&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        self.MaxPool3 = keras.layers.MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">        self.Flat = keras.layers.Flatten()</span><br><span class="line"></span><br><span class="line">        self.Dense1 = keras.layers.Dense(<span class="number">4096</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        self.DropOut1 = keras.layers.Dropout(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">        self.Dense2 = keras.layers.Dense(<span class="number">4096</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        self.DropOut2 = keras.layers.Dropout(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">        self.OutDense = keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&quot;softmax&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, Input</span>):</span><br><span class="line">        X = self.Conv1(Input)</span><br><span class="line">        X = self.BatchNorm1(X)</span><br><span class="line">        X = self.MaxPool2(X)</span><br><span class="line">        X = self.Conv2(X)</span><br><span class="line">        X = self.BatchNorm2(X)</span><br><span class="line">        X = self.MaxPool2(X)</span><br><span class="line">        X = self.Conv3(X)</span><br><span class="line">        X = self.Conv4(X)</span><br><span class="line">        X = self.Conv5(X)</span><br><span class="line">        X = self.MaxPool3(X)</span><br><span class="line">        X = self.Flat(X)</span><br><span class="line">        X = self.Dense1(X)</span><br><span class="line">        X = self.DropOut1(X)</span><br><span class="line">        X = self.Dense2(X)</span><br><span class="line">        X = self.DropOut2(X)</span><br><span class="line">        X = self.OutDense(X)</span><br><span class="line">        <span class="keyword">return</span> X</span><br></pre></td></tr></table></figure><p>자, 필자는 굳이 더럽게 짜 보았다. 왜냐? <em>이렇게 짤거면 Model Subclassing을 쓰지 말라는 의미로 이렇게 짜 보았다.</em> 진짜 이따구로 짤거면 그냥 Sequential API나 Functional API를 사용하자. 근데 이 정도면 설명이 필요 없을 정도로 그냥 무지성 구현을 시전한 것이다. 그러니 간단하게 Keras의 Conv2D를 설명하고 넘어 가도록 하겠다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Conv2D(filters, kernel_size=(kernel_sz, kernel_sz), padding=<span class="string">&quot;SAME&quot;</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br></pre></td></tr></table></figure><p>이전에 이론 글에서 설명했던 부분을 다시 되짚어 보고 위 함수를 다시 살펴보자.</p><blockquote><p><em>Definition 1</em></p></blockquote><ul><li>$w_{ijmk}^l$: $l$번째 층의 Weight의 $k$번째 Kernel Set에 $m$번째 Channel, $i$행, $j$열의 성분</li></ul><p>위의 $w_{ijmk}^l$를 우리는 위의 Conv2D 함수로 정의한 것이다. filters는 kernel set의 개수를 의미하며, kernel_size는 Weight kernel의 이미지 크기를 의미한다. padding은 “SAME”과 “VALID”가 있는데, “SAME”으로 하면 알아서 크기를 계산해서 입력 이미지와 출력 이미지의 크기를 같게 만든다. Valid를 선택하면 그냥 padding이 없다고 판단하면 된다. </p><p>AlextNet에서 대충 Conv2D를 어떻게 사용하는지 감이 왔다면, ResNet을 한번 구현해 보자.</p><p>ResNet에 대한 자세한 설명은 다른 포스트에서 정말 이게 맞나 싶을 정도로 분해해서 설명하도록 하겠다. 지금은 그저 다음과 같은 구조가 있구나 정도만 이해하고 넘어가면 된다.</p><p align="center"><img src="http://kimh060612.github.io/img/ResNet50.png" width="70%" height="70%"></p><p>이것이 ResNet50의 구조인데, 2가지 layer를 구현해 보아야 한다. 첫번째는 Conv Block이고 두번째는 Identity Block이다. 하나는 Skip Connection에 Convolution layer를 입힌 것이고 다른 하나는 그렇지 않은 것 뿐이다.</p><blockquote><p>Residual Conv Block</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResidualConvBlock</span>(tfk.layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, InputChannel, OutputChannel, strides = (<span class="params"><span class="number">1</span>, <span class="number">1</span></span>), trainable=<span class="literal">True</span>, name=<span class="literal">None</span>, dtype=<span class="literal">None</span>, dynamic=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(trainable=trainable, name=name, dtype=dtype, dynamic=dynamic, **kwargs)</span><br><span class="line"></span><br><span class="line">        self.Batch1 = tfk.layers.BatchNormalization(momentum=<span class="number">0.99</span>, epsilon= <span class="number">0.001</span>)</span><br><span class="line">        self.conv1 = tfk.layers.Conv2D(filters=InputChannel, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=strides)</span><br><span class="line">        self.LeakyReLU1 = tfk.layers.LeakyReLU()</span><br><span class="line">        self.Batch2 = tfk.layers.BatchNormalization(momentum=<span class="number">0.99</span>, epsilon= <span class="number">0.001</span>)</span><br><span class="line">        self.conv2 = tfk.layers.Conv2D(filters=InputChannel, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">&quot;SAME&quot;</span>)</span><br><span class="line">        self.LeakyReLU2 = tfk.layers.LeakyReLU()</span><br><span class="line">        self.Batch3 = tfk.layers.BatchNormalization(momentum=<span class="number">0.99</span>, epsilon= <span class="number">0.001</span>)</span><br><span class="line">        self.conv3 = tfk.layers.Conv2D(filters=OutputChannel, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.LeakyReLU3 = tfk.layers.LeakyReLU()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Skip Connection</span></span><br><span class="line">        self.SkipConnection = tfk.layers.Conv2D(filters=OutputChannel, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=strides)</span><br><span class="line">        self.SkipBatch = tfk.layers.BatchNormalization(momentum=<span class="number">0.99</span>, epsilon= <span class="number">0.001</span>)</span><br><span class="line">        self.LeakyReLUSkip = tfk.layers.LeakyReLU()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, Input</span>):</span><br><span class="line">        Skip = Input</span><br><span class="line">        Skip = self.SkipConnection(Skip)</span><br><span class="line">        Skip = self.SkipBatch(Skip)</span><br><span class="line">        Skip = self.LeakyReLUSkip(Skip)</span><br><span class="line">        Z = Input</span><br><span class="line">        Z = self.conv1(Z)</span><br><span class="line">        Z = self.Batch1(Z)</span><br><span class="line">        Z = self.LeakyReLU1(Z)</span><br><span class="line">        Z = self.conv2(Z)</span><br><span class="line">        Z = self.Batch2(Z)</span><br><span class="line">        Z = self.LeakyReLU2(Z)  </span><br><span class="line">        Z = self.conv3(Z)</span><br><span class="line">        Z = self.Batch3(Z)</span><br><span class="line">        Z = self.LeakyReLU3(Z)</span><br><span class="line">        <span class="keyword">return</span> Z + Skip </span><br></pre></td></tr></table></figure><blockquote><p>Residual Identity Block</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResidualIdentityBlock</span>(tfk.layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, InputChannel, OutputChannel, trainable=<span class="literal">True</span>, name=<span class="literal">None</span>, dtype=<span class="literal">None</span>, dynamic=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(trainable=trainable, name=name, dtype=dtype, dynamic=dynamic, **kwargs)</span><br><span class="line">        self.Batch1 = tfk.layers.BatchNormalization(momentum=<span class="number">0.99</span>, epsilon= <span class="number">0.001</span>)</span><br><span class="line">        self.conv1 = tfk.layers.Conv2D(filters=InputChannel, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.LeakyReLU1 = tfk.layers.LeakyReLU()</span><br><span class="line">        self.Batch2 = tfk.layers.BatchNormalization(momentum=<span class="number">0.99</span>, epsilon= <span class="number">0.001</span>)</span><br><span class="line">        self.conv2 = tfk.layers.Conv2D(filters=InputChannel, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), padding=<span class="string">&quot;SAME&quot;</span>)</span><br><span class="line">        self.LeakyReLU2 = tfk.layers.LeakyReLU()</span><br><span class="line">        self.Batch3 = tfk.layers.BatchNormalization(momentum=<span class="number">0.99</span>, epsilon= <span class="number">0.001</span>)</span><br><span class="line">        self.conv3 = tfk.layers.Conv2D(filters=OutputChannel, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.LeakyReLU3 = tfk.layers.LeakyReLU()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, Input</span>):</span><br><span class="line">        Skip = Input</span><br><span class="line">        Z = Input</span><br><span class="line">        Z = self.conv1(Z)</span><br><span class="line">        Z = self.Batch1(Z)</span><br><span class="line">        Z = self.LeakyReLU1(Z)</span><br><span class="line">        Z = self.conv2(Z)</span><br><span class="line">        Z = self.Batch2(Z)</span><br><span class="line">        Z = self.LeakyReLU2(Z)  </span><br><span class="line">        Z = self.conv3(Z)</span><br><span class="line">        Z = self.Batch3(Z)</span><br><span class="line">        Z = self.LeakyReLU3(Z)</span><br><span class="line">        <span class="comment"># Z : 256</span></span><br><span class="line">        <span class="keyword">return</span> Z + Skip</span><br></pre></td></tr></table></figure><p>우선 이 또한 정말이지 Model Subclassing을 그지같이 사용한 예시중 하나이다. 부디 독자들은 이따구로 구현할거면 그냥 Functional API를 사용하기 바란다.</p><p>이쯤되면 이런 질문이 나올 것이다. </p><blockquote><p>Q: 왜 저게 그지같이 구현한 예시인가요?<br>A: 여러 이유가 있지만, 가장 큰 이유는 굳이 모델(Weight)의 정의와 호출을 분리할 이유가 전혀 없는 구조이기 때문입니다.</p></blockquote><p>여기까지 잘 따라왔다면 이제 이 2개의 layer를 사용해서 ResNet50을 다음과 같이 구현할 수 있다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet50</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># Input Shape 224*224*3</span></span><br><span class="line">        <span class="comment"># Conv 1 Block</span></span><br><span class="line">        self.ZeroPadding1 = keras.layers.ZeroPadding2D(padding=(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">        self.Conv1 = keras.layers.Conv2D(filters = <span class="number">64</span>, kernel_size=(<span class="number">7</span>, <span class="number">7</span>), strides=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        self.Batch1 = keras.layers.BatchNormalization()</span><br><span class="line">        self.ReLU1 = keras.layers.LeakyReLU()</span><br><span class="line">        self.ZeroPadding2 = keras.layers.ZeroPadding2D(padding=(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        self.MaxPool1 = keras.layers.MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">2</span>)</span><br><span class="line">        self.ResConvBlock1 = ResidualConvBlock(<span class="number">64</span>, <span class="number">256</span>, strides = (<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.ResIdentityBlock1 = ResidualIdentityBlock(<span class="number">64</span>, <span class="number">256</span>)</span><br><span class="line">        self.ResIdentityBlock2 = ResidualIdentityBlock(<span class="number">64</span>, <span class="number">256</span>)</span><br><span class="line"></span><br><span class="line">        self.ResConvBlock2 = ResidualConvBlock(<span class="number">128</span>, <span class="number">512</span>, strides = (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        self.ResIdentityBlock3 = ResidualIdentityBlock(<span class="number">128</span>, <span class="number">512</span>)</span><br><span class="line">        self.ResIdentityBlock4 = ResidualIdentityBlock(<span class="number">128</span>, <span class="number">512</span>)</span><br><span class="line">        self.ResIdentityBlock5 = ResidualIdentityBlock(<span class="number">128</span>, <span class="number">512</span>)</span><br><span class="line"></span><br><span class="line">        self.ResConvBlock3 = ResidualConvBlock(<span class="number">256</span>, <span class="number">1024</span>, strides = (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        self.ResIdentityBlock6 = ResidualIdentityBlock(<span class="number">256</span>, <span class="number">1024</span>)</span><br><span class="line">        self.ResIdentityBlock7 = ResidualIdentityBlock(<span class="number">256</span>, <span class="number">1024</span>)</span><br><span class="line">        self.ResIdentityBlock8 = ResidualIdentityBlock(<span class="number">256</span>, <span class="number">1024</span>)</span><br><span class="line">        self.ResIdentityBlock9 = ResidualIdentityBlock(<span class="number">256</span>, <span class="number">1024</span>)</span><br><span class="line">        self.ResIdentityBlock10 = ResidualIdentityBlock(<span class="number">256</span>, <span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line">        self.ResConvBlock4 = ResidualConvBlock(<span class="number">512</span>, <span class="number">2048</span>, strides = (<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.ResIdentityBlock11 = ResidualIdentityBlock(<span class="number">512</span>, <span class="number">2048</span>)</span><br><span class="line">        self.ResIdentityBlock12 = ResidualIdentityBlock(<span class="number">512</span>, <span class="number">2048</span>)</span><br><span class="line">        </span><br><span class="line">        self.GAP = keras.layers.GlobalAveragePooling2D()</span><br><span class="line">        self.DenseOut = keras.layers.Dense(<span class="number">1000</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, Input</span>):</span><br><span class="line">        X = self.ZeroPadding1(Input)</span><br><span class="line">        X = self.Conv1(X)</span><br><span class="line">        X = self.Batch1(X)</span><br><span class="line">        X = self.ReLU1(X)</span><br><span class="line">        X = self.ZeroPadding2(X)</span><br><span class="line"></span><br><span class="line">        X = self.MaxPool1(X)</span><br><span class="line">        X = self.ResConvBlock1(X)</span><br><span class="line">        X = self.ResIdentityBlock1(X)</span><br><span class="line">        X = self.ResIdentityBlock2(X)</span><br><span class="line"></span><br><span class="line">        X = self.ResConvBlock2(X)</span><br><span class="line">        X = self.ResIdentityBlock3(X)</span><br><span class="line">        X = self.ResIdentityBlock4(X)</span><br><span class="line">        X = self.ResIdentityBlock5(X)</span><br><span class="line"></span><br><span class="line">        X = self.ResConvBlock3(X)</span><br><span class="line">        X = self.ResIdentityBlock6(X)</span><br><span class="line">        X = self.ResIdentityBlock7(X)</span><br><span class="line">        X = self.ResIdentityBlock8(X)</span><br><span class="line">        X = self.ResIdentityBlock9(X)</span><br><span class="line">        X = self.ResIdentityBlock10(X)</span><br><span class="line"></span><br><span class="line">        X = self.ResConvBlock4(X)</span><br><span class="line">        X = self.ResIdentityBlock11(X)</span><br><span class="line">        X = self.ResIdentityBlock12(X)</span><br><span class="line"></span><br><span class="line">        X = self.GAP(X)</span><br><span class="line">        Out = self.DenseOut(X)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> Out</span><br></pre></td></tr></table></figure><p>여기서 하나 GAP로 정의된 Global Average Pooling layer가 있다. 이것에 대해서 간단하게만 알아보자.</p><p>이 layer는 단순하게 말하자면 feaeture map을 1차원을 만들어 주는 layer이다. 대개, Image는 3차원인데, 차원별로 존재하는 image를 하나의 Scalar 값으로 만든다는 뜻이다. (Global Pooling) 그때, Scalar 값으로 만드는 과정에서 이미지의 각 픽셀 값을 평균을 내는 방법을 취한 것 뿐이다. (Average)</p><p>이를 간단히 그림으로 표현하자면 다음과 같다.</p><p align="center"><img src="http://kimh060612.github.io/img/GAP.jpg" width="100%" height="100%"></p><p>그림에서 보여지는 것과 같이, 각 채널에 있는 이미지들의 픽셀값을 평균을 내서 그것을 모으면 채널의 개수 만큼의 크기를 가지는 1-dimensional vector가 완성된다.</p><p>여기까지 Convolutional Neural Network의 구현 실습을 마치도록 하겠다. 부디 도움이 되었….을까?는 모르겠지만 재밌게 보았으면 좋겠다.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Deep-Learning/">Deep Learning</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="https://kimh060612.github.io/tags/Tensorflow2/">Tensorflow2</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/05/CNN-B/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Convoltional Neural Network 강의 내용 part.A</title>
      <link>https://kimh060612.github.io/2022/03/05/CNN-A/</link>
      <guid>https://kimh060612.github.io/2022/03/05/CNN-A/</guid>
      <pubDate>Sat, 05 Mar 2022 10:26:40 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;&lt;em&gt;본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document를 참조하여 작성되었음을 알립니다.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;Index&quot;&gt;&lt;a href=&quot;#Ind</description>
        
      
      
      
      <content:encoded><![CDATA[<p><em>본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document를 참조하여 작성되었음을 알립니다.</em></p><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li>Introduction of Convolution Operation  </li><li>Definition of Convolutional Neural Network(CNN)</li><li>Back Propagation of CNN</li><li>Partice</li></ol><p>여기서는 1~3는 Part. A이고 4은 Part. B에서 다루도록 하겠다.<br><br></p><h3 id="Introduction-of-Convolution-Operation"><a href="#Introduction-of-Convolution-Operation" class="headerlink" title="Introduction of Convolution Operation"></a>Introduction of Convolution Operation</h3><hr><p>Convolutional Neural Network는 Convolution 연산을 Neural Network에 적용한 것이다. 따라서 이를 알기 위해서는 Convolution 연산을 먼저 알아야할 필요가 있다. 관련 학과 대학생이라면 아마도 신호와 시스템을 배우면서 이를 처음 접했을 것이다. Continuous domain, Discrete domian까지 이 연산을 정의될 수 있고 각각에 따라 계산 방법 또한 배웠을 것이다. 예를 들어서 2차원의 Image와 2차원의 Filter의 Convolution 연산을 수식으로 표현해 보도록 하겠다.</p><ul><li>Image 행렬 정의</li></ul><script type="math/tex; mode=display">I(i, j)</script><p>Image의 $i$열, $j$행의 성분 </p><ul><li>Filter 행렬 정의</li></ul><script type="math/tex; mode=display">K(i, j)</script><p>Filter의 $i$열, $j$행의 성분. 높이를 $k_1$, 너비를 $k_2$라고 가정.</p><ul><li>$I$와 $K$의 Convolution 연산</li></ul><script type="math/tex; mode=display">(I*K)_{ij} = \sum_{m = 0}^{k_1 - 1} \sum_{n = 0}^{k_2 - 1}I(i - m, j - n)K(m, n)\tag{equation (1)}</script><p>위 정의를 조금 틀면 다음과 같이도 표현이 가능하다.</p><script type="math/tex; mode=display">(I*K)_{ij} = \sum_{m = 0}^{k_1 - 1} \sum_{n = 0}^{k_2 - 1}I(i + m, j + n)K(-m, -n)\tag{equation (2)}</script><p>위와 같은 연산의 형태를 Correlation이라고 한다. 즉, Convolution 연산의 Filter를 $\pi$만큼 회전시킨다면 그것이 Correlation 연산인 것이다. 이는 아주 중요한 관계이므로 꼭 기억해 두도록 하자.</p><h3 id="Definition-of-Convolutional-Neural-Network-CNN"><a href="#Definition-of-Convolutional-Neural-Network-CNN" class="headerlink" title="Definition of Convolutional Neural Network(CNN)"></a>Definition of Convolutional Neural Network(CNN)</h3><hr><p>CNN의 정의는 위의 Convolution 연산을 사용하여 Weight와 Input을 계산하는 것이다. 매우 간단한 예시로 LeNet이라는 것을 보자. 너무 자주 나오는 예시라서 하품이 나올 것 같지만, 본래 기본이라는 것은 “쉬운”것이 아니라 “중요한”것이다.</p><p align="center"><img src="https://kimh060612.github.io/img/LeNet.png" width="100%"></p><p>그림에서의 각 파트를 분해해서 살펴보면 다음과 같다.</p><blockquote><p>Image Input -&gt; (Convolution) -&gt; Feature Map -&gt; (Pooling) -&gt; Feature Map -&gt; (Convolution) -&gt; Feature Map -&gt; (Pooling) -&gt; Feature Map -&gt; (Flatten) -&gt; Feature Vector -&gt; (FCNN) -&gt; Feature Vector -&gt; (FCNN) -&gt; Feature Vector -&gt; (Gaussian Connection) -&gt; Output Vector</p></blockquote><p>여기서 괄호 안에 들어 있는 것이 연산의 이름이다. FCNN은 다른 포스트에서 봤다고 가정하고, 여기서 주목해야 할 것은 Pooling Layer이다. </p><p>Pooling은 다양한 종류가 있는데 간단하게 한가지만 소개하자면 Max Pooling이 있다. 자세한 것은 Tensorflow 2 <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D">공식 문서</a>를 참조하는 것이 더 좋을 것 같다.<br>여기서는 Pooling까지 자세히 다룰 이유는 없는 것 같다.</p><p>이제 본격적으로 Convolution 연산에 대해서 알아보도록 하겠다. 그 전에 FCNN 포스트에서도 그랬듯이, 수식 표현을 하기 위한 정의부터 하고 시작하자.</p><blockquote><p><em>Definition 1</em></p></blockquote><ul><li>$u_{ijm}^l$: $l$번째 층의 Feature Map의 $m$번째 Channel $i$행, $j$열의 성분</li><li>$x_{ijm}$: Input의 $m$번째 Channel의 $i$행, $j$열의 성분</li><li>$w_{ijmk}^l$: $l$번째 층의 Weight의 $k$번째 Kernel Set에 $m$번째 Channel, $i$행, $j$열의 성분</li><li>$b_m^l$: $l$번째 층의 $m$번째 Channel의 Bias</li></ul><p>이를 통해서 Convolution Layer를 수학적으로 표현해 보자면 다음과 같다.</p><script type="math/tex; mode=display">u_{ijm}^l = \sum^{H - 1}_{p = 0} \sum^{W - 1}_{q = 0} \sum^{K - 1}_{k = 0} z^{l - 1}_{i+sp,j+sq,k}w^l_{p,q,k,m} + b^l_m\tag{equation (3)}</script><p>여기서 $z$행렬은 $u$행렬에 activation function을 씌워 놓은 것이라고 생각하면 편하다.</p><p>이를 그림으로 표현해보면 다음과 같다. </p><p align="center"><img src="https://kimh060612.github.io/img/CNN.png" width="100%"></p><p>위 수식에서는 아직 정의되지 않은 부분, 설명되지 않은 부분이 많다. 첫번째로 $H$, $W$, $K$의 의미, 그리고 index 부분의 $s$의 의미이다. 또한, 위의 연산은 Correlation인데 왜 Convolution 연산이라고 하는 것일까? </p><p>일단 첫번째는 $H$, $W$, $K$인데, 이는 각각 Weight의 높이, 너비, 채널수이다. 그리고 index 부분의 $s$는 Stride이다. Convolution 연산의 Weight를 옮겨가면서 곱셉을 할때 얼마나 옮길지를 결정한다. 이 값을 키울수록 결과 이미지의 크기가 작아진다. 자세한 것을 하나하나 까볼려면 오래 걸리니, 이 부분은 혼자서 잘 생각해 보는게 좋을 것 같다. 어디까지나 이 문서는 입문서가 아니라는 점을 알아주었으면 좋겠다. 기존에 Tensorflow/Pytorch만을 사용하던 사람들에게 이론을 제공하고자 함이다.</p><h3 id="Back-Propagation-of-CNN"><a href="#Back-Propagation-of-CNN" class="headerlink" title="Back Propagation of CNN"></a>Back Propagation of CNN</h3><hr><p>자. 본격적으로 어려운 부분이다. 앞으로 Deep learning 강의를 써내려가면서 이보다 어려운 부분은 없다. 그리고 필자가 생각하기에도 쓸모가 없다. 단지 지적 유희를 위해서 읽어주기를 바라며 틀린 부분이 있다면 지적해 주기를 바란다. </p><p>그 전에, 왜 필자는 굳이 이 파트를 써내려 가는가를 적어보도록 하겠다. (잡담이니 굳이 안 읽어도 상관 없다.) 최근의 Deep learning 개발은 Auto Grad 계열의 알고리즘들을 활용하여 앞먹임 연산만을 정의하면 알아서 역전파 수식이 계산되어 BackPropagation을 편리하게 할 수 있다. 하지만 라이브러리에 모든 것을 맡기고 개발만 하는 것이 과연 좋은 개발자/연구원 이라고 할 수 있을까? 필요하다면 더 깊은 인사이트를 얻어서 문제를 해결해야할 필요가 있다. 이 글은 그런 사람들을 위함이기도 하고 나처럼 학문 변태들을 위한 것이기도 하다. 그러니 이 파트가 필요 없다고 판단되면 읽지 않는 것을 추천하고, 만약 틀린 것이 있다면 부디 연락해서 알려주었으면 좋겠다. 환영하는 마음으로 받아들이고 수정하도록 하겠다.</p><p>사족이 길었는데, 그래서 Back Propagation이 어떻게 정의되는 것일까? 큰 틀은 FCNN과 다를 바가 없다. Weight를 업데이트함에 있어서 Chain Rule을 활용하는 것이다. 그렇다면 어떻게 그것을 진행할 것인가?<br>우선 첫번째로 미분부터 써내려 가보자. </p><script type="math/tex; mode=display">\frac{\partial E}{\partial w^l_{ijmk}}\tag{def 2}</script><p>이것을 구해서 Weight를 업데이트하는 것이 Back Propagation의 핵심이다. 그렇다면 FCNN과 똑같이 일반화된 Delta Rule을 활용해 보는 것으로 시작하자. 이를 위해서 chain rule을 적용해 보면 다음과 같이 표현할 수 있다. </p><script type="math/tex; mode=display">\frac{\partial E}{\partial w^l_{ijmk}} = \sum_{p=0}^{H'}\sum_{q=0}^{W'} \frac{\partial E}{\partial u^l_{pqm}}\frac{\partial u^l_{pqm}}{\partial w^l_{ijmk}}\tag{equation (4)}</script><p>이때, $H’$, $W’$는 Convolution output의 결과 Feature map의 높이와 너비이다.<br>FCNN때와 똑같이 한다면 다음과 같이 Delta를 정의하고 식을 수정할 수 있다. </p><script type="math/tex; mode=display">\delta_{pqm}^l = \frac{\partial E}{\partial u^l_{pqm}}\tag{def 3}</script><p>그리고 다음과 같이 식을 유도하는 것이 가능하다. </p><script type="math/tex; mode=display">\frac{\partial E}{\partial w^l_{ijmk}} = \sum_{p=0}^{H'}\sum_{q=0}^{W'} \delta_{pqm}^l  \frac{\partial u^l_{pqm}}{\partial w^l_{ijmk}} =  \sum_{p=0}^{H'}\sum_{q=0}^{W'} \delta_{pqm}^l z^{l - 1}_{i+sp, j+sq, k}\tag{equation (5)}</script><p>결국 다음과 같이 표현 가능하다.</p><script type="math/tex; mode=display">\frac{\partial E}{\partial w^l_{ijmk}} = (\delta_{m}^l * z^{l-1}_k)_{ij}\tag{equation (6)}</script><p>이제 delta를 정의했으니, 앞층의 delta와 뒷층의 delta간의 관계를 밝혀내서 연산을 효율화 하면 된다. 이 과정을 손으로 유도하는 것은 필자가 생각해도 실용적 측면에서는 정말 쓸데가 없다. 왜냐하면 현대의 신경망 구조는 너무 복잡해져서 이걸 유도했다 쳐도 다른 구조들이 정말 많이 때문에 써먹을 수가 없기 때문이다. 하지만 아주 제한적인 경우에 대해서 이걸 유도해 보도록 하겠다. </p><ol><li>Convolution - Convolution layer 에서의 Delta 점화식</li></ol><p>우선 다시 한번 delta에서 chain rule을 적용해 보도록 하겠다 . 이 과정은 FCNN에서도 했을 것이다. 따라서 최대한 간결하게 진행해 보도록 하겠다.  </p><script type="math/tex; mode=display">\frac{\partial E}{\partial u^l_{pqm}} = \sum_{x=0}^{H''}\sum_{y=0}^{W''} \sum_{c=0}^{C''}  \frac{\partial E}{\partial u^{l + 1}_{p - sx,q - sy, c}} \frac{\partial u^{l + 1}_{p - sx,q - sy, c}}{\partial u^l_{pqm}}\tag{equation (7)}</script><p>이때 $H’’$, $W’’$, $C’’$는 다음 층에서의 Feature Map의 크기이다.</p><p>이를 전개해 보면 다음과 같다.</p><script type="math/tex; mode=display">\frac{\partial E}{\partial u^l_{pqm}} = \sum_{x=0}^{H''}\sum_{y=0}^{W''} \sum_{c=0}^{C''} \delta_{p-sx,q-sy,c}^{l+1} w^{l+1}_{xycm} f'(u^{l}_{pqm})\tag{equation (8)}</script><p>이는 다음과 같이 Convolution 연산으로 표현될 수 있다.</p><script type="math/tex; mode=display">\frac{\partial E}{\partial u^l_{pqm}} = (\delta^{l+1} * w_m^{l+1}) \odot f'(u^l_m)\tag{equation (9)}</script><p>위의 $\odot$은 성분 끼리의 곱(element wise multiplication)을 의미한다. </p><ol><li>Convolution - Pooling - Convolution 에서의 Delta 점화식</li></ol><p>위에서 delta를 유도함에 있어서 한 층이 더 추가될 뿐이다. 다음과 같이 말이다. 여기서는 Max Pooling, Average Pooling을 예로 들어보겠다. </p><script type="math/tex; mode=display">\frac{\partial E}{\partial u^l_{pqm}} = \sum_{x=0}^{H''}\sum_{y=0}^{W''} \sum_{c=0}^{C''}  \frac{\partial E}{\partial u^{l + 2}_{p' - sx,q' - sy, c}} \frac{\partial u^{l + 2}_{p' - sx,q' - sy, c}}{\partial u^{l + 1}_{p'q'm}} \frac{u^{l + 1}_{p'q'm}}{u^l_{pqm}}\tag{equation (10)}</script><script type="math/tex; mode=display">\frac{\partial E}{\partial u^l_{pqm}} = \sum_{x=0}^{H''}\sum_{y=0}^{W''} \sum_{c=0}^{C''}  \delta_{p-sx,q-sy,c}^{l+1} w^{l+1}_{xycm} \frac{\partial u^{l + 2}_{p' - sx,q' - sy, c}}{\partial u^{l + 1}_{p'q'm}} f'(u^{l}_{pqm})\tag{equation (11)}</script><p>위 식에서 중간에 있는 $l+1$층이 Pooling 층이다. 이 미분은 다음과 같이 정의된다. </p><ul><li>Max Pooling의 경우</li></ul><script type="math/tex; mode=display">\frac{\partial u^{l + 2}_{p' - sx,q' - sy, c}}{\partial u^{l + 1}_{p'q'm}} = \begin{cases}    1 \space \space \space \space \space \text{if p, q 성분이 최댓값이었을 경우} \\    0 \space \space \space \space \space \text{otherwise}\end{cases} \tag{equation (12)}</script><ul><li>Average Pooling의 경우</li></ul><script type="math/tex; mode=display">\frac{\partial u^{l + 2}_{p' - sx,q' - sy, c}}{\partial u^{l + 1}_{p'q'm}} = \frac{1}{H''' * W'''} \tag{equation (12)}</script><p>여기서 $H’’’$,$W’’’$는 Pooling Layer의 크기이다.</p><p>결국 Pooling layer까지 포함하면 다음과 같이 convolution 연산으로 정의할 수 있다.</p><script type="math/tex; mode=display">\delta_{pqm}^l = \text{Upsampling}[(\delta^{l + 2} * w^{l + 2}_m)] \odot f'(u^l_m)\tag{equation (13)}</script><p>어디까지나 이렇게 연산을 할 수 있는 이유는 Pooling layer는 업데이트를 할 필요가 없기 때문이다. 만약 업데이트를 할 피라미터가 있다면 “제대로” 다시 delta rule의 방정식을 수정해 줘야 한다.</p><ol><li>이게 정말 쓸데 없는 이유</li></ol><p>현대의 신경망은 에시당초 Convolution layer에서 탈각하는 분위기 인데다가 Convolution - Feed Forward 관계나 ResNet같은 현대의 신경망 구조에서는 이런 복잡한 수식으로 구현하는 것은 사실상 불가능에 가깝다. 그러니 우리는 Autograd를 믿고 이런건 그냥 지적 유희로만 알아 두도록 하자.</p><p>그리고 마지막으로 Bias의 Update 방법을 알아보면 다음과 같다.</p><script type="math/tex; mode=display">\frac{\partial E}{\partial b_m^l} = \sum^{H_o - 1}_{p = 0} \sum^{W_o - 1}_{q = 0} \frac{\partial E}{\partial u_{pqm}^l} \frac{\partial u_{pqm}^l}{\partial b_m^l} \tag{equation (14)}</script><p>이때, 곱셈 term의 뒷 항은 전부 1이므로 다음과 같은 식이 성립한다.</p><script type="math/tex; mode=display">\frac{\partial E}{\partial b_m^l} = \sum^{H' - 1}_{p = 0} \sum^{W' - 1}_{q = 0} \delta_{pqm}^l\tag{equation (15)}</script><p>이걸로 CNN의 이론 부분은 끝났다. 다음에는 실습 부분으로 찾아오도록 하겠다.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Deep-Learning/">Deep Learning</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="https://kimh060612.github.io/tags/Mathematics/">Mathematics</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/05/CNN-A/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Fully Connected Neural Network 강의 내용 part.B</title>
      <link>https://kimh060612.github.io/2022/03/05/FCNN-B/</link>
      <guid>https://kimh060612.github.io/2022/03/05/FCNN-B/</guid>
      <pubDate>Sat, 05 Mar 2022 08:33:29 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;&lt;em&gt;본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document를 참조하여 작성되었음을 알립니다.&lt;/em&gt;&lt;/p&gt;
&lt;h6 id=&quot;Index&quot;&gt;&lt;a href=&quot;#Ind</description>
        
      
      
      
      <content:encoded><![CDATA[<p><em>본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document를 참조하여 작성되었음을 알립니다.</em></p><h6 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h6><ol><li><del>Basic of Neural Network</del>  </li><li><del>Definition of Fully Connected Neural Network(FCNN)</del></li><li><del>Feed Forward of FCNN</del></li><li><del>Gradient Descent</del></li><li><del>Back Propagation of FCNN</del></li><li>Partice(+ 부록 Hyper parameter tuning)</li></ol><p><br></p><h4 id="6-Partice-부록-Hyper-parameter-tuning"><a href="#6-Partice-부록-Hyper-parameter-tuning" class="headerlink" title="6. Partice(+ 부록 Hyper parameter tuning)"></a>6. Partice(+ 부록 Hyper parameter tuning)</h4><hr><p>자 실습 시간이다. 왜 실습을 Part. B로 뺐느냐? FCNN이 뭐 할게 있다고?<br>뭐 할게 있겠다. Tensorflow 2가 대충 어떻게 이루어 졌는지 설명하기 위해 분량 조절을 위해서 뺀것이다.<br>무엇보다 Part. A 쓰는데 수식을 너무 많이 써서 힘들어서 분리했다. <del>Tlqkf</del><br>자, 우선 실습에 들어가기에 앞서, TF 2를 애정하는 나로써는 앞으로 이 스터디 포스트에 작성될 대부분의 소스코드를 꿰뚫는 구현 체계를 먼저 설명하고 넘어가겠다.<br>다음 사진을 보자.</p><p align="center"><img src="http://kimh060612.github.io/img/API.png" width="70%" height="70%"></p><p><em>출처: pyimagesearch blog: <a href="https://www.pyimagesearch.com/2019/10/28/3-ways-to-create-a-keras-model-with-tensorflow-2-0-sequential-functional-and-model-subclassing/">링크</a></em></p><p>위 그림에서 필자는 대부분의 코드를 <strong>Model Subclassing</strong> 방식으로 구현할 것이다. 구현 하면서 설명할 터이니 잘 따라와 주기를 바란다.<br>여기서부터는 대학교 강의 수준의 <strong>객체지향프로그래밍</strong> 지식을 갖추지 않으면 읽기 힘들 수 있다. “상속”, “오버라이딩”의 개념이라도 살펴보고 오자.</p><h6 id="6-1-Model-Subclassing"><a href="#6-1-Model-Subclassing" class="headerlink" title="6-1. Model Subclassing"></a>6-1. Model Subclassing</h6><hr><p>우선 준비한 소스부터 보고 시작하자.<br><em>file: model/FCNN1.py</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FCNN</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, _units = [<span class="number">56</span>, <span class="number">56</span>], _activation = [<span class="string">&#x27;relu&#x27;</span>, <span class="string">&#x27;relu&#x27;</span>], **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        self.Hidden1 = keras.layers.Dense(units=_units[<span class="number">0</span>], activation=_activation[<span class="number">0</span>], kernel_initializer=<span class="string">&quot;normal&quot;</span>)</span><br><span class="line">        self.Hidden2 = keras.layers.Dense(units=_units[<span class="number">1</span>], activation=_activation[<span class="number">1</span>], kernel_initializer=<span class="string">&quot;normal&quot;</span>)</span><br><span class="line">        self._output = keras.layers.Dense(units=<span class="number">10</span>, activation=<span class="string">&quot;softmax&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, Input</span>):</span><br><span class="line">        hidden1 = self.Hidden1(Input)</span><br><span class="line">        hidden2 = self.Hidden2(hidden1)</span><br><span class="line">        Output = self._output(hidden2)</span><br><span class="line">        <span class="keyword">return</span> Output</span><br></pre></td></tr></table></figure><br>자, 별거 없다. keras를 써봤다면 뭔지 바로 감이 올 것이다.<br>이 부분에 대해서는 함수에 대한 설명보다는 class에 대한 설명을 해야할 것 같다. 바로 FCNN class가 상속을 받은 부모 클래스인 keras.Model 클래스에 관해서이다.</p><p>keras.Model class는 케라스에서 Deep learning을 진행하는 모델을 정의해주는 class이다. 우리가 이미 존재하는 layer를 가져다가 특정 순서로 연산을 진행하는 graph를 만들어 내기 위한 class이다. 하지만 그렇게 어렵게 생각하지 말자. 사용하는 것을 보면 바로 답이 나온다.</p><p>여기서는 생성자와 call이라는 함수를 오버라이딩을 통해서 사용자가 재 정의를 해서 사용한다. call은 우리가 구현하고자 하는 model이 feed forward를 진행할때 호출되는 함수이다. 생성자는 사용할 폭이 넓다. 여기서는 model을 구성하는 layer를 정의하는데 사용하였는데, 꼭 그 역할만 할 필요는 없는 것이다.</p><p>가타부타 말이 많았는데, 실제 어떻게 동작을 시키는가?</p><p><em>file: train_MNIST.py</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> model.FCNN1 <span class="keyword">import</span> FCNN</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">mnist = keras.datasets.mnist</span><br><span class="line"></span><br><span class="line">(train_img, train_labels), (test_img, test_labels) = mnist.load_data()</span><br><span class="line"></span><br><span class="line">train_img, test_img = train_img.reshape([-<span class="number">1</span>, <span class="number">784</span>]), test_img.reshape([-<span class="number">1</span>, <span class="number">784</span>])</span><br><span class="line"></span><br><span class="line">train_img = train_img.astype(np.float32) / <span class="number">255.</span></span><br><span class="line">test_img = test_img.astype(np.float32) / <span class="number">255.</span></span><br><span class="line"></span><br><span class="line">model = FCNN()</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&quot;accuracy&quot;</span>])</span><br><span class="line">model.fit(train_img, train_labels, batch_size = <span class="number">32</span>, epochs = <span class="number">15</span>, verbose = <span class="number">1</span>, validation_split = <span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">model.evaluate(test_img, test_labels, verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><br>간단하다. keras.Model class를 상속 받았으니, 그곳에 있는 기본 함수들을 모두 사용할 수있다. fit method로 학습을 진행하고 evalute로 test데이터로 모델을 평가한다.<br>이는 기존에 keras의 사용법과 별반 다른게 없다.</p><p>여기까지는 쉽다. 하지만 이러고 끝낼거면 시작도 하지 않았다.</p><p>다음을 진짜 자세하게 설명할 것이다.</p><p><em>file: model/layer.py</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line"><span class="comment"># Weight Sum을 진행하는 Layer를 정의하는 예제 1</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WeightSum</span>(keras.layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, units=<span class="number">32</span>, input_dim=<span class="number">32</span>, trainable=<span class="literal">True</span>, name=<span class="literal">None</span>, dtype=<span class="literal">None</span>, dynamic=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(trainable=trainable, name=name, dtype=dtype, dynamic=dynamic, **kwargs)</span><br><span class="line">        <span class="comment"># tf.Variable을 활용하는 예시</span></span><br><span class="line">        <span class="comment"># 가중치 행렬을 초기화 하기 위한 객체</span></span><br><span class="line">        w_init = tf.random_normal_initializer()</span><br><span class="line">        <span class="comment"># 가중치 행렬을 tf.Variable로 정의함. 당연히 학습해야하니 training parameter를 true로 둠.</span></span><br><span class="line">        self.Weight = tf.Variable(</span><br><span class="line">            initial_value = w_init(shape=(input_dim, units), dtype=<span class="string">&quot;float32&quot;</span>),</span><br><span class="line">            trainable = <span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        b_init = tf.zeros_initializer()</span><br><span class="line">        <span class="comment"># 위랑 같음. 별반 다를거 X</span></span><br><span class="line">        self.Bias = tf.Variable(</span><br><span class="line">            initial_value = b_init(shape=(units, ), dtype=<span class="string">&quot;float32&quot;</span>),</span><br><span class="line">            trainable = <span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># add_weight를 활용하는 예시 - Short Cut</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        # 이는 keras.layers.Layer의 method 중에서 add_weight를 사용하는 방법임. </span></span><br><span class="line"><span class="string">        # 주로 training을 시키기 위한 행렬을 이렇게 선언해서 나중에 편하게 불러오기 위한 목적이 큼. </span></span><br><span class="line"><span class="string">        self.Weight = self.add_weight(</span></span><br><span class="line"><span class="string">            shape=(input_dim, units), initializer=&quot;random_normal&quot;, trainable=True</span></span><br><span class="line"><span class="string">        )</span></span><br><span class="line"><span class="string">        self.Bias = self.add_weight(shape=(units,), initializer=&quot;zeros&quot;, trainable=True)</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, Input</span>):</span><br><span class="line">        <span class="comment"># 행렬 곱을 위한 tf 함수임. 별거 없음</span></span><br><span class="line">        <span class="comment"># 그냥 U = WZ + B 구현한거. </span></span><br><span class="line">        <span class="keyword">return</span> tf.matmul(Input, self.Weight) + self.Bias</span><br><span class="line"></span><br><span class="line"><span class="comment"># Weight Sum을 진행하는 Layer를 정의하는 예제 2</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WeightSumBuild</span>(keras.layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, _units = <span class="number">32</span>, trainable=<span class="literal">True</span>, name=<span class="literal">None</span>, dtype=<span class="literal">None</span>, dynamic=<span class="literal">False</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(trainable=trainable, name=name, dtype=dtype, dynamic=dynamic, **kwargs)</span><br><span class="line">        self.units = _units</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build</span>(<span class="params">self, input_dim</span>):</span><br><span class="line">        <span class="comment"># 이 함수는 밑에서 자세히 설명함.</span></span><br><span class="line">        self.Weight = self.add_weight(</span><br><span class="line">            shape=(input_dim[-<span class="number">1</span>], self.units),</span><br><span class="line">            initializer = <span class="string">&quot;random_normal&quot;</span>,</span><br><span class="line">            trainable= <span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.Bias = self.add_weight(</span><br><span class="line">            shape = (self.units,),</span><br><span class="line">            initializer = <span class="string">&quot;random_normal&quot;</span>,</span><br><span class="line">            trainable = <span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, Input</span>):</span><br><span class="line">        <span class="comment"># 상기 동일.</span></span><br><span class="line">        <span class="keyword">return</span> tf.matmul(Input, self.Weight) + self.Bias</span><br></pre></td></tr></table></figure><br>위의 2개의 class는 하는 짓거리가 완벽하게 똑같다. 하지만 하는 짓거리는 같은데 아주 치명적인 부분이 조금 다르다. 바로 build 함수의 overwritting이다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#                입력 벡터/텐서의 크기를 받음</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build</span>(<span class="params">self, input_dim</span>):</span><br><span class="line">    <span class="comment"># 그에 따라서 Weight와 Bias의 차원을 결정함.</span></span><br><span class="line">    <span class="comment"># 물론, Bias는 차이가 없을 지언정, Weight는 크게 차이가 나게 된다.</span></span><br><span class="line">    self.Weight = self.add_weight(</span><br><span class="line">        shape=(input_dim[-<span class="number">1</span>], self.units),</span><br><span class="line">        initializer = <span class="string">&quot;random_normal&quot;</span>,</span><br><span class="line">        trainable= <span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    self.Bias = self.add_weight(</span><br><span class="line">        shape = (self.units,),</span><br><span class="line">        initializer = <span class="string">&quot;random_normal&quot;</span>,</span><br><span class="line">        trainable = <span class="literal">True</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p>이 함수는 call이 호출되기 전에 무조건 실행되는 함수라고 생각하면 된다. 즉, 호출하기 전에 Weight를 정의하는 것이다. 즉, 입력 벡터의 크기에 따라 모델의 형태가 알아서 바꾸게 해줄 수 있는 것이다. 이는 Image를 처리할때 이점이 될 수 있다.<br>Image를 학습시킬때, 이러한 처리가 없으면 이미지를 전부 동일한 크기로 만들어 주어야 한다. 하지만 build 함수를 정의해서 그때 그때 입력 벡터/텐서에 따라 커널을 수정해 주면 굳이 그럴 필요가 없다. 전처리 비용이 줄어드는 것이다. </p><p>그리고, 이제 이를 학습시키기 위한 코드를 보도록 하자.</p><p><em>file: train_MNIST_2.py</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> model.FCNN2 <span class="keyword">import</span> FCNN</span><br><span class="line"></span><br><span class="line">EPOCHS = <span class="number">15</span></span><br><span class="line">LR = <span class="number">0.01</span></span><br><span class="line">BatchSize = <span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 이미지 불러오기</span></span><br><span class="line">mnist = keras.datasets.mnist</span><br><span class="line">(train_img, train_labels), (test_img, test_labels) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 필요한 전처리</span></span><br><span class="line">train_img, test_img = train_img.reshape([-<span class="number">1</span>, <span class="number">784</span>]), test_img.reshape([-<span class="number">1</span>, <span class="number">784</span>])</span><br><span class="line">train_img = train_img.astype(np.float32) / <span class="number">255.</span></span><br><span class="line">test_img = test_img.astype(np.float32) / <span class="number">255.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Train-Validation Split</span></span><br><span class="line">validation_img = train_img[-<span class="number">18000</span>:]</span><br><span class="line">validation_label = train_labels[-<span class="number">18000</span>:]</span><br><span class="line">train_img = train_img[:-<span class="number">18000</span>]</span><br><span class="line">train_labels = train_labels[:-<span class="number">18000</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train Data의 규합. &amp; Batch 별로 쪼갬</span></span><br><span class="line">train_dataset = tf.data.Dataset.from_tensor_slices((train_img, train_labels))</span><br><span class="line">train_dataset = train_dataset.shuffle(buffer_size=<span class="number">1024</span>).batch(BatchSize)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Validation Data의 규합 &amp; Batch 별로 쪼갬</span></span><br><span class="line">validation_dataset = tf.data.Dataset.from_tensor_slices((validation_img, validation_label))</span><br><span class="line">validation_dataset = validation_dataset.batch(BatchSize)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optimizer &amp; Loss Function 정의</span></span><br><span class="line">optimizer = keras.optimizers.Adam(learning_rate=LR)</span><br><span class="line">loss_function = keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 학습이 잘 되고 있나 확인하기 위한 지표를 확인하기 위함.</span></span><br><span class="line">train_accuracy = keras.metrics.SparseCategoricalAccuracy()</span><br><span class="line">val_acc_metric = keras.metrics.SparseCategoricalAccuracy()</span><br><span class="line"></span><br><span class="line">model = FCNN()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Custom Training을 위한 반복문</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Epoch %d start&quot;</span>%epoch)</span><br><span class="line">    <span class="keyword">for</span> step, (x_batch, y_batch) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataset):</span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            <span class="comment"># Model의 Feed Forward</span></span><br><span class="line">            logits = model(x_batch, training=<span class="literal">True</span>)</span><br><span class="line">            <span class="comment"># Feed Forward 결과를 바탕으로 Loss를 구함</span></span><br><span class="line">            loss_val = loss_function(y_batch, logits)</span><br><span class="line">        <span class="comment"># 위의 과정을 바탕으로 gradient를 구함</span></span><br><span class="line">        grad = tape.gradient(loss_val, model.trainable_weights)</span><br><span class="line">        <span class="comment"># Optimizer를 통해서 Training Variables를 업데이트</span></span><br><span class="line">        optimizer.apply_gradients(<span class="built_in">zip</span>(grad, model.trainable_weights))</span><br><span class="line">        <span class="comment"># Batch 별로 Training dataset에 대한 정확도를 구함.</span></span><br><span class="line">        train_accuracy.update_state(y_batch, logits)</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">0</span> :</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Training loss at step %d: %.4f&quot;</span>%(step, loss_val))</span><br><span class="line">    <span class="comment"># 정확도를 규합해서 출력</span></span><br><span class="line">    train_acc = train_accuracy.result()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Training acc over epoch: %.4f&quot;</span> % (<span class="built_in">float</span>(train_acc),))</span><br><span class="line">    train_accuracy.reset_states()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Validation을 진행함.</span></span><br><span class="line">    <span class="keyword">for</span> x_batch_val, y_batch_val <span class="keyword">in</span> validation_dataset:</span><br><span class="line">        <span class="comment"># Validation을 위한 Feed Forward</span></span><br><span class="line">        val_logits = model(x_batch_val, training = <span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># Batch 별로 Validation dataset에 대한 정확도를 구함</span></span><br><span class="line">        val_acc_metric.update_state(y_batch_val, val_logits)</span><br><span class="line">    <span class="comment"># 구한 정확도를 규합하여 출력함.</span></span><br><span class="line">    val_acc = val_acc_metric.result()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Validation acc: %.4f&quot;</span> % (<span class="built_in">float</span>(val_acc),))</span><br><span class="line">    val_acc_metric.reset_states()</span><br></pre></td></tr></table></figure><br>이는 TF2에서 추가된 tf.GradientTape를 통해서 사용자 정의 학습 루프를 만든 것이다. 각 줄마다 주석을 달아 놓았으니 Part. A의 내용을 숙지했다면 그렇게 어렵지 않게 알아들을 수 있을 것이다. </p><p>이제, 한가지 의문이 든다. 그렇다면 위의 Hyper parameter들을 변화시켜가면서 model을 최적화 하려면 노가다 밖에 답이없는건가? 답은 아니다. 이번에는 맛보기만 보여줄 것이다. 이는 scikit learn의 RandomizedSearchCV를 통해서 확인할 수 있다.</p><p><em>file: RandomSearch.py</em><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> reciprocal</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> RandomizedSearchCV</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">mnist = keras.datasets.mnist</span><br><span class="line">(train_img, train_labels), (test_img, test_labels) = mnist.load_data()</span><br><span class="line">train_img, test_img = train_img.reshape([-<span class="number">1</span>, <span class="number">784</span>]), test_img.reshape([-<span class="number">1</span>, <span class="number">784</span>])</span><br><span class="line">train_img = train_img.astype(np.float32) / <span class="number">255.</span></span><br><span class="line">test_img = test_img.astype(np.float32) / <span class="number">255.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 여기 parameter들의 Key는 무적권 입력 함수의 parameter와 같아야 한다. 아마도 **kwargs로 한번에 보내버리는 것일거다.</span></span><br><span class="line">param_distribution = &#123;</span><br><span class="line">    <span class="string">&quot;n_hidden&quot;</span>: [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">    <span class="string">&quot;n_neurons&quot;</span>: np.arange(<span class="number">1</span>,<span class="number">100</span>),</span><br><span class="line">    <span class="string">&quot;lr&quot;</span>: reciprocal(<span class="number">3e-4</span>, <span class="number">3e-2</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이것을 사용하기 위해서는 모델을 만들어줄 함수가 하나 필요하다.</span></span><br><span class="line"><span class="comment"># 여기서는 그냥 Sequential API를 사용하였다. 생각하기 귀찮았다. ㅋ;; </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Build_model</span>(<span class="params">n_hidden = <span class="number">1</span>, n_neurons=<span class="number">30</span>, lr = <span class="number">3e-3</span>, input_shape=[<span class="number">784</span>]</span>):</span><br><span class="line">    model = keras.models.Sequential()</span><br><span class="line">    model.add(keras.layers.InputLayer(input_shape=input_shape))</span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> <span class="built_in">range</span>(n_hidden):</span><br><span class="line">        model.add(keras.layers.Dense(n_neurons, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(keras.layers.Dense(units=<span class="number">10</span>, activation=<span class="string">&quot;softmax&quot;</span>))</span><br><span class="line">    optimizer = keras.optimizers.SGD(learning_rate=lr)</span><br><span class="line">    model.<span class="built_in">compile</span>(optimizer=optimizer, loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&quot;accuracy&quot;</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이는 keras 모델을 scikit learn에서 관리하기 위해 호출하는 함수이다.</span></span><br><span class="line">keras_classify = keras.wrappers.scikit_learn.KerasClassifier(Build_model)</span><br><span class="line"><span class="comment"># 여기서부터 본론이다. parameter_distribution으로 주어진 집합 한에서 가장 좋은 성능의 모델을 탐색한다.</span></span><br><span class="line"><span class="comment"># 여기서는 Cross-Validation을 사용한다. cv 항은 몇개로 Validation-training set을 분리할지 정하는 것이다. </span></span><br><span class="line">rnd_search_model = RandomizedSearchCV(keras_classify, param_distributions=param_distribution, n_iter = <span class="number">10</span>, cv = <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 이제 주어진 데이터를 가지고 학습을 돌면서 최적의 모델을 탐색한다. </span></span><br><span class="line">rnd_search_model.fit(train_img, train_labels, epochs=<span class="number">10</span>, validation_data=(test_img,test_labels), callbacks=[keras.callbacks.EarlyStopping(patience=<span class="number">10</span>)])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(rnd_search_model.best_params_)</span><br></pre></td></tr></table></figure></p><p>오늘은 이것으로 끝내도록 하자.<br>다음 포스트는 Convolutional Neural Network를 오늘처럼 다뤄볼 예정이다.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Deep-Learning/">Deep Learning</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="https://kimh060612.github.io/tags/Tensorflow2/">Tensorflow2</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/05/FCNN-B/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Fully Connected Neural Network 강의 내용 part.A</title>
      <link>https://kimh060612.github.io/2022/03/05/FCNN-A/</link>
      <guid>https://kimh060612.github.io/2022/03/05/FCNN-A/</guid>
      <pubDate>Sat, 05 Mar 2022 08:32:02 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;&lt;em&gt;본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document를 참조하여 작성되었음을 알립니다.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;Index&quot;&gt;&lt;a href=&quot;#Ind</description>
        
      
      
      
      <content:encoded><![CDATA[<p><em>본 포스트는 Hands-on Machine learning 2nd Edition, CS231n, Tensorflow 공식 document를 참조하여 작성되었음을 알립니다.</em></p><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><ol><li>Basic of Neural Network  </li><li>Definition of Fully Connected Neural Network(FCNN)</li><li>Feed Forward of FCNN</li><li>Gradient Descent</li><li>Back Propagation of FCNN</li><li>Hyper parameter tuning</li><li>Partice</li></ol><p>여기서는 1~5는 Part. A이고 6,7은 Part. B에서 다루도록 하겠다.<br><br></p><h3 id="Basic-of-Neural-Network"><a href="#Basic-of-Neural-Network" class="headerlink" title="Basic of Neural Network"></a>Basic of Neural Network</h3><hr><p>Neural Network의 기본을 설명할때 항상 나오는 것이 바로 뉴런 구조 사진이다. 여기서는 그들을 생략하도록 하겠다. 굳이 여기서 설명할 필요를 못 느끼겠다.<br>궁금하면 SLP(Single Layer Perceptron)와 MLP(Multi Layer Perceptron)에 대해서 구글링을 해보도록 하자.</p><p>우선 FCNN을 본격적으로 들어가기 전에, 지도 학습에 대한 Deep learning의 학습 프로세스에 대한 개략적인 모식도를 보고 가자.</p><p align="center"><img src="https://kimh060612.github.io/img/DeepProcess_1.png" width="100%"></p><p>이러한 모식도에 개략적인 생략이 들어 갔고, 반례도 충분히 있겠지만, 지도 학습의 형태로 학습하는 대부분의 Neural Network는 이런 Process로 학습을 하게 된다.<br>앞으로 나오는 신경망 구조들 중에서 위의 “출력”, “평가”, “학습”의 3가지의 과정을 집중적으로 기술할 생각이다. </p><p>그렇다면 Neural Network 구조를 활용해서 풀 수 있는 문제는 무엇이 있을까?<br>여기서는 크게 2가지만 다룰 예정이다. </p><ol><li><em>Classification</em>: 어떤 입력을 특정 범주로 분류해내는 문제. </li><li><em>Regression</em>: 어떤 변수들 사이의 관계를 도출해내는 문제. (Modeling에 가깝다고 생각하면 편함.)</li></ol><p>이러한 2개의 문제의 범주를 설명하고 넘어가는 이유는 Neural Network로 어떤 문제를 풀 것이냐에 따라서 학습 과정에서 다양한 부분이 상이하게 변하기 때문이다. 이는 나중에 따로 자세하게 다룰 예정이다. 지금은 일단 이런 것이 있다 라는 것만 알아두고 가자.</p><p><br></p><h3 id="Definition-of-FCNN"><a href="#Definition-of-FCNN" class="headerlink" title="Definition of FCNN"></a>Definition of FCNN</h3><hr><p>여기서는 Fully Connected Nueral Network의 정의를 먼저 알아보도록 하겠다. 간단하게 이를 표현하자면 다음과 같은 구조를 가지는 Neural Network를 일컫는다.</p><p align="center"><img src="https://kimh060612.github.io/img/FCNN.png" width="100%"></p><p><em>Figure 1: FCNN의 모식도 1</em><br>이렇게 앞층의 뉴런과 뒷층의 뉴런이 빠짐없이 전부 연결된 구조를 FCNN이라고 한다. 여기서 만약 독자가 MLP를 모르는 상태라면 위의 구조가 상당히 추상적으로 다가올 것이다. 간단하게 생각해서, 각 뉴런들은 숫자를 가지고 있다고 생각하면 된다. 다음 그림을 보면 훨씬 쉽게 이해할 수 있다.</p><p align="center"><img src="https://kimh060612.github.io/img/FCNN2.png" width="100%"></p><p><em>Figure 2: FCNN의 모식도 2</em></p><p>이렇게 층의 뉴런마다 간선으로 연결되어 있고 각 뉴런들은 뒤의 뉴런들에게 어떠한 가중치를 반영해서 자신의 값을 가지고 있다고 생각하면 된다. 이제부터 우리는 이러한 구조를 가진 Neural Network가 어떻게 주어진 문제에 대해서 결과를 도출하고 학습을 진행하는지 알아보도록 하겠다. </p><p><br></p><h3 id="Feed-Forward-of-FCNN"><a href="#Feed-Forward-of-FCNN" class="headerlink" title="Feed Forward of FCNN"></a>Feed Forward of FCNN</h3><hr><p>이 과정은 학습이 되었건 되지 않았건 FCNN의 구조에서 입력을 통해 출력을 얻어내는 과정이다. 층층이 쌓인 Neural Network 구조에서 앞으로 계속 나아가면서 결과를 도출해 내는 모습에서 Feed Forward(앞 먹임)이라는 이름이 붙은 것이다.<br>앞으로 대부분의 예시는 <em>Figure 2</em>와 비슷한 형식으로 나올 것이다. 그리고 앞으로는 <em>뉴런</em>이라는 명칭보다는 <em>Unit</em>이라는 명칭을 사용할 것이다.<br>이제, 이전 슬라이드에 있는 것들을 기호를 명확하게 정의해 보도록 하겠다.</p><blockquote><p><em>Definition 1</em></p></blockquote><ul><li>$x_i$: 입력 벡터의 $i$번째 원소</li><li>$u_i^k$: $k$번째 Layer의 $i$번째 Hidden Units의 값.</li><li>$w^k_{ij}$: $k$번째 층의 $i$번째 Unit과 $k-1$번째 층의 $j$번째 Unit을 이어주는 가중치</li><li>$y_i$: 출력층의 $i$번째 Unit</li><li>$n_k$: $k$번째 층의 Unit의 갯수</li></ul><p>그렇다면 이제 Feed Forward를 위해서 가장 중요한 부분을 설명하도록 하겠다. Weighted Sum(가중합)에 대한 부분이다.<br>앞선 <em>Figure 1</em>과 <em>Figure 2</em>에서 앞층과 뒷층의 관계를 우리는 다음과 같이 정의한 것이다.</p><script type="math/tex; mode=display">u_i^k = \sum_{j=1}^{n^{k-1}}w^k_{ij}u^{k-1}_j\tag{Equation (2)}</script><p>정말 단순하게 생각해서 이전 유닛에 해당하는 가중치만큼 앞의 유닛에 반영해 주면 되는 것이다. 이렇게 뒤의 층에서 앞의 층으로 순차적으로 계산해 나가면 된다.</p><p>하지만 여기에는 치명적인 문제점이 있다. 바로, 이렇게 된다면 Neural Network 구조로 Linear Function 밖에 표현할 수 없다는 것이다.<br>위의  $equation (1)$의 형식으로 Feed Foward를 진행하게 된다면 층을 쌓는 것이 의미가 없어진다. 그 이유는 단순히 일변수 선형 함수를 생각해보면 알 수 있다.<br>우리가 $y = a_ix$라는 임의의 $N$개의 함수들을 층층이 쌓는다 할저언정 그것은 새로운 선형 함수 $y = a’x, \quad a’ = a_1a_2a_3\cdot\cdot\cdot a_N$ 를 만들어 내는 것과 별반 다를 것이 없다. 이렇게 되면 가장 대표적인 문제점은 바로 XOR문제를 해결할 수 없다는 것이다. 이는 너무 보편적인 문제라서 그냥 구글링 하면 나보다 설명 잘해놓은 글이 널려있다. 따라서 여기서는 생략한다.<br>똑같은 논리이다. 이에 대한 자세한 논의는 Appendix. A에 자세히 기술하도록 하겠다.</p><p>이러한 문제를 해결하고 더 다양한 함수를 신경망이 표현할 수 있게 하기 위해서 Activation function과 Bias를 적용하게 된다.</p><blockquote><p>Activation Function(활성 함수)</p></blockquote><p>신경망이 Linear한 함수만을 근사시키는 것을 방지하기 위해서 중간에 Non Linear Function을 Unit에 적용하게 된다. 이때 이러한 함수를 Non linear function이라고 한다. 그렇다고, 전부 Non linear인 것은 아니다. 하지만 Non linear function이여야 앞선 문제가 발생하지 않을 것이다. 그 종류는 대략 다음과 같다.</p><ol><li>Sigmoid: $\sigma(x) = \frac{1}{1+\exp(-x)}$</li><li>ReLU(Rectified Linear Unit): $max(0, x)$</li><li>Leaky ReLU: $max(0.1x, x)$</li><li>Hyperbolic tangent: $\tanh(x) = \frac{\exp(x) - \exp(-x)}{\exp(x) + \exp(-x)}$</li><li>ELU(Exponential Linear Unit): $\sigma(x) = xu(x) + a(\exp(x)-1)u(-x)$</li></ol><p>이것 뿐만 아니라 진짜 개 많다. 나머지는 Tensorflow 공식 Document나 구글링을 통해서 알아보도록 하라. </p><p>이렇게 Activation Function을 씌운 값을 앞으로는 다음과 같이 표현하도록 하겠다.</p><blockquote><p><em>Defintion 2</em>: 활성함수를 적용한 Unit의 값.</p></blockquote><script type="math/tex; mode=display">z_i^k = f(u^k_i)</script><blockquote><p>Bias (편향)</p></blockquote><p>Bias로써는 Non Linear성을 신경망에 추가할 수는 없다. 하지만 Activation Function을 평행 이동 시켜주는 역할을 하게 해서 입력이 0인 지점에서의 신경망의 자율도를 높여주게 된다. 예를 들어보자. 위에 예시를 든 Activation function들에서는 예를 들어서 $(0, 32)$같은 점을 표현할 수 없다. 그렇기 때문에 Bias를 주어서 평행 이동을 시켜주는 것이다. 이것의 유무가 신경망의 학습 양상과 성능이 크게 차이를 주는 경우가 많다. </p><p>즉, 최대한 많은 함수를 근사할 수 있도록 위와 같은 설정을 추가해 주는 것이다.<br>이러면 어떤 잼민이는 이런 질문을 할 수 있을 것이다.</p><blockquote><p>???: 아 ㅋㅋㅋㅋ 그런 근사 못 하는 함수는 어쩔건데요 ㅋㅋ루삥뽕</p></blockquote><p>걱정 마라. 이미 <em>만능 근사 정리</em>(<em>Universal Approximation Theorem</em>, <em>시벤코 정리</em>)에 의해서 증명되었다. 그냥 안심하고 쓰면 된다.</p><p>그렇다면 Bias를 적용해서 다시금 Unit의 값을 작성해 보자.</p><blockquote><p><em>Definition 3</em>: Bias를 적용한 Unit의 값  </p></blockquote><script type="math/tex; mode=display">u_i^k = \sum_{j=1}^{n_{k-1}}w^k_{ij}z^{k-1}_j + b^k_i\tag{Equation (2)}</script><p><br></p><p align="center"><img src="https://kimh060612.github.io/img/FCNN3.png" width="100%"></p><p><em>Figure 3: Bias를 반영한 Neural Network의 표현</em></p><p>이제 이를 행렬로 표현해보자. 행렬로써 표현하여 식을 짧고 간편하게 정리할 수 있으며, 컴퓨터에서의 구현을 다소 직관적이고 편하게 할 수 있다.</p><script type="math/tex; mode=display">U^k = \begin{bmatrix}    u^k_1 && u^k_2 && \dots && u^k_{n_k}\end{bmatrix} ^T\tag{Def. 4}</script><p><br></p><script type="math/tex; mode=display">W^k = \begin{bmatrix}    w^k_{11} && w^k_{12} && \cdots && w^k_{1n_{k-1}} \\    w^k_{21} && w^k_{22} && \cdots && w^k_{2n_{k-1}} \\    \vdots && \ddots && \ddots && \vdots \\    w^k_{n_k1} && w^k_{n_k2} && \cdots && w^k_{n_kn_{k-1}} \\\end{bmatrix}\tag{Def. 5}</script><p><br></p><script type="math/tex; mode=display">Z^{k-1} = \begin{bmatrix}    z^{k-1}_1 && z^{k-1}_2 && \dots && z^{k-1}_{n_{k-1}}\end{bmatrix}^T\tag{Def. 6}</script><p><br></p><script type="math/tex; mode=display">B^k = \begin{bmatrix}    b^k_1 && b^k_2 && \dots && b^k_{n_k}\end{bmatrix}^T\tag{Def. 7}</script><p><br></p><script type="math/tex; mode=display">\therefore U^k = W^kZ^{k-1} + B^k\quad(Z^k = f(U^k), \quad where \space f: \mathbb{R}^{n^k} \to \mathbb{R}^{n^k})</script><p><br></p><h3 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h3><hr><p>이번 장에서는 Gradient Descent에 대해서 다룰 예정이다. 하지만 너무 깊게는 안 다룰 생각이다. 그렇다고 걱정할 필요는 없다. 나중에 존나 자세하게 다룰거니깐 걱정은 붙들어 매도록 하자. </p><p align="center"><img src="https://kimh060612.github.io/img/GradientDescent.gif" width="100%"></p><p><em>Figure 4. Gradient Descent을 묘사하는 Figure</em><br>Gradient Descent는 간단하게 설명해서 Gradient를 활용해서 Objective Function(목적 함수)의 최저점을 찾는 것이 목표이다. 위의 사진처럼 말이다. 이의 명확한 표현을 직관적으로 납득시키기 위해서 다음의 사진을 보자.</p><p align="center"><img src="https://kimh060612.github.io/img/GD.jpg" width="70%"></p><p><em>Figure 5. Gradient Descent를 직관적으로 설명하기 위한 그림</em></p><p>이처럼 목적 함수의 미분값을 활용하여 목적 함수의 최저점을 찾는 것이 가능하다. 이에 대한 자세한 설명은 진짜 나중에 질리도록 해주도록 하겠다. 걱정하지 말아달라.</p><p>그렇다면 이제 Neural Network에서 목적 함수는 어떤 것을 사용하는지 알아봐야한다. 이것도 지금은 그냥 “그런 것이 있다”라고만 생각하자. 이 파트는 신경망을 이해하는데 있어서 중요하고 심도있는 내용이기 때문에 나중에 Post 하나를 통으로 열어서 집중적으로 설명할 것이다.</p><p>이번 포스트에서는 목적함수로써 주로 2가지를 다룰 것이다.</p><ol><li>Mean Squared Error</li></ol><script type="math/tex; mode=display">E = \frac{1}{2N}\sum_i(y_i - t_i)^2\tag{Equation (3)}</script><ol><li>Cross-Entropy</li></ol><script type="math/tex; mode=display">E = -\sum_c t_c\ln y_c\tag{Equation (4)}</script><p>$Equation 3$은 주로 regression 문제에서 목적 함수로 쓰이고, $Equation 4$는 주로 classification 문제에서 쓰인다.<br>이렇게 Error function이 있는데 Update를 어떻게 한다고 하는 것일까? 다음과 같은 공식으로 Update 하면 된다</p><script type="math/tex; mode=display">w_{t+1} \gets w_t - \alpha \frac{\partial E}{\partial w_t}\quad\alpha: learning \space rate\tag{Equation (5)}</script><p>직관적으로 생각해보면, 그래프의 미분값이 음수이면 아래로 볼록한 이차 함수에서 극소점이 오른쪽에 있다는 것이다. 그렇다면 변수에 양수를 더해줘야 극소점에 다가갈 것이다. 반대도 마찬가지이다. 그리고 한번 Update를 할때 너무 변화폭을 급하게 하지 않기 위해서 learning rate를 곱해줘서 update를 해준다. 그렇게 적절한 learning rate를 지정하여 몇번 반복해주면 최저점에 수렴해 있을 것이다.</p><p>집요하지만, 이번 주제에 관한 내용은 나중에 “Optimization, Error function, and Problem”에 관한 포스트에서 자세하게 다룰 것이다. 그러니 지금은 직관적으로만 학습의 Process를 이해하는데 사력을 다해주기를 바란다.</p><h3 id="Back-propagation-of-FCNN"><a href="#Back-propagation-of-FCNN" class="headerlink" title="Back-propagation of FCNN"></a>Back-propagation of FCNN</h3><hr><p>이번에는 어떻게 신경망에 Gradient Descent를 적용할 것인지에 대한 내용이다. 위의 Gradient Descent를 배운 사람이라면 <script type="math/tex">Equation 5</script>를 활용하여 가중치의 Update를 다음과 같이 해줘야 할 것이라는데 이견을 가지지는 않을 것이다.</p><script type="math/tex; mode=display">w^m_{ij} \gets w^m_{ij} - \alpha \frac{\partial E}{\partial w^m_{ij}}\tag{Equation (6)}\quad, m \in [1, K] \cap \N</script><p>여기서 $K$는 층의 갯수이다. </p><p>이때 수치해석을 공부한 사람이라면, 다음과 같은 말을 할 수 있다.</p><blockquote><p>적당한 $\epsilon$을 선택하고, 수치 미분을 해주면 되지 않을까?</p></blockquote><p>뭐, 틀린 말은 아니다. 실제로도 좋은 방법이 될 수 있다.(<em>신경망이 아니라면 말이지</em>) 하지만 이건 Neural Network이다. 미친 연산량을 자랑하는 이쪽 바닥에서 안이하게 접근했다가는 피를 볼 수 있다.<br>요즘은 많은 알고리즘들이 발달해서 어떨지는 모르지만, 기본적인 수치 미분은 여기서 좋은 방법이 아니다. 우선 수치 미분을 진행하는 방법은 다음과 같다.</p><script type="math/tex; mode=display">    \frac{df}{dx} \approx \frac{f(x+\epsilon) - f(x)}{\epsilon}</script><p>우선 이걸 신경망에 적용시키기 위해 가장 먼저 떠오르는 방법은 다음과 같을 것이다.</p><ol><li>$f(x+\epsilon)$를 계산한다.</li><li>$f(x)$를 계산한다.</li><li>미분을 계산한다.</li></ol><p>자, 1,2번의 과정을 신경망에 적용해 주려면 당신은 2번의 함수 값을 계산해 줘야한다. 만약, 계산량이 크지 않은 함수라면 빨리 되겠지만, 이건 신경망이다. <em>Figure 3</em>을 보자. 저기 그려져 있는 모든 간선에 대해서 Update를 해줘야하는데 진짜 어림도 없는 방법이 아닐 수 없다. 이걸 parameter마다 해준다? 진짜 어림도 없는 소리가 된다.</p><p>그렇다면 다음으로 패기 넘치는 잼민이가 다음과 같이 말한다.</p><blockquote><p>그냥 간단한 함수만 쓰고 손으로 계산하면 안됨? 그것도 못하누 ㅋㅋ루삥뽕</p></blockquote><p>^^ 열심히 해보십셔 잼민님^^(<em>말도 안되는 소리는 집어 치우자</em>)</p><p>여기서 tensorflow의 자동 미분(Autograd)가 나오는데, 우리는 이 전에 수학적인 부분으로 이를 접근해 보도록하자.</p><p>가장 먼저, 이는 엄청나게 곂곂이 쌓인 함수이다. 일변수 Scalar 함수로 예시를 들어보면 다음과 비슷한 것이라고 생각할 수 있다.</p><script type="math/tex; mode=display">y = f(f(f( \cdots f(x) \cdots)))</script><p>이를 미분해야한다고 생각해보자. Calculus를 배웠다면 가장 먼저 떠오르는 것은 Chain Rule 일 것이다.</p><p>하지만, 어디서부터 어떻게 Chain Rule을 적용해야하는지 막막하다. 그 전에 우선 <strong>상대적으로 구히기 쉬울 것 같은</strong> 출력층 바로 이전의 가중치의 미분을 Chaine Rule을 통해서 구해보자.</p><script type="math/tex; mode=display">\frac{\partial E}{\partial w^K_{ij}} = \frac{\partial E}{\partial y_i}\frac{\partial y_i}{\partial u^K_i}\frac{\partial u^K_i}{\partial w^K_{ij}}\tag{Equation (6)}</script><p>이는 출력층 바로 이전의 층의 가중치이기에, Chain Rule을 통해서 <strong>비교적 쉽게</strong> 구할 수 있다. 다음과 같이 말이다.<br>(Error function(목적 함수)는 MSE를 사용하였다고 생각하자.)</p><script type="math/tex; mode=display">\frac{\partial E}{\partial y_i} = \frac{1}{N}(y_i - t_i)\quad  \frac{\partial y_i}{\partial u^K_i} = f'(u^K_i)\quad\frac{\partial u^K_i}{\partial w^K_{ij}} = z^{K-1}_j\tag{Equation (7)}</script><script type="math/tex; mode=display">\therefore \frac{\partial E}{\partial w^K_{ij}} = \frac{1}{N}(y_i - t_i)f'(u^K_i)z^{K-1}_j\tag{Equation (8)}</script><p>이렇게 성공적으로 $W^K$의 미분은 구했다고 치고, 어떻게 그 뒤의 층을 구할 것인가?<br>우선, 다음 그림을 보자.</p><p align="center"><img src="https://kimh060612.github.io/img/Layer.png" width="70%"></p><p><em>Figure 7. Neural Network 구조에서 일부를 떼어서 표현한 그림</em><br>이는 Neural Network 구조에서 일부를 떼어낸 것을 표현한 그림이다. 위의 $\vdots$가 그려진 Unit은 그냥 거기에 많은 수의 Unit들이 있다고 생각하면 될 것이다.<br>우리는 여기서 $W^k$의 $E$에 대한 미분을 구하는 것이 목표이다.<br>즉, $Equation (9)$를 구하는 것이 목표이다.</p><script type="math/tex; mode=display">\frac{\partial E}{\partial w^k_{ip}} \space = \space ?</script><p>그것을 위해서 우선, Chaine Rule을 진행해 보자.</p><script type="math/tex; mode=display">\frac{\partial E}{\partial w^k_{ip}} = \frac{\partial E}{\partial u^k_i}\frac{\partial u^k_i}{\partial w^k_{ip}}\tag{Equation (9)}</script><p>여기까지만 봐서는 잘 모르겠다. 하지만 다음의 그림을 보고, $\frac{\partial E}{\partial u^k_i}$ 에 한번 더 Chain Rule을 적용해 보자.</p><p align="center"><img src="https://kimh060612.github.io/img/Layer2.png" width="70%"></p><p><em>Figure 6. $u^k_i$가 영향을 주는 앞 층의 Unit들</em><br>FCNN의 정의에 의해, $u^k_i$는 앞층의 모든 뉴런에 연결되어 있다. 그리고 그 앞 층의 뉴런들은 또 그 다음층으로 값을 전달하며, 점점 출력층에 가까워 지고, Error에 영향을 미치게 된다. 한마디로, 다음과 같이 Chain Rule을 펼칠 수 있다.</p><script type="math/tex; mode=display">\frac{\partial E}{\partial u^k_i} = \sum_{j=1}^{n_{k+1}} \frac{\partial E}{\partial u^{k+1}_j}\frac{\partial u^{k+1}_j}{\partial u^k_i}\tag{Equation (10)}</script><p>이때 우리는 위의 $Equation (10)$에서 유사한 부분을 찾을 수 있다.</p><script type="math/tex; mode=display">\frac{\partial E}{\partial u^k_i} \quad and \quad \frac{\partial E}{\partial u^{k+1}_j}</script><p>그렇다면 우리는 다음과 같이 정의를 해보자.</p><script type="math/tex; mode=display">\delta^k_i = \frac{\partial E}{\partial u^k_i}\tag{Def. 8}</script><p>그렇다면 $Equation (10)$을 다음과 같이 작성할 수 있다.</p><script type="math/tex; mode=display">\delta^k_i = \sum_{j=1}^{n_{k+1}} \delta^{k+1}_j\frac{\partial u^{k+1}_j}{\partial u^k_i}\tag{Equation (11)}</script><p><strong>이 점화식이 이번 포스트의 핵심이다.</strong><br>그렇다면 식을 다시 정리해서, 최종적인 미분 값을 구해보자.</p><script type="math/tex; mode=display">\frac{\partial u^{k+1}_j}{\partial u^k_i} = \frac{\partial u^{k+1}_j}{\partial z^k_i}\frac{\partial z^{k}_i}{\partial u^k_i} = w^{k+1}_{ji}f'(u^k_i)\tag{Equation (12)}</script><p>그리고, $Equation (12)$를 통해서 $Equation (10)$을 다시 써보면 다음과 같다.</p><script type="math/tex; mode=display">\delta^k_i = \sum_{j=1}^{n_{k+1}} \delta^{k+1}_jw^{k+1}_{ji}f'(u^k_i)\tag{Equation (13)}</script><p>자! 다 왔다. 이제 최종 미분식을 다시 써보자.</p><script type="math/tex; mode=display">\frac{\partial E}{\partial w^k_{ip}} = \delta^k_i\frac{\partial u^k_i}{\partial w^k_{ip}} = \left(\sum_{j=1}^{n_{k+1}} \delta^{k+1}_jw^{k+1}_{ji}f'(u^k_i)\right )\frac{\partial u^k_i}{\partial w^k_{ip}}</script><script type="math/tex; mode=display">\therefore \frac{\partial E}{\partial w^k_{ip}} = \left(\sum_{j=1}^{n_{k+1}} \delta^{k+1}_jw^{k+1}_{ji}f'(u^k_i)\right )z^{k-1}_p\tag{Equation (14)}</script><p>이 포스트의 핵심은 이것이다.<br>결국 우리는 <strong>상대적으로 구하기 쉬운 출력층의 미분을 구하는 과정에서 미분을 구하기 어려운 층의 미분을 구할 수 있는 실마리를 얻은 것이다.</strong><br>무슨 말이냐? 우리는 $\delta^k_i$를 정의했다면, 출력층의 $\delta^K$도 구할 수 있을 것이다. 그렇다면 $K-1$층의 $\delta^{K-1}$는 $\delta^K$를 통해서 구할 수 있으니, 결국 $W^{K-1}$층의 미분도 구할 수 있다는 뜻이 된다.</p><p>본격적으로 $\delta^K$를 구해보자.</p><script type="math/tex; mode=display">\delta^K_i = \frac{\partial E}{\partial y_i}\frac{\partial y_i}{\partial u^K_i} = \frac{1}{N}(y_i - t_i)f'(u^K_i)</script><p>그렇다. 바로 구할 수 있다. 그렇다면 이를 통해서 뒤에 있는 층의 미분을 차례로 구할 수 있는 것이다.<br>Feed Forward와는 달리, 이 과정은 방향이 반대로 진행된다. 따라서 이는 Back Propagation이라고 하며, 이렇게 $\delta$를 정의하여 미분을 구하는 방식을 <strong>일반화된 델타 규칙</strong>이라고 한다. </p><p>자, Weight의 미분은 구했으니, Bias의 미분도 구해야한다. 이는 매우 간단하다.</p><script type="math/tex; mode=display">\frac{\partial E}{\partial b^k_i} = \frac{\partial E}{\partial u^k_i}\frac{\partial u^k_i}{\partial b^k_i} = \delta^k_i\cdot 1\tag{Equation (15)}</script><p>이렇게 우리는 $\delta$에 관한 값만 구하면 신경망을 Update 하기 위한 미분을 전부 구할 수 있다. 그렇기에, <em>핵심</em>이라고 할 수 있는 방정식 $Def. 8$, $Equation (13)$, $Equation (15)$, $Equation (14)$에 대해서 행렬로써 표현해 보자.</p><p><em>Definition of Delta</em></p><script type="math/tex; mode=display">\Delta^k = \nabla_UE = \nabla_ZE \odot f'(U^k)\tag{Def. 8}</script><p><em>Delta Matrix Relation</em></p><script type="math/tex; mode=display">\Delta^k = \left( (W^{k+1})^T\Delta^k \right) \odot f'(U^k)\tag{Equation (13)}</script><p><em>Bias Update Equation</em></p><script type="math/tex; mode=display">\nabla_B E = \Delta^k\tag{Equation (15)}</script><p><em>Weight Update Equation</em></p><script type="math/tex; mode=display">\nabla_WE = \Delta^kZ^{k-1}\tag{Equation (14)}</script><p>이걸로 FCNN의 Feed Forward, Back Propagation의 이론적인 부분이 끝났다. 이제 실습은 Part. B에서 마저 다룰 예정이다.</p>]]></content:encoded>
      
      
      <category domain="https://kimh060612.github.io/categories/Deep-Learning/">Deep Learning</category>
      
      
      <category domain="https://kimh060612.github.io/tags/Deep-Learning/">Deep Learning</category>
      
      <category domain="https://kimh060612.github.io/tags/Mathematics/">Mathematics</category>
      
      
      <comments>https://kimh060612.github.io/2022/03/05/FCNN-A/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
